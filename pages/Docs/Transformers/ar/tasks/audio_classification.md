<!-- ุญููู ุงููุดุฑ 2022 ูุฑูู HuggingFace. ุฌููุน ุงูุญููู ูุญููุธุฉ.

ูุฑุฎุต ุจููุฌุจ ุฑุฎุตุฉ ุฃุจุงุชุดูุ ุงูุฅุตุฏุงุฑ 2.0 (ุงูุฑุฎุตุฉ)ุ ูุง ูุฌูุฒ ูู ุงุณุชุฎุฏุงู ูุฐุง ุงูููู ุฅูุง ููููุง ูุดุฑูุท ุงูุฑุฎุตุฉ. ููููู ุงูุญุตูู ุนูู ูุณุฎุฉ ูู ุงูุฑุฎุตุฉ ุนูู

http://www.apache.org/licenses/LICENSE-2.0

ูุง ูู ูุชุทูุจ ุงููุงููู ุงููุนููู ุจู ุฃู ูุชู ุงูุงุชูุงู ุนููู ูุชุงุจููุงุ ูุชู ุชูุฒูุน ุงูุจุฑูุงูุฌ ุงูููุฒุน ุจููุฌุจ ุงูุฑุฎุตุฉ ุนูู ุฃุณุงุณ "ููุง ูู" ุจุฏูู ุถูุงูุงุช ุฃู ุดุฑูุท ูู ุฃู ููุนุ ุณูุงุก ูุงูุช ุตุฑูุญุฉ ุฃู ุถูููุฉ. ุฑุงุฌุน ุงูุฑุฎุตุฉ ููุญุตูู ุนูู ุงููุบุฉ ุงููุญุฏุฏุฉ ุงูุชู ุชุญูู ุงูุฃุฐููุงุช ูุงููููุฏ ุจููุฌุจ ุงูุฑุฎุตุฉ.

โ๏ธ ูุฑุฌู ููุงุญุธุฉ ุฃู ูุฐุง ุงูููู ููุชูุจ ุจูุบุฉ Markdown ููููู ูุญุชูู ุนูู ุจูุงุก ุฌููุฉ ูุญุฏุฏ ููููุดุฆ ูุซุงุฆููุง (ูุดุจู MDX) ูุงูุฐู ูุฏ ูุง ูุชู ุนุฑุถู ุจุดูู ุตุญูุญ ูู ุนุงุฑุถ Markdown ุงูุฎุงุต ุจู.

-->

# ุงูุชุตููู ุงูุตูุชู

[[open-in-colab]]

<Youtube id="KWwzcmG98Ds"/>

ุงูุชุตููู ุงูุตูุชู - ุชูุงููุง ูุซู ุงููุต - ูููู ุจุชุนููู ุชุณููุฉ ูุฆุฉ ุงูุฅุฎุฑุงุฌ ูู ุจูุงูุงุช ุงูุฅุฏุฎุงู. ูุงููุฑู ุงููุญูุฏ ูู ุฃูู ุจุฏูุงู ูู ุฅุฏุฎุงู ุงููุตุ ูุฏูู ุฃุดูุงู ููุฌูุฉ ุตูุชูุฉ ุฎุงู. ุจุนุถ ุงูุชุทุจููุงุช ุงูุนูููุฉ ููุชุตููู ุงูุตูุชู ุชุดูู ุชุญุฏูุฏ ููุฉ ุงููุชุญุฏุซุ ูุชุตููู ุงููุบุฉุ ูุญุชู ุชุญุฏูุฏ ุฃููุงุน ุงูุญููุงูุงุช ูู ุฎูุงู ุฃุตูุงุชูุง.

ุณููุถุญ ูู ูุฐุง ุงูุฏููู ููููุฉ:

1. ุถุจุท ูููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ุนูู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูุชุตููู ููุฉ ุงููุชุญุฏุซ.
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงููุถุจูุท ููุชูุจุค.

<Tip>

ูุฑุคูุฉ ุฌููุน ุงูุจูู ูุงูููุงุท ุงููุฑุฌุนูุฉ ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/audio-classification)

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate
```

ูุญู ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ุญุชู ุชุชููู ูู ุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ูููุ ุฃุฏุฎู ุฑูุฒู ููุฏุฎูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ูู ููุชุจุฉ ๐ค Datasets:

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

ูู ุจุชูุณูู ูุฌููุนุฉ ุจูุงูุงุช `train` ุฅูู ูุฌููุนุฉ ุจูุงูุงุช ุฃุตุบุฑ ููุชุฏุฑูุจ ูุงูุงุฎุชุจุงุฑ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.train_test_split`]. ุณูุนุทูู ูุฐุง ูุฑุตุฉ ููุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

ุซู ุฃูู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> minds
DatasetDict({
    train: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 450
    })
    test: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 113
    })
})
```

ูู ุญูู ุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชุญุชูู ุนูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุงููููุฏุฉุ ูุซู `lang_id` ู `english_transcription`ุ ุณุชุฑูุฒ ูู ูุฐุง ุงูุฏููู ุนูู `audio` ู `intent_class`. ูู ุจุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.remove_columns`]:

```py
>>> minds = minds.remove_columns(["path", "transcription", "english_transcription", "lang_id"])
```

ุฃูู ูุธุฑุฉ ุนูู ูุซุงู ุงูุขู:

```py
>>> minds["train"][0]
{'audio': {'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,
         -0.00024414, -0.00024414], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 8000},
 'intent_class': 2}
```

ููุงู ุญููุงู:

- `audio`: ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจุนุฏ ููุฅุดุงุฑุฉ ุงูุตูุชูุฉ ุงูุชู ูุฌุจ ุงุณุชุฏุนุงุคูุง ูุชุญููู ูููุงุฒูุฉ ููู ุงูุตูุช.
- `intent_class`: ููุซู ูุนุฑู ูุฆุฉ ููุฉ ุงููุชุญุฏุซ.

ูุชุณููู ุญุตูู ุงููููุฐุฌ ุนูู ุงุณู ุงูุชุณููุฉ ูู ูุนุฑู ุงูุชุณููุฉุ ูู ุจุฅูุดุงุก ูุงููุณ ูููู ุจุชุนููู ุงุณู ุงูุชุณููุฉ ุฅูู ุนุฏุฏ ุตุญูุญ ูุงูุนูุณ ุจุงูุนูุณ:

```py
>>> labels = minds["train"].features["intent_class"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

ุงูุขู ููููู ุชุญููู ูุนุฑู ุงูุชุณููุฉ ุฅูู ุงุณู ุงูุชุณููุฉ:

```py
>>> id2label[str(2)]
'app_error'
```

## ุงููุนุงูุฌุฉ ุงููุณุจูุฉ

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุณุชุฎุฑุฌ ููุฒุงุช Wav2Vec2 ููุนุงูุฌุฉ ุงูุฅุดุงุฑุฉ ุงูุตูุชูุฉ:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

ุชุจูุบ ูุณุจุฉ ุฃุฎุฐ ุงูุนููุงุช ูู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 8000 ูููู ูุฑุชุฒ (ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุงุช ูู [ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/PolyAI/minds14))ุ ููุง ูุนูู ุฃูู ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู 16000 ูููู ูุฑุชุฒ ูุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงูููุฏุฑุจ ูุณุจููุง:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,
         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 16000},
 'intent_class': 2}
```

ุงูุขู ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุนุงูุฌุฉ ูุณุจูุฉ ุชููู ุจูุง ููู:

1. ุงุณุชุฏุนุงุก ุนููุฏ `audio` ูุชุญูููุ ูุฅุฐุง ูุฒู ุงูุฃูุฑุ ููุงุฒูุฉ ููู ุงูุตูุช.
2. ุงูุชุญูู ููุง ุฅุฐุง ูุงูุช ูุณุจุฉ ุฃุฎุฐ ุงูุนููุงุช ูููู ุงูุตูุช ุชุชุทุงุจู ูุน ูุณุจุฉ ุฃุฎุฐ ุงูุนููุงุช ูุจูุงูุงุช ุงูุตูุช ุงูุชู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนูููุง ูุณุจููุง. ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุงุช ูู ุจุทุงูุฉ ูููุฐุฌ Wav2Vec2 [model card](https://huggingface.co/facebook/wav2vec2-base).
3. ุชุนููู ุทูู ุฅุฏุฎุงู ุฃูุตู ูุฏูุนุงุช ุงูุฅุฏุฎุงูุงุช ุงูุฃุทูู ุฏูู ุชูุทูุนูุง.

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True
...     )
...     return inputs
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงููุงููุ ุงุณุชุฎุฏู ูุธููุฉ ๐ค Datasets [`~datasets.Dataset.map`]. ููููู ุชุณุฑูุน `map` ุนู ุทุฑูู ุชุนููู `batched=True` ููุนุงูุฌุฉ ุนูุงุตุฑ ูุชุนุฏุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู ููุช ูุงุญุฏ. ูู ุจุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุญุชุงุฌูุงุ ูุฃุนุฏ ุชุณููุฉ `intent_class` ุฅูู `label` ูุฃู ูุฐุง ูู ุงูุงุณู ุงูุฐู ูุชููุนู ุงููููุฐุฌ:

```py
>>> encoded_minds = minds.map(preprocess_function, remove_columns="audio", batched=True)
>>> encoded_minds = encoded_minds.rename_column("intent_class", "label")
```

## ุงูุชูููู

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุชุญููู ุทุฑููุฉ ุชูููู ุจุณุฑุนุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index). ุจุงููุณุจุฉ ููุฐู ุงููููุฉุ ูู ุจุชุญููู ูููุงุณ [ุงูุฏูุฉ](https://huggingface.co/spaces/evaluate-metric/accuracy) (ุฑุงุฌุน ุฌููุฉ ๐ค Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูุญุณุงุจ ูููุงุณ):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชููู ุจุชูุฑูุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ ุงูุฏูุฉ:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions = np.argmax(eval_pred.predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)
```

ุฏุงูุฉ `compute_metrics` ุงูุฎุงุตุฉ ุจู ุฌุงูุฒุฉ ุงูุขูุ ูุณุชุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุชุฏุฑูุจู.

## ุงูุชุฏุฑูุจ

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ุนูู ุฏุฑุงูุฉ ุจุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`], ุฃูู ูุธุฑุฉ ุนูู ุงูุฏููู ุงูุชุนูููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ูุณุชุนุฏ ุงูุขู ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู Wav2Vec2 ุจุงุณุชุฎุฏุงู [`AutoModelForAudioClassification`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุนุฏุฏ ุงูุชุณููุงุช ุงููุชููุนุฉุ ูุชุนูููุงุช ุงูุชุณููุงุช:

```py
>>> from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer

>>> num_labels = len(id2label)
>>> model = AutoModelForAudioClassification.from_pretrained(
...     "facebook/wav2vec2-base", num_labels=num_labels, label2id=label2id, id2label=id2label
... )
```
ูู ูุฐู ุงููุฑุญูุฉุ ุชุจูู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุญุฏุฏ ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]. ุงููุนููุฉ ุงููุญูุฏุฉ ุงููุทููุจุฉ ูู `output_dir` ูุงูุชู ุชุญุฏุฏ ููุงู ุญูุธ ูููุฐุฌู. ุณุชุฑุณู ูุฐุง ุงููููุฐุฌ ุฅูู ุงููุฑูุฒ ูู ุฎูุงู ุชุนููู `push_to_hub=True` (ูุฌุจ ุฃู ุชููู ูุณุฌูุงู ูู Hugging Face ูุชุญููู ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉุ ุณูููู [`Trainer`] ุจุชูููู ุงูุฏูุฉ ูุญูุธ ููุทุฉ ุชูุชูุด ุงูุชุฏุฑูุจ.
2. ูุฑุฑ ุญุฌุฌ ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุงููููุฐุฌุ ููุฌููุนุฉ ุงูุจูุงูุงุชุ ูุงููุญููุ ููุฌูุน ุงูุจูุงูุงุชุ ููุธููุฉ `compute_metrics`.
3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุชุนุฏูู ูููุฐุฌู.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_mind_model",
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=3e-5,
...     per_device_train_batch_size=32,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=32,
...     num_train_epochs=10,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy",
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=encoded_minds["train"],
...     eval_dataset=encoded_minds["test"],
...     processing_class=feature_extractor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ูู ุงููุฑูุฒ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ุญุชู ูุชููู ุงูุฌููุน ูู ุงุณุชุฎุฏุงู ูููุฐุฌู:

```py
>>> trainer.push_to_hub()
```
</frameworkcontent>

<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุนูููุง ุญูู ููููุฉ ุชุนุฏูู ูููุฐุฌ ูุชุตููู ุงูุตูุชุ ุงุทูุน ุนูู ุฏูุชุฑ ููุงุญุธุงุช PyTorch ุงูููุงุจู [PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb).

</Tip>

## ุงูุงุณุชุฏูุงู

ุฑุงุฆุนุ ุงูุขู ุจุนุฏ ุฃู ููุช ุจุชุนุฏูู ูููุฐุฌุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชุฏูุงู!

ูู ุจุชุญููู ููู ุตูุชู ุชุฑูุฏ ุชุดุบูู ุงูุงุณุชุฏูุงู ุนููู. ุชุฐูุฑ ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุฉ ูู ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ููููู ุงูุตูุชู ููุทุงุจูุฉ ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููููุฐุฌ ุฅุฐุง ููุช ุจุญุงุฌุฉ ุฅูู ุฐูู!

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

ุฃุจุณุท ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุนุฏู ููุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ูู [`pipeline`]. ูู ุจุชูููุฐ `pipeline` ูุชุตููู ุงูุตูุช ูุน ูููุฐุฌูุ ููุฑุฑ ููู ุงูุตูุช ุงูุฎุงุต ุจู ุฅููู:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("audio-classification", model="stevhliu/my_awesome_minds_model")
>>> classifier(audio_file)
[
    {'score': 0.09766869246959686, 'label': 'cash_deposit'},
    {'score': 0.07998877018690109, 'label': 'app_error'},
    {'score': 0.0781070664525032, 'label': 'joint_account'},
    {'score': 0.07667109370231628, 'label': 'pay_bill'},
    {'score': 0.0755252093076706, 'label': 'balance'}
]
```

ููููู ุฃูุถูุง ุชูุฑุงุฑ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ุฃุฑุฏุช:

<frameworkcontent>
<pt>
ูู ุจุชุญููู ูุณุชุฎุฑุฌ ุงูููุฒุงุช ููุนุงูุฌุฉ ููู ุงูุตูุช ูุฅุฑุฌุงุน `input` ููุชุฌูุงุช PyTorch:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("stevhliu/my_awesome_minds_model")
>>> inputs = feature_extractor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

ูุฑุฑ ูุฏุฎูุงุชู ุฅูู ุงููููุฐุฌ ูุฃุฑุฌุน ุงูููุบุงุฑูุชูุงุช:

```py
>>> from transformers import AutoModelForAudioClassification

>>> model = AutoModelForAudioClassification.from_pretrained("stevhliu/my_awesome_minds_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ุงุญุตู ุนูู ุงููุฆุฉ ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุฃุนููุ ูุงุณุชุฎุฏู ุฎุฑูุทุฉ `id2label` ูููููุฐุฌ ูุชุญููููุง ุฅูู ุชุณููุฉ:

```py
>>> import torch

>>> predicted_class_ids = torch.argmax(logits).item()
>>> predicted_label = model.config.id2label[predicted_class_ids]
>>> predicted_label
'cash_deposit'
```
</pt>
</frameworkcontent>
```