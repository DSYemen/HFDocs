# الوحدة 3. هندسة المحول للصوت

في هذه الدورة، سننظر بشكل أساسي في نماذج المحول وكيفية تطبيقها على مهام الصوت. بينما لا تحتاج إلى معرفة التفاصيل الداخلية لهذه النماذج، من المفيد فهم المفاهيم الرئيسية التي تجعلها تعمل، لذا إليك تذكير سريع. للحصول على نظرة متعمقة حول المحولات، اطلع على [دورة NLP](https://huggingface.co/course/chapter1/1).

## كيف يعمل المحول؟

تم تصميم نموذج المحول الأصلي لترجمة النص المكتوب من لغة إلى أخرى. كان شكل هندسته على النحو التالي:

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="هندسة المحول الأصلي">
</div>

على اليسار يوجد **المشفر** وعلى اليمين يوجد **فك الشفرة**.

- يستقبل المشفر إدخالاً، في هذه الحالة تسلسل رموز نصية، ويبني تمثيلاً له (ميزاته). هذا الجزء من النموذج مدرب على اكتساب الفهم من الإدخال.

- يستخدم فك الشفرة تمثيل المشفر (الميزات) إلى جانب إدخالات أخرى (الرموز المتوقعة مسبقًا) لتوليد تسلسل مستهدف. هذا الجزء من النموذج مدرب على توليد المخرجات. في التصميم الأصلي، كان تسلسل الإخراج يتكون من رموز نصية.

هناك أيضًا نماذج قائمة على المحول تستخدم فقط جزء المشفر (جيد لمهام تتطلب فهم الإدخال، مثل التصنيف)، أو جزء فك الشفرة فقط (جيد لمهام مثل توليد النص). مثال على نموذج المشفر فقط هو BERT؛ مثال على نموذج فك الشفرة فقط هو GPT2.

تتمثل إحدى الميزات الرئيسية لنماذج المحول في أنها مبنية باستخدام طبقات خاصة تسمى **طبقات الانتباه**. تخبر هذه الطبقات النموذج بإيلاء اهتمام محدد لعناصر معينة في تسلسل الإدخال وتجاهل الآخرين عند حساب تمثيلات الميزات.

## استخدام المحولات للصوت

عادةً ما يكون لنماذج الصوت التي سنغطيها في هذه الدورة هندسة محول قياسية كما هو موضح أعلاه، ولكن مع تعديل طفيف على جانب الإدخال أو الإخراج للسماح ببيانات الصوت بدلاً من النص. نظرًا لأن جميع هذه النماذج عبارة عن محولات في جوهرها، فستكون معظم هندستها مشتركة والاختلافات الرئيسية هي في كيفية تدريبها واستخدامها.

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/transformers_blocks.png" alt="المحول مع إدخال وإخراج الصوت">
</div>

بالنسبة لمهام الصوت، قد يكون الإدخال و/أو تسلسل الإخراج صوتيًا بدلاً من النص:

- التعرف التلقائي على الكلام (ASR): الإدخال هو الكلام، والإخراج هو النص.

- تركيب الكلام (TTS): الإدخال هو النص، والإخراج هو الكلام.

- تصنيف الصوت: الإدخال هو الصوت، والإخراج هو احتمال الفئة - واحد لكل عنصر في التسلسل أو احتمال فئة واحدة للتسلسل بالكامل.

- تحويل الصوت أو تحسين الكلام: كل من الإدخال والإخراج صوتي.

هناك بضع طرق مختلفة للتعامل مع الصوت بحيث يمكن استخدامه مع المحول. الاعتبار الرئيسي هو ما إذا كان سيتم استخدام الصوت في شكله الخام - كموجة - أو معالجته كطيف بدلاً من ذلك.

## إدخالات النموذج

يمكن أن يكون إدخال نموذج الصوت إما نصًا أو صوتًا. الهدف هو تحويل هذا الإدخال إلى متجه مضمن يمكن معالجته بواسطة هندسة المحول.

### إدخال النص

يأخذ نموذج تحويل النص إلى كلام النص كإدخال. يعمل هذا تمامًا مثل المحول الأصلي أو أي نموذج NLP آخر: يتم ترميز النص المدخل أولاً، مما يعطي تسلسل رموز نصية. يتم إرسال هذا التسلسل عبر طبقة تضمين الإدخال لتحويل الرموز إلى متجهات أبعاد 512. ثم يتم تمرير متجهات التضمين هذه إلى مشفر المحول.

### إدخال الموجة

يأخذ نموذج التعرف التلقائي على الكلام الصوت كإدخال. لكي نتمكن من استخدام محول لـ ASR، نحتاج أولاً إلى تحويل الصوت إلى تسلسل من متجهات التضمين بطريقة ما.

تستخدم النماذج مثل **Wav2Vec2** و **HuBERT** موجة الصوت مباشرة كإدخال للنموذج. كما رأيت في [الفصل الخاص ببيانات الصوت](../chapter1/introduction)، فإن الموجة عبارة عن تسلسل أحادي البعد من الأرقام العائمة، حيث يمثل كل رقم السعة المعينة في وقت معين. يتم تطبيع هذه الموجة الخام أولاً إلى متوسط صفري وتغاير وحدة، مما يساعد على توحيد عينات الصوت عبر أحجام مختلفة (السعات).

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/wav2vec2-input.png" alt="Wav2Vec2 يستخدم CNN لإنشاء تضمينات من موجة الإدخال">
</div>

بعد التطبيع، يتم تحويل تسلسل عينات الصوت إلى تضمين باستخدام شبكة عصبية ذات ترابطية صغيرة، تُعرف باسم مشفر الميزة. تقوم كل طبقة من الطبقات الترابطية في هذه الشبكة بمعالجة تسلسل الإدخال، وتقليل عينات الصوت لتقليل طول التسلسل، حتى تقوم الطبقة الترابطية النهائية بإخراج متجه أبعاده 512 مع التضمين لكل 25 مللي ثانية من الصوت. بمجرد تحويل تسلسل الإدخال إلى تسلسل من هذه التضمينات، سيقوم المحول بمعالجة البيانات كالمعتاد.

### إدخال الطيف

أحد الجوانب السلبية لاستخدام الموجة الخام كإدخال هو أنها تميل إلى أن يكون لها أطوال تسلسل طويلة. على سبيل المثال، يعطي ثلاثون ثانية من الصوت بمعدل أخذ العينات 16 كيلو هرتز إدخالاً بطول `30 * 16000 = 480000`. تتطلب أطوال التسلسل الأطول حسابات أكثر في نموذج المحول، وبالتالي استخدام ذاكرة أعلى.

لهذا السبب، لا تكون موجات الصوت الخام عادةً أكثر أشكال تمثيل إدخال الصوت كفاءة. باستخدام طيف، نحصل على نفس كمية المعلومات ولكن بشكل مضغوط أكثر.

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/whisper-input.png" alt="Whisper يستخدم CNN لإنشاء تضمينات من طيف الإدخال">
</div>

تقوم النماذج مثل **Whisper** أولاً بتحويل الموجة إلى طيف لوغاريتمي-ميل. يقوم Whisper دائمًا بتقسيم الصوت إلى مقاطع مدتها 30 ثانية، ويكون شكل طيف اللوغاريتم-ميل لكل مقطع هو `(80، 3000)` حيث 80 هو عدد صناديق الميل و3000 هو طول التسلسل. من خلال التحويل إلى طيف لوغاريتمي-ميل، قمنا بتقليل كمية بيانات الإدخال، ولكن الأهم من ذلك، هذا تسلسل أقصر بكثير من الموجة الخام. بعد ذلك، يتم معالجة طيف اللوغاريتم-ميل بواسطة شبكة CNN صغيرة إلى تسلسل من التضمينات، والذي يدخل المحول كالمعتاد.

في كلتا الحالتين، سواء كان الإدخال موجة أو طيفًا، هناك شبكة صغيرة أمام المحول تقوم بتحويل الإدخال إلى تضمينات، ثم يتولى المحول الأمر.

## مخرجات النموذج

تخرج هندسة المحول تسلسلًا من متجهات الحالة المخفية، والمعروفة أيضًا بتضمينات الإخراج. هدفنا هو تحويل هذه المتجهات إلى إخراج نصي أو صوتي.

### إخراج النص

هدف نموذج التعرف التلقائي على الكلام هو التنبؤ بتسلسل من رموز النص. يتم ذلك عن طريق إضافة رأس نمذجة اللغة - عادةً طبقة خطية واحدة - تليها دالة softmax أعلى إخراج المحول. هذا يتنبأ بالاحتمالات عبر رموز النص في المفردات.

### إخراج الطيف

بالنسبة للنماذج التي تولد الصوت، مثل نموذج تحويل النص إلى كلام (TTS)، سنضطر إلى إضافة طبقات يمكنها إنتاج تسلسل صوتي. من الشائع جدًا توليد طيف ثم استخدام شبكة عصبية إضافية، تُعرف باسم فك التشفير، لتحويل هذا الطيف إلى موجة.

في نموذج **SpeechT5** TTS، على سبيل المثال، يكون الإخراج من شبكة المحول عبارة عن تسلسل من المتجهات المكونة من 768 عنصرًا. تقوم طبقة خطية بمشروع ذلك التسلسل إلى طيف لوغاريتمي-ميل. تقوم شبكة ما بعد المعالجة، المكونة من طبقات خطية وترابطية إضافية، بتنقيح الطيف عن طريق تقليل الضوضاء. بعد ذلك، يقوم فك التشفير بإنشاء موجة الصوت النهائية.

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/speecht5.png" alt="SpeechT5 يخرج طيفًا ويستخدم فك التشفير لإنشاء الموجة">
</div>
<Tip>
💡 إذا قمت بأخذ موجة موجودة وتطبيق تحويل فورييه قصير المدى أو STFT، فمن الممكن إجراء العملية العكسية، ISTFT، للحصول على الموجة الأصلية مرة أخرى. يعمل هذا لأن المخطط الطيفي الذي تم إنشاؤه بواسطة STFT يحتوي على كل من معلومات السعة والطور، وكلاهما مطلوب لإعادة بناء الموجة. ومع ذلك، فإن نماذج الصوت التي تنتج مخرجاتها كمخطط طيفي عادة ما تتنبأ فقط بمعلومات السعة، وليس الطور. لتحويل مثل هذا المخطط الطيفي إلى موجة، يجب علينا بطريقة ما تقدير معلومات الطور. هذا ما يفعله فوكودر.
</Tip>

### إخراج الموجة

من الممكن أيضًا للنماذج أن تخرج موجة مباشرة بدلاً من المخطط الطيفي كخطوة وسيطة، ولكن لا يوجد لدينا حاليًا أي نماذج في 🤗 المحولات التي تقوم بذلك.

## خاتمة

باختصار: معظم نماذج المحول الصوتي متشابهة أكثر من كونها مختلفة - فهي جميعها مبنية على نفس هندسة المحول وطبقات الانتباه، على الرغم من أن بعض النماذج ستستخدم فقط الجزء المشفر من المحول بينما يستخدم البعض الآخر كل من المشفر وفك التشفير.

لقد رأيت أيضًا كيفية إدخال بيانات الصوت وإخراجها من نماذج المحول. لأداء مهام الصوت المختلفة ASR وTTS، وما إلى ذلك، يمكننا ببساطة استبدال الطبقات التي تقوم بمعالجة المدخلات إلى تضمين، واستبدال الطبقات التي تقوم بمعالجة التضمينات المتوقعة إلى مخرجات، في حين أن العمود الفقري للمحول يبقى كما هو.

بعد ذلك، دعنا نلقي نظرة على بعض الطرق المختلفة التي يمكن من خلالها تدريب هذه النماذج على التعرف على الكلام التلقائي.