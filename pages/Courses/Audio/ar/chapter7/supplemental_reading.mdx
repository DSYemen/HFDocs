# قراءات وموارد إضافية

جمعت هذه الوحدة العديد من المكونات من الوحدات السابقة، حيث قدمت مهام الترجمة من الكلام إلى الكلام، والمساعدين الصوتيين، وتحديد المتحدث. لذا تم تقسيم المواد القرائية الإضافية إلى هذه المهام الثلاث الجديدة لراحتك:

الترجمة من الكلام إلى الكلام:
* [الترجمة من الكلام إلى الكلام مع وحدات منفصلة](https://ai.facebook.com/blog/advancing-direct-speech-to-speech-modeling-with-discrete-units/) بواسطة Meta AI: نهج مباشر للترجمة من الكلام إلى الكلام من خلال نماذج الترميز وفك الترميز
* [الترجمة المباشرة من الكلام إلى الكلام لهوكين](https://ai.facebook.com/blog/ai-translation-hokkien/) بواسطة Meta AI: نهج مباشر للترجمة من الكلام إلى الكلام باستخدام نماذج الترميز وفك الترميز مع فك ترميز من مرحلتين
* [الاستفادة من البيانات غير المُشرفة والبيانات المُشرفة بشكل ضعيف لتحسين الترجمة المباشرة من الكلام إلى الكلام](https://arxiv.org/abs/2203.13339) بواسطة Google: يقترح نهجًا جديدًا للاستفادة من البيانات غير المُشرفة والبيانات المُشرفة بشكل ضعيف لتدريب نماذج الترجمة المباشرة من الكلام إلى الكلام وتغيير بسيط في بنية المحول
* [ترانسلاتوترون-2](https://google-research.github.io/lingvo-lab/translatotron2/) بواسطة Google: نظام قادر على الاحتفاظ بخصائص المتحدث في الكلام المترجم

المساعد الصوتي:
* [كشف دقيق لكلمة الاستيقاظ](https://www.amazon.science/publications/accurate-detection-of-wake-word-start-and-end-using-a-cnn) بواسطة Amazon: نهج منخفض الكمون لاكتشاف كلمة الاستيقاظ للتطبيقات على الجهاز
* [بنية RNN-Transducer](https://arxiv.org/pdf/1811.06621.pdf) بواسطة Google: تعديل على بنية CTC للبث المباشر لتعرف الكلام التلقائي على الجهاز

نصوص الاجتماعات:
* [التقرير الفني لـ pyannote.audio](https://huggingface.co/pyannote/speaker-diarization/blob/main/technical_report_2.1.pdf) بواسطة هيرفي بريدين: يصف هذا التقرير المبادئ الرئيسية وراء خط أنابيب تحديد المتحدث في pyannote.audio
* [Whisper X](https://arxiv.org/pdf/2303.00747.pdf) بواسطة ماكس باين وآخرون: نهج متفوق لحساب الطوابع الزمنية على مستوى الكلمة باستخدام نموذج Whisper