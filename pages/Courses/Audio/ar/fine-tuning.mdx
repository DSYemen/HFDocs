# ุถุจุท ูููุฐุฌ SpeechT5

ุงูุขู ุจุนุฏ ุฃู ุฃุตุจุญุช ุนูู ุฏุฑุงูุฉ ุจูููุฉ ุชุญููู ุงููุต ุฅูู ููุงู ูุงูุฃุฌุฒุงุก ุงูุฏุงุฎููุฉ ููููุฐุฌ SpeechT5 ุงูุฐู ุชู ุชุฏุฑูุจู ูุณุจููุง ุนูู ุจูุงูุงุช ุงููุบุฉ ุงูุฅูุฌููุฒูุฉุ ุฏุนูุง ูุฑู ููู ูููููุง ุถุจุทู ุจุฏูุฉ ููุนูู ูุน ูุบุฉ ุฃุฎุฑู.

## ุงูุฅุนุฏุงุฏุงุช ุงูุฃูููุฉ
ุชุฃูุฏ ูู ุฃู ูุฏูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ุฅุฐุง ููุช ุชุฑุบุจ ูู ุฅุนุงุฏุฉ ุฅูุชุงุฌ ูุฐุง ุงููุซุงู. ูู ุฏูุชุฑ ุงูููุงุญุธุงุชุ ููููู ุงูุชุญูู ูู ุฐูู ุจุงุณุชุฎุฏุงู ุงูุฃูุฑ ุงูุชุงูู:

```bash
nvidia-smi
```

<Tip warning={true}>

ูู ูุซุงููุงุ ุณูุณุชุฎุฏู ุญูุงูู 40 ุณุงุนุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ. ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงููุชุงุจุนุฉ ุจุงุณุชุฎุฏุงู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูู ุงููุณุชูู ุงููุฌุงูู ูู Google Colabุ ูุณุชุญุชุงุฌ ุฅูู ุชูููู ูููุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุฅูู ุญูุงูู 10-15 ุณุงุนุฉุ ูุชูููู ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ.

</Tip>

ุณุชุญุชุงุฌ ุฃูุถูุง ุฅูู ุจุนุถ ุงูุงุนุชูุงุฏุงุช ุงูุฅุถุงููุฉ:

```bash
pip install transformers datasets soundfile speechbrain accelerate
```

ุฃุฎูุฑูุงุ ูุง ุชูุณ ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจู ุนูู Hugging Face ุญุชู ุชุชููู ูู ุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน:

```py
from huggingface_hub import notebook_login

notebook_login()
```

## ูุฌููุนุฉ ุงูุจูุงูุงุช

ูู ูุฐุง ุงููุซุงูุ ุณูุฃุฎุฐ ุงููุฌููุนุฉ ุงููุฑุนูุฉ ููุบุฉ ุงูููููุฏูุฉ (`nl`) ูู ูุฌููุนุฉ ุจูุงูุงุช [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli).
[VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) ูู ูุฌููุนุฉ ุจูุงูุงุช ูุชุนุฏุฏุฉ ุงููุบุงุช ูุงุณุนุฉ ุงููุทุงู ุชุชููู ูู ุจูุงูุงุช ูุณุฌูุฉ ูู ุฃุญุฏุงุซ ุงูุจุฑููุงู ุงูุฃูุฑูุจู ูู ุงููุชุฑุฉ ูู 2009 ุฅูู 2020. ุชุญุชูู ุนูู ุจูุงูุงุช ุตูุชูุฉ-ูุตูุฉ ูุนูููุฉ ูู 15 ูุบุฉ ุฃูุฑูุจูุฉ. ุนูู ุงูุฑุบู ูู ุฃููุง ุณูุณุชุฎุฏู ุงููุฌููุนุฉ ุงููุฑุนูุฉ ููุบุฉ ุงูููููุฏูุฉุ ููููู ุงุฎุชูุงุฑ ูุฌููุนุฉ ูุฑุนูุฉ ุฃุฎุฑู.

ูุฐู ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR)ุ ูุฐุงุ ููุง ุฐูุฑูุง ุณุงุจููุงุ ููู ููุณุช ุงูุฎูุงุฑ ุงูุฃูุณุจ ูุชุฏุฑูุจ ููุงุฐุฌ ุชุญููู ุงููุต ุฅูู ููุงู (TTS). ููุน ุฐููุ ุณุชููู ุฌูุฏุฉ ุจูุง ูููู ููุฐุง ุงูุชูุฑูู.

ุฏุนูุง ูุญูู ุงูุจูุงูุงุช:

```python
from datasets import load_dataset, Audio

dataset = load_dataset("facebook/voxpopuli", "nl", split="train")
len(dataset)
```

**ุงูุฅุฎุฑุงุฌ:**
```out
20968
```

20968 ูุซุงู ูุฌุจ ุฃู ุชููู ูุงููุฉ ูุถุจุท ุงููููุฐุฌ. ูุชููุน SpeechT5 ุฃู ูููู ููุจูุงูุงุช ุงูุตูุชูุฉ ูุนุฏู ุฃุฎุฐ ุนููุงุช ูุจูุบ 16 ูููู ูุฑุชุฒุ ูุฐุง ุชุฃูุฏ ูู ุฃู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชูุจู ูุฐุง ุงูุดุฑุท:

```python
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
```

## ูุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุง

ุฏุนูุง ูุจุฏุฃ ุจุชุญุฏูุฏ ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ุงูุชู ุณูุณุชุฎุฏููุง ูุชุญููู ุงููุนุงูุฌ ุงูููุงุณุจ ุงูุฐู ูุญุชูู ุนูู ูู ูู ุงููุนุงูุฌ ุงููุบูู (tokenizer) ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุงูุฐู ุณูุญุชุงุฌ ุฅููู ูุฅุนุฏุงุฏ ุงูุจูุงูุงุช ููุชุฏุฑูุจ:

```py
from transformers import SpeechT5Processor

checkpoint = "microsoft/speecht5_tts"
processor = SpeechT5Processor.from_pretrained(checkpoint)
```

### ุชูุธูู ุงููุต ูุชูุณูู SpeechT5 ุฅูู ุฑููุฒ

ุฃููุงูุ ุจุงููุณุจุฉ ูุฅุนุฏุงุฏ ุงููุตุ ุณูุญุชุงุฌ ุฅูู ุงูุฌุฒุก ุงููุนุงูุฌ ุงููุบูู (tokenizer) ูู ุงููุนุงูุฌุ ูุฐุง ุฏุนูุง ูุญุตู ุนููู:

```py
tokenizer = processor.tokenizer
```

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ูุซุงู:

```python
dataset[0]
```

**ุงูุฅุฎุฑุงุฌ:**
```out
{'audio_id': '20100210-0900-PLENARY-3-nl_20100210-09:06:43_4',
 'language': 9,
 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/02ec6a19d5b97c03e1379250378454dbf3fa2972943504a91c7da5045aa26a89/train_part_0/20100210-0900-PLENARY-3-nl_20100210-09:06:43_4.wav',
  'array': array([ 4.27246094e-04,  1.31225586e-03,  1.03759766e-03, ...,
         -9.15527344e-05,  7.62939453e-04, -2.44140625e-04]),
  'sampling_rate': 16000},
 'raw_text': 'Dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'normalized_text': 'dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'gender': 'female',
 'speaker_id': '1122',
 'is_gold_transcript': True,
 'accent': 'None'}
```

ูุง ูุฏ ุชูุงุญุธู ูู ุฃู ุฃูุซูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช ุชุญุชูู ุนูู ููุฒุชู `raw_text` ู`normalized_text`. ุนูุฏ ุชุญุฏูุฏ ุงูููุฒุฉ ุงูุชู ุณุชุณุชุฎุฏู ููุฏุฎู ูุตูุ ุณูููู ูู ุงูููู ูุนุฑูุฉ ุฃู ุงููุนุงูุฌ ุงููุบูู (tokenizer) ูู SpeechT5 ูุง ูุญุชูู ุนูู ุฃู ุฑููุฒ ููุฃุฑูุงู. ูู `normalized_text`ุ ูุชู ูุชุงุจุฉ ุงูุฃุฑูุงู ููุต. ูุจุงูุชุงููุ ููู ููุงุณุจุฉ ุฃูุซุฑุ ููุฌุจ ุฃู ูุณุชุฎุฏู `normalized_text` ููุต ุฅุฏุฎุงู.

ุจูุง ุฃู SpeechT5 ุชู ุชุฏุฑูุจู ุนูู ุงููุบุฉ ุงูุฅูุฌููุฒูุฉุ ููุฏ ูุง ูุชุนุฑู ุนูู ุจุนุถ ุงูุฃุญุฑู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูููููุฏูุฉ. ุฅุฐุง ุชูุฑูุช ููุง ููุ ูุณูุชู ุชุญููู ูุฐู ุงูุฃุญุฑู ุฅูู ุฑููุฒ `<unk>`. ููุน ุฐููุ ูู ุงููุบุฉ ุงูููููุฏูุฉุ ุชูุณุชุฎุฏู ุฃุญุฑู ูุนููุฉ ูุซู `ร` ููุชุดุฏูุฏ ุนูู ุงูููุงุทุน. ูู ุฃุฌู ุงูุญูุงุธ ุนูู ูุนูู ุงููุตุ ูููููุง ุงุณุชุจุฏุงู ูุฐุง ุงูุญุฑู ุจุญุฑู `a` ุนุงุฏู.

ูุชุญุฏูุฏ ุงูุฑููุฒ ุบูุฑ ุงููุฏุนููุฉุ ูู ุจุงุณุชุฎุฑุงุฌ ุฌููุน ุงูุฃุญุฑู ุงููุฑูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุงุณุชุฎุฏุงู `SpeechT5Tokenizer` ุงูุฐู ูุนูู ูุน ุงูุฃุญุฑู ูุฑููุฒ. ููููุงู ุจุฐููุ ุณููุชุจ ุฏุงูุฉ `extract_all_chars` ุงูุชู ุชููู ุจุฏูุฌ ุงููุตูุต ูู ุฌููุน ุงูุฃูุซูุฉ ูู ุณูุณูุฉ ูุงุญุฏุฉ ูุชุญููููุง ุฅูู ูุฌููุนุฉ ูู ุงูุฃุญุฑู. ุชุฃูุฏ ูู ุชุนููู `batched=True` ู`batch_size=-1` ูู `dataset.map()` ุจุญูุซ ุชููู ุฌููุน ุงููุตูุต ูุชุงุญุฉ ูุฑุฉ ูุงุญุฏุฉ ููุฏุงูุฉ ุงูุฎุฑุงุฆุทูุฉ.

```py
def extract_all_chars(batch):
    all_text = " ".join(batch["normalized_text"])
    vocab = list(set(all_text))
    return {"vocab": [vocab], "all_text": [all_text]}


vocabs = dataset.map(
    extract_all_chars,
    batched=True,
    batch_size=-1,
    keep_in_memory=True,
    remove_columns=dataset.column_names,
)

dataset_vocab = set(vocabs["vocab"][0])
tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}
```

ุงูุขู ูุฏูู ูุฌููุนุชุงู ูู ุงูุฃุญุฑู: ูุงุญุฏุฉ ูุน ุงูููุฑุฏุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุงูุฃุฎุฑู ูุน ุงูููุฑุฏุงุช ูู ุงููุนุงูุฌ ุงููุบูู. ูุชุญุฏูุฏ ุฃู ุฃุญุฑู ุบูุฑ ูุฏุนููุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููููู ุฃุฎุฐ ุงููุฑู ุจูู ูุงุชูู ุงููุฌููุนุชูู. ุงููุฌููุนุฉ ุงููุงุชุฌุฉ ุณุชุชุถูู ุงูุฃุญุฑู ุงูููุฌูุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูููููุง ุบูุฑ ููุฌูุฏุฉ ูู ุงููุนุงูุฌ ุงููุบูู.

```py
dataset_vocab - tokenizer_vocab
```

**ุงูุฅุฎุฑุงุฌ:**
```out
{' ', 'ร', 'รง', 'รจ', 'รซ', 'รญ', 'รฏ', 'รถ', 'รผ'}
```

ููุชุนุงูู ูุน ุงูุฃุญุฑู ุบูุฑ ุงููุฏุนููุฉ ุงูุชู ุชู ุชุญุฏูุฏูุง ูู ุงูุฎุทูุฉ ุงูุณุงุจูุฉุ ูููููุง ุชุญุฏูุฏ ุฏุงูุฉ ุชููู ุจุชุนููู ูุฐู ุงูุฃุญุฑู ุฅูู ุฑููุฒ ุตุงูุญุฉ. ูุงุญุธ ุฃู ุงููุณุงูุงุช ูุชู ุงุณุชุจุฏุงููุง ุจุงููุนู ุจู `โ` ูู ุงููุนุงูุฌ ุงููุบูู ููุง ุชุญุชุงุฌ ุฅูู ูุนุงูุฌุฉ ูููุตูุฉ.

```py
replacements = [
    ("ร", "a"),
    ("รง", "c"),
    ("รจ", "e"),
    ("รซ", "e"),
    ("รญ", "i"),
    ("รฏ", "i"),
    ("รถ", "o"),
    ("รผ", "u"),
]


def cleanup_text(inputs):
    for src, dst in replacements:
        inputs["normalized_text"] = inputs["normalized_text"].replace(src, dst)
    return inputs


dataset = dataset.map(cleanup_text)
```

ุงูุขู ุจุนุฏ ุฃู ุชุนุงูููุง ูุน ุงูุฃุญุฑู ุงูุฎุงุตุฉ ูู ุงููุตุ ุญุงู ุงูููุช ูุชุญููู ุงูุชุฑููุฒ ุฅูู ุงูุจูุงูุงุช ุงูุตูุชูุฉ.

### ุงููุชุญุฏุซูู

ุชุชุถูู ูุฌููุนุฉ ุจูุงูุงุช VoxPopuli ููุงููุง ูู ูุชุญุฏุซูู ูุชุนุฏุฏููุ ูููู ูู ุนุฏุฏ ุงููุชุญุฏุซูู ุงูููุซููู ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชุญุฏูุฏ ุฐููุ ูููููุง ุญุณุงุจ ุนุฏุฏ ุงููุชุญุฏุซูู ุงููุฑูุฏูู ูุนุฏุฏ ุงูุฃูุซูุฉ ุงูุชู ูุณุงูู ุจูุง ูู ูุชุญุฏุซ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ูุน ูุฌูุฏ ูุง ูุฌููุนู 20,968 ูุซุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ุณุชููุญูุง ูุฐู ุงููุนูููุงุช ููููุง ุฃูุถู ูุชูุฒูุน ุงููุชุญุฏุซูู ูุงูุฃูุซูุฉ ูู ุงูุจูุงูุงุช.

```py
from collections import defaultdict

speaker_counts = defaultdict(int)

for speaker_id in dataset["speaker_id"]:
    speaker_counts[speaker_id] += 1
```

ูู ุฎูุงู ุฑุณู ูุฎุทุท ุชูุฑุงุฑูุ ููููู ุงูุญุตูู ุนูู ููุฑุฉ ุนู ูููุฉ ุงูุจูุงูุงุช ุงููุชููุฑุฉ ููู ูุชุญุฏุซ.

```py
import matplotlib.pyplot as plt

plt.figure()
plt.hist(speaker_counts.values(), bins=20)
plt.ylabel("Speakers")
plt.xlabel("Examples")
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_speakers_histogram.png" alt="Speakers histogram"/>
</div>

ููุดู ุงููุฎุทุท ุงูุชูุฑุงุฑู ุฃู ุญูุงูู ุซูุซ ุงููุชุญุฏุซูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฏููู ุฃูู ูู 100 ูุซุงูุ ูู ุญูู ุฃู ุญูุงูู ุนุดุฑุฉ ูุชุญุฏุซูู ูุฏููู ุฃูุซุฑ ูู 500 ูุซุงู. ูุชุญุณูู ููุงุกุฉ ุงูุชุฏุฑูุจ ูุชูุงุฒู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูููููุง ุชุญุฏูุฏ ุงูุจูุงูุงุช ูููุชุญุฏุซูู ุงูุฐูู ูุฏููู ูุง ุจูู 100 ู400 ูุซุงู.

```py
def select_speaker(speaker_id):
    return 100 <= speaker_counts[speaker_id] <= 400


dataset = dataset.filter(select_speaker, input_columns=["speaker_id"])
```

ุฏุนูุง ูุชุญูู ูู ุนุฏุฏ ุงููุชุญุฏุซูู ุงููุชุจููู:

```py
len(set(dataset["speaker_id"]))
```

**ุงูุฅุฎุฑุงุฌ:**
```out
42
```

ุฏุนูุง ูุฑู ูู ุนุฏุฏ ุงูุฃูุซูุฉ ุงููุชุจููุฉ:

```py
len(dataset)
```

**ุงูุฅุฎุฑุงุฌ:**
```out
9973
ุฏุนูุง ูุฑู ูู ุนุฏุฏ ุงูุฃูุซูุฉ ุงููุชุจููุฉ:

```py
len(dataset)
```

**ุงููุงุชุฌ:**
```out
9973
```

ุชุจูู ูุฏูู ุฃูู ุจูููู ูู 10,000 ูุซุงู ูู ุญูุงูู 40 ูุชุญุฏุซ ูุฑูุฏุ ููู ูุง ููุจุบู ุฃู ูููู ูุงููุงู.

ูุงุญุธ ุฃู ุจุนุถ ุงููุชุญุฏุซูู ุงูุฐูู ูุฏููู ุฃูุซูุฉ ููููุฉ ูุฏ ูููู ูุฏููู ูู ุงููุงูุน ุงููุฒูุฏ ูู ุงูุตูุช ุงููุชุงุญ ุฅุฐุง ูุงูุช ุงูุฃูุซูุฉ ุทูููุฉ. ููุน ุฐููุ
ุชุญุฏูุฏ ุฅุฌูุงูู ูููุฉ ุงูุตูุช ููู ูุชุญุฏุซ ูุชุทูุจ ูุญุตูุง ุนุจุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ููู
ุนูููุฉ ุชุณุชุบุฑู ููุชูุง ุทูููุงู ุชุชุถูู ุชุญููู ููู ุชุดููุฑ ูู ููู ุตูุชู. ูููุฐุงุ ุงุฎุชุฑูุง ุชุฎุทู ูุฐู ุงูุฎุทูุฉ ููุง.

### ุชุถููู ุงููุชุญุฏุซ

ูุชูููู ูููุฐุฌ TTS ูู ุงูุชูููุฒ ุจูู ุนุฏุฉ ูุชุญุฏุซููุ ุณุชุญุชุงุฌ ุฅูู ุฅูุดุงุก ุชุถููู ูุชุญุฏุซ ููู ูุซุงู.
ุชุถููู ุงููุชุญุฏุซ ูู ุฅุฏุฎุงู ุฅุถุงูู ูู ุงููููุฐุฌ ุงูุฐู ููุชูุท ุฎุตุงุฆุต ุตูุช ูุชุญุฏุซ ูุนูู.
ูุฅูุดุงุก ูุฐู ุชุถูููุงุช ุงููุชุญุฏุซุ ุงุณุชุฎุฏู ุงููููุฐุฌ ุงููุฏุฑุจ ูุณุจููุง [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb)
ุงููููุฐุฌ ูู SpeechBrain.

ูู ุจุฅูุดุงุก ุฏุงูุฉ `create_speaker_embedding()` ุงูุชู ุชุฃุฎุฐ ููุฌุฉ ุตูุช ุฅุฏุฎุงู ูุชุฎุฑุฌ ูุชุฌููุง ูููููุง ูู 512 ุนูุตุฑูุง
ูุญุชูู ุนูู ุชุถููู ุงููุชุญุฏุซ ุงูููุงุจู.

```py
import os
import torch
from speechbrain.pretrained import EncoderClassifier

spk_model_name = "speechbrain/spkrec-xvect-voxceleb"

device = "cuda" if torch.cuda.is_available() else "cpu"
speaker_model = EncoderClassifier.from_hparams(
    source=spk_model_name,
    run_opts={"device": device},
    savedir=os.path.join("/tmp", spk_model_name),
)


def create_speaker_embedding(waveform):
    with torch.no_grad():
        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))
        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)
        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()
    return speaker_embeddings
```

ูู ุงูููู ููุงุญุธุฉ ุฃู ุงููููุฐุฌ `speechbrain/spkrec-xvect-voxceleb` ุชู ุชุฏุฑูุจู ุนูู ุงูููุงู ุงูุฅูุฌููุฒู ูู ูุฌููุนุฉ ุจูุงูุงุช VoxCeleb
ูู ุญูู ุฃู ุงูุฃูุซูุฉ ุงูุชุฏุฑูุจูุฉ ูู ูุฐุง ุงูุฏููู ูู ุจุงููุบุฉ ุงูููููุฏูุฉ. ุนูู ุงูุฑุบู ูู ุฃููุง ูุนุชูุฏ ุฃู ูุฐุง ุงููููุฐุฌ ุณูุธู ูููุฏ
ุชุถูููุงุช ุงููุชุญุฏุซ ูุนูููุฉ ููุฌููุนุฉ ุจูุงูุงุชูุง ุงูููููุฏูุฉุ ููุฏ ูุง ูููู ูุฐุง ุงูุงูุชุฑุงุถ ุตุญูุญูุง ูู ุฌููุน ุงูุญุงูุงุช.

ููุญุตูู ุนูู ูุชุงุฆุฌ ูุซููุ ุณูุญุชุงุฌ ุฅูู ุชุฏุฑูุจ ูููุฐุฌ X-vector ุนูู ุงูููุงู ุงููุณุชูุฏู ุฃููุงู. ูุฐุง ุณูุถูู ุฃู ุงููููุฐุฌ
ูุงุฏุฑ ุจุดูู ุฃูุถู ุนูู ุงูุชูุงุท ุฎุตุงุฆุต ุงูุตูุช ุงููุฑูุฏุฉ ุงูููุฌูุฏุฉ ูู ุงููุบุฉ ุงูููููุฏูุฉ. ุฅุฐุง ููุช ุชุฑุบุจ ูู ุชุฏุฑูุจ
ูููุฐุฌ X-vector ุงูุฎุงุต ุจูุ ููููู ุงุณุชุฎุฏุงู [ูุฐุง ุงููุต ุงูุจุฑูุฌู](https://huggingface.co/mechanicalsea/speecht5-vc/blob/main/manifest/utils/prep_cmu_arctic_spkemb.py)
ููุซุงู.

### ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช

ุฃุฎูุฑูุงุ ุฏุนูุง ูุนุงูุฌ ุงูุจูุงูุงุช ุฅูู ุงูุชูุณูู ุงูุฐู ูุชููุนู ุงููููุฐุฌ. ูู ุจุฅูุดุงุก ุฏุงูุฉ `prepare_dataset` ุงูุชู ุชุฃุฎุฐ
ูุซุงู ูุงุญุฏ ููุณุชุฎุฏู ูุงุฆู `SpeechT5Processor` ูุฑููุฒ ูุต ุงูุฅุฏุฎุงู ูุชุญููู ุงูุตูุช ุงููุณุชูุฏู ุฅูู ูุฎุทุท ุทููู ููุบุงุฑูุชูู.
ููุง ูุฌุจ ุฃู ุชุถูู ุชุถูููุงุช ุงููุชุญุฏุซ ูุฅุฏุฎุงู ุฅุถุงูู.

```py
def prepare_dataset(example):
    audio = example["audio"]

    example = processor(
        text=example["normalized_text"],
        audio_target=audio["array"],
        sampling_rate=audio["sampling_rate"],
        return_attention_mask=False,
    )

    # ุฅุฒุงูุฉ ุงูุจุนุฏ ุงูุฏูุนู
    example["labels"] = example["labels"][0]

    # ุงุณุชุฎุฏู SpeechBrain ููุญุตูู ุนูู x-vector
    example["speaker_embeddings"] = create_speaker_embedding(audio["array"])

    return example
```

ุชุญูู ูู ุตุญุฉ ุงููุนุงูุฌุฉ ูู ุฎูุงู ุงููุธุฑ ุฅูู ูุซุงู ูุงุญุฏ:

```py
processed_example = prepare_dataset(dataset[0])
list(processed_example.keys())
```

**ุงููุงุชุฌ:**
```out
['input_ids', 'labels', 'stop_labels', 'speaker_embeddings']
```

ูุฌุจ ุฃู ูููู ุชุถููู ุงููุชุญุฏุซ ูุชุฌููุง ูููููุง ูู 512 ุนูุตุฑูุง:

```py
processed_example["speaker_embeddings"].shape
```

**ุงููุงุชุฌ:**
```out
(512,)
```

ูุฌุจ ุฃู ุชููู ุงูุนูุงูุงุช ุนุจุงุฑุฉ ุนู ูุฎุทุท ุทููู ููุบุงุฑูุชูู ูุน 80 ุนูุจุฉ ููู.

```py
import matplotlib.pyplot as plt

plt.figure()
plt.imshow(processed_example["labels"].T)
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_logmelspectrogram_1.png" alt="ูุฎุทุท ุทููู ููุบุงุฑูุชูู ูุน 80 ุนูุจุฉ ููู"/>
</div>

ููุงุญุธุฉ ุฌุงูุจูุฉ: ุฅุฐุง ูุฌุฏุช ูุฐุง ุงููุฎุทุท ุงูุทููู ูุฑุจููุงุ ููุฏ ูููู ุฐูู ุจุณุจุจ ุฅููุงูู ุจุงุชูุงููุฉ ูุถุน ุงูุชุฑุฏุฏุงุช ุงูููุฎูุถุฉ
ูู ุงูุฃุณูู ูุงูุชุฑุฏุฏุงุช ุงูุนุงููุฉ ูู ุฃุนูู ุงููุฎุทุท. ููุน ุฐููุ ุนูุฏ ุฑุณู ุงููุฎุทุทุงุช ุงูุทูููุฉ ูุตูุฑุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ matplotlibุ
ูุชู ููุจ ูุญูุฑ ุงูุตุงุฏุงุช ูุชุธูุฑ ุงููุฎุทุทุงุช ุงูุทูููุฉ ููููุจุฉ.

ุงูุขู ูุญุชุงุฌ ุฅูู ุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง. ุณูุณุชุบุฑู ูุฐุง ูุง ุจูู 5 ู10 ุฏูุงุฆู.

```py
dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)
```

ุณุชุฑู ุชุญุฐูุฑูุง ูููู ุฅู ุจุนุถ ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฃุทูู ูู ุทูู ุงูุฅุฏุฎุงู ุงูุฃูุตู ุงูุฐู ูููู ูููููุฐุฌ ุงูุชุนุงูู ูุนู (600 ุฑูุฒ).
ูู ุจุฅุฒุงูุฉ ุชูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ููุง ูุฐูุจ ุฅูู ุฃุจุนุฏ ูู ุฐูู ูููุณูุงุญ ุจุฃุญุฌุงู ุฏูุนุงุช ุฃูุจุฑุ ูููู ุจุฅุฒุงูุฉ ุฃู ุดูุก ูุฒูุฏ ุนู 200 ุฑูุฒ.

```py
def is_not_too_long(input_ids):
    input_length = len(input_ids)
    return input_length < 200


dataset = dataset.filter(is_not_too_long, input_columns=["input_ids"])
len(dataset)
```

**ุงููุงุชุฌ:**
```out
8259
```

ุจุนุฏ ุฐููุ ูู ุจุฅูุดุงุก ุชูุณูู ุชุฏุฑูุจู/ุงุฎุชุจุงุฑู ุฃุณุงุณู:

```py
dataset = dataset.train_test_split(test_size=0.1)
```

### ุฌุงูุน ุงูุจูุงูุงุช

ูู ุฃุฌู ุฏูุฌ ุฃูุซูุฉ ูุชุนุฏุฏุฉ ูู ุฏูุนุฉุ ุชุญุชุงุฌ ุฅูู ุชุญุฏูุฏ ุฌุงูุน ุจูุงูุงุช ูุฎุตุต. ุณูููู ุฌุงูุน ุงูุจูุงูุงุช ูุฐุง ุจุชุนุจุฆุฉ ุงูุชุณูุณูุงุช ุงูุฃูุตุฑ ุจุฑููุฒ ุงูุชุนุจุฆุฉ
ุ ููุง ูุถูู ุฃู ูููู ูุฌููุน ุงูุฃูุซูุฉ ููุณ ุงูุทูู. ุจุงููุณุจุฉ ูุนูุงูุงุช ุงููุฎุทุท ุงูุทูููุ ูุชู ุงุณุชุจุฏุงู ุงูุฃุฌุฒุงุก ุงููุนุจุฃุฉ
ุจุงููููุฉ ุงูุฎุงุตุฉ `-100`. ูุฐู ุงููููุฉ ุงูุฎุงุตุฉ ุชูุนุฒ ูููููุฐุฌ ุจุชุฌุงูู ูุฐุง ุงูุฌุฒุก ูู ุงููุฎุทุท ุงูุทููู ุนูุฏ ุญุณุงุจ ุฎุณุงุฑุฉ ุงููุฎุทุท ุงูุทููู.

```py
from dataclasses import dataclass
from typing import Any, Dict, List, Union


@dataclass
class TTSDataCollatorWithPadding:
    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        input_ids = [{"input_ids": feature["input_ids"]} for feature in features]
        label_features = [{"input_values": feature["labels"]} for feature in features]
        speaker_features = [feature["speaker_embeddings"] for feature in features]

        # ุชุฌููุน ุงูุฅุฏุฎุงูุงุช ูุงูุฃูุฏุงู ูู ุฏูุนุฉ
        batch = processor.pad(
            input_ids=input_ids, labels=label_features, return_tensors="pt"
        )

        # ุงุณุชุจุฏุงู ุงูุชุนุจุฆุฉ ุจู -100 ูุชุฌุงูู ุงูุฎุณุงุฑุฉ ุจุดูู ุตุญูุญ
        batch["labels"] = batch["labels"].masked_fill(
            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100
        )

        # ุบูุฑ ูุณุชุฎุฏู ุฃุซูุงุก ุงูุถุจุท ุงูุฏููู
        del batch["decoder_attention_mask"]

        # ุชูุฑูุจ ุฃุทูุงู ุงููุฏู ูุฃุณูู ุฅูู ูุถุงุนู ุนุงูู ุงูุชุฎููุถ
        if model.config.reduction_factor > 1:
            target_lengths = torch.tensor(
                [len(feature["input_values"]) for feature in label_features]
            )
            target_lengths = target_lengths.new(
                [
                    length - length % model.config.reduction_factor
                    for length in target_lengths
                ]
            )
            max_length = max(target_lengths)
            batch["labels"] = batch["labels"][:, :max_length]

        # ุฃุถู ุฃูุถูุง ุชุถูููุงุช ุงููุชุญุฏุซ
        batch["speaker_embeddings"] = torch.tensor(speaker_features)

        return batch
```

ูู SpeechT5ุ ูุชู ุชูููู ุงูุฅุฏุฎุงู ูู ุงูุฌุฒุก ูู ุงูุชุฑููุฒ ูู ุงููููุฐุฌ ุจุนุงูู 2. ูุจุนุจุงุฑุฉ ุฃุฎุฑูุ ูุฅูู ูุชุฎูุต ูู ูู
ุฎุทูุฉ ุฒูููุฉ ุฃุฎุฑู ูู ุงูุชุณูุณู ุงููุณุชูุฏู. ุจุนุฏ ุฐููุ ูุชูุจุฃ ูู ุงูุชุฑููุฒ ุจุชุณูุณู ูููู ุถุนู ุงูุทูู. ูุธุฑูุง ูุฃู ุทูู ุงูุชุณูุณู ุงููุณุชูุฏู ุงูุฃุตูู ูุฏ ูููู ูุฑุฏููุงุ
ูุชุฃูุฏ ุฌุงูุน ุงูุจูุงูุงุช ูู ุชูุฑูุจ ุงูุทูู ุงูุฃูุตู ููุฏูุนุฉ ูุฃุณูู ููููู ูุถุงุนููุง ูู 2.

```py
data_collator = TTSDataCollatorWithPadding(processor=processor)
```

## ุชุฏุฑูุจ ุงููููุฐุฌ

ูู ุจุชุญููู ุงููููุฐุฌ ุงููุฏุฑุจ ูุณุจููุง ูู ููุณ ููุทุฉ ุงูุชูุชูุด ุงูุชู ุงุณุชุฎุฏูุชูุง ูุชุญููู ุงููุนุงูุฌ:

```py
from transformers import SpeechT5ForTextToSpeech

model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)
```
ุฎูุงุฑ `use_cache=True` ุบูุฑ ูุชูุงูู ูุน ุญูุธ ููุงุท ุงูุชุฏุฑุฌ. ูู ุจุชุนุทููู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูุฃุนุฏ ุชูุนูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ ููุฌูู ูุชุณุฑูุน ููุช ุงูุงุณุชุฏูุงู:

```py
from functools import partial

# ุชุนุทูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ ุจุณุจุจ ุนุฏู ุชูุงูููุง ูุน ุญูุธ ููุงุท ุงูุชุฏุฑุฌ
model.config.use_cache = False

# ุชุญุฏูุฏ ุงููุบุฉ ูุงูููุงู ููุฌูู ูุฅุนุงุฏุฉ ุชูุนูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ
model.generate = partial(model.generate, use_cache=True)
```

ูู ุจุชุนุฑูู ุญุฌุฌ ุงูุชุฏุฑูุจ. ููุงุ ูู ูููู ุจุญุณุงุจ ุฃู ููุงููุณ ุชูููู ุฃุซูุงุก ุนูููุฉ ุงูุชุฏุฑูุจุ ูุณูุชุญุฏุซ ุนู ุงูุชูููู ูุงุญูุงู ูู ูุฐุง ุงููุตู. ุจุฏูุงู ูู ุฐููุ ุณููุธุฑ ููุท ุฅูู ุงูุฎุณุงุฑุฉ:

```python
from transformers import Seq2SeqTrainingArguments

training_args = Seq2SeqTrainingArguments(
    output_dir="speecht5_finetuned_voxpopuli_nl"ุ  # ูู ุจุชุบููุฑู ุฅูู ุงุณู ูุณุชูุฏุน ูู ุงุฎุชูุงุฑู
    per_device_train_batch_size=4ุ
    gradient_accumulation_steps=8ุ
    learning_rate=1e-5ุ
    warmup_steps=500ุ
    max_steps=4000ุ
    gradient_checkpointing=Trueุ
    fp16=Trueุ
    evaluation_strategy="steps"ุ
    per_device_eval_batch_size=2ุ
    save_steps=1000ุ
    eval_steps=1000ุ
    logging_steps=25ุ
    report_to=["tensorboard"]ุ
    load_best_model_at_end=Trueุ
    greater_is_better=Falseุ
    label_names=["labels"]ุ
    push_to_hub=Trueุ
)
```

ูู ุจุฅูุดุงุก ูุงุฆู ุงููุฏุฑุจ `Trainer` ููุฑุฑ ุฅููู ุงููููุฐุฌุ ููุฌููุนุฉ ุงูุจูุงูุงุชุ ููุฌููุน ุงูุจูุงูุงุช.

```py
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    args=training_args,
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator,
    tokenizer=processor,
)
```

ูุจุฐููุ ูููู ุฌุงูุฒูู ูุจุฏุก ุงูุชุฏุฑูุจ! ุณูุณุชุบุฑู ุงูุชุฏุฑูุจ ุนุฏุฉ ุณุงุนุงุช. ุงุนุชูุงุฏุงู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงูุฎุงุตุฉ ุจูุ ูู ุงููููู ุฃู ุชูุงุฌู ุฎุทุฃ "ููุงุฏ ุงูุฐุงูุฑุฉ" ูู CUDA ุนูุฏ ุจุฏุก ุงูุชุฏุฑูุจ. ูู ูุฐู ุงูุญุงูุฉุ ููููู ุชูููู `per_device_train_batch_size` ุชุฏุฑูุฌูุงู ุจุนูุงูู 2 ูุฒูุงุฏุฉ `gradient_accumulation_steps` ุจููุฏุงุฑ 2x ููุชุนููุถ.

```py
trainer.train()
```

ูู ุจุฏูุน ุงููููุฐุฌ ุงูููุงุฆู ุฅูู ููุตุฉ ๐ค Hub:

```py
trainer.push_to_hub()
```

## ุงูุงุณุชุฏูุงู

ุจูุฌุฑุฏ ุถุจุท ูููุฐุฌุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชุฏูุงู! ูู ุจุชุญููู ุงููููุฐุฌ ูู ููุตุฉ ๐ค Hub (ุชุฃูุฏ ูู ุงุณุชุฎุฏุงู ุงุณู ุญุณุงุจู ูู ููุชุทู ุงูููุฏ ุงูุชุงูู):

```py
model = SpeechT5ForTextToSpeech.from_pretrained(
    "YOUR_ACCOUNT/speecht5_finetuned_voxpopuli_nl"
)
```

ุงุฎุชุฑ ูุซุงูุงูุ ููุง ุณูุฃุฎุฐ ูุซุงูุงู ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ. ุงุญุตู ุนูู ุชุถููู ุงููุชุญุฏุซ.

```py
example = dataset["test"][304]
speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)
```

ูู ุจุชุนุฑูู ูุต ุงูุฅุฏุฎุงู ููู ุจุชูุณููู ุฅูู ุฑููุฒ.

```py
text = "hallo allemaal, ik praat nederlands. groetjes aan iedereen!"
```

ูู ุจูุนุงูุฌุฉ ูุต ุงูุฅุฏุฎุงู:

```py
inputs = processor(text=text, return_tensors="pt")
```

ูู ุจุฅูุดุงุก ุฌูุงุฒ ุชูููู ุงูููุงู ูุชูููุฏ ุงูููุงู:

```py
from transformers import SpeechT5HifiGan

vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)
```

ูู ุฃูุช ูุณุชุนุฏ ููุงุณุชูุงุน ุฅูู ุงููุชูุฌุฉุ

```py
from IPython.display import Audio

Audio(speech.numpy(), rate=16000)
```

ูุฏ ูููู ุงูุญุตูู ุนูู ูุชุงุฆุฌ ูุฑุถูุฉ ูู ูุฐุง ุงููููุฐุฌ ุนูู ูุบุฉ ุฌุฏูุฏุฉ ุฃูุฑุงู ุตุนุจุงู. ูููู ุฃู ุชููู ุฌูุฏุฉ ุชุถููู ุงููุชุญุฏุซ ุนุงููุงู ูููุงู. ุญูุซ ุฃู SpeechT5 ุชู ุชุฏุฑูุจู ูุณุจูุงู ุจุงุณุชุฎุฏุงู x-vectors ุงูุฅูุฌููุฒูุฉุ ููู ูุนูู ุจุดูู ุฃูุถู ุนูุฏ ุงุณุชุฎุฏุงู ุชุถููู ุงููุชุญุฏุซ ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ. ุฅุฐุง ูุงู ุงูููุงู ุงูููุตููุน ูุจุฏู ุฑุฏูุฆุงูุ ุญุงูู ุงุณุชุฎุฏุงู ุชุถููู ูุชุญุฏุซ ูุฎุชูู.

ูู ุงููุฑุฌุญ ุฃู ูุคุฏู ุฒูุงุฏุฉ ูุฏุฉ ุงูุชุฏุฑูุจ ุฅูู ุชุญุณูู ุฌูุฏุฉ ุงููุชุงุฆุฌ ุฃูุถุงู. ููุน ุฐููุ ูู ุงููุงุถุญ ุฃู ุงูููุงู ุจุงููุบุฉ ุงูููููุฏูุฉ ุจุฏูุงู ูู ุงูุฅูุฌููุฒูุฉุ ููุณุชุทูุน ุงูุชูุงุท ุฎุตุงุฆุต ุตูุช ุงููุชุญุฏุซ (ูุงุฑู ูุน ุงูุตูุช ุงูุฃุตูู ูู ุงููุซุงู).

ููุงู ุดูุก ุขุฎุฑ ูููู ุชุฌุฑุจุชู ููู ุชูููู ุงููููุฐุฌ. ุนูู ุณุจูู ุงููุซุงูุ ุฌุฑุจ ุงุณุชุฎุฏุงู `config.reduction_factor = 1` ููุนุฑูุฉ ูุง ุฅุฐุง ูุงู ูุฐุง ูุญุณู ุงููุชุงุฆุฌ.

ูู ุงููุณู ุงูุชุงููุ ุณูุชุญุฏุซ ุนู ููููุฉ ุชูููู ููุงุฐุฌ ุชุญููู ุงููุต ุฅูู ููุงู.
