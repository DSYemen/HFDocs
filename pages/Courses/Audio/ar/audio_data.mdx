# مقدمة لبيانات الصوت

بطبيعتها، الموجة الصوتية هي إشارة مستمرة، مما يعني أنها تحتوي على عدد لانهائي من قيم الإشارة في وقت معين.
هذا يطرح مشاكل للأجهزة الرقمية التي تتوقع مصفوفات محدودة. ليتم معالجتها وتخزينها ونقلها بواسطة الأجهزة
الرقمية، تحتاج الموجة الصوتية المستمرة إلى تحويلها إلى سلسلة من القيم المنفصلة، والمعروفة بالتمثيل الرقمي.

إذا نظرت إلى أي مجموعة بيانات صوتية، ستجد ملفات رقمية بمقتطفات صوتية، مثل السرد النصي أو الموسيقى.
قد تصادف تنسيقات ملفات مختلفة مثل `.wav` (ملف صوتي بتنسيق موجي) و `.flac` (ترميز صوتي حر بدون فقدان)
و `.mp3` (الطبقة الصوتية 3 MPEG-1). تختلف هذه التنسيقات بشكل أساسي في كيفية ضغطها للتمثيل الرقمي لإشارة الصوت.

دعنا نلقي نظرة على كيفية وصولنا من إشارة مستمرة إلى هذا التمثيل. يتم التقاط الإشارة التناظرية أولاً بواسطة
ميكروفون، والذي يحول الموجات الصوتية إلى إشارة كهربائية. ثم يتم تحويل الإشارة الكهربائية إلى إشارة رقمية بواسطة
محول تناظري إلى رقمي للحصول على التمثيل الرقمي من خلال المعاينة.

## المعاينة ومعدل المعاينة

المعاينة هي عملية قياس قيمة إشارة مستمرة في خطوات زمنية ثابتة. الموجة المعاينة هي _منفصلة_،
حيث تحتوي على عدد محدود من قيم الإشارة على فترات منتظمة.

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/Signal_Sampling.png" alt="توضيح المعاينة">
</div>

*توضيح من مقالة ويكيبيديا: [المعاينة (معالجة الإشارة)](https://en.wikipedia.org/wiki/Sampling_(signal_processing))*

**معدل المعاينة** (يسمى أيضًا تردد المعاينة) هو عدد العينات المأخوذة في ثانية واحدة ويقاس
بالهرتز (Hz). لإعطائك نقطة مرجعية، فإن الصوت بجودة قرص مضغوط له معدل معاينة يبلغ 44,100 هرتز، مما يعني أن العينات تؤخذ
44,100 مرة في الثانية. للمقارنة، فإن الصوت عالي الدقة له معدل معاينة يبلغ 192,000 هرتز أو 192 كيلو هرتز. معدل المعاينة الشائع
المستخدم في تدريب نماذج الكلام هو 16,000 هرتز أو 16 كيلو هرتز.

يحدد اختيار معدل المعاينة بشكل أساسي أعلى تردد يمكن التقاطه من الإشارة. وهذا ما يسمى أيضًا
حد نايكويست وهو بالضبط نصف معدل المعاينة. الترددات المسموعة في الكلام البشري أقل من 8 كيلو هرتز
لذلك فإن معاينة الكلام عند 16 كيلو هرتز كافية. لن يؤدي استخدام معدل معاينة أعلى إلى التقاط المزيد من المعلومات
ويؤدي فقط إلى زيادة التكلفة الحسابية لمعالجة مثل هذه الملفات. من ناحية أخرى، فإن معاينة الصوت بمعدل
معدل معاينة منخفض للغاية سيؤدي إلى فقدان المعلومات. سيبدو الكلام المعاين عند 8 كيلو هرتز مكتومًا، حيث لا يمكن التقاط الترددات العالية
بهذا المعدل.

من المهم التأكد من أن جميع الأمثلة الصوتية في مجموعة بياناتك لها نفس معدل المعاينة عند العمل على أي مهمة صوتية.
إذا كنت تخطط لاستخدام بيانات صوتية مخصصة لضبط نموذج مسبق التدريب، يجب أن يتطابق معدل معاينة بياناتك
مع معدل معاينة البيانات التي تم تدريب النموذج مسبقًا عليها. يحدد معدل المعاينة الفاصل الزمني بين العينات الصوتية المتتالية،
والذي يؤثر على الدقة الزمنية لبيانات الصوت. خذ على سبيل المثال: صوت مدته 5 ثوانٍ بمعدل معاينة يبلغ 16,000 هرتز
سيتم تمثيله على أنه سلسلة من 80,000 قيمة، في حين أن نفس الصوت الذي مدته 5 ثوانٍ بمعدل معاينة يبلغ 8,000 هرتز
سيتم تمثيله على أنه سلسلة من 40,000 قيمة. تعامل نماذج المحول التي تحل المهام الصوتية الأمثلة على أنها
تسلسلات وتعتمد على آليات الانتباه لتعلم التمثيل الصوتي أو متعدد الوسائط. نظرًا لأن التسلسلات تختلف للصوت
الأمثلة بمعدلات معاينة مختلفة، سيكون من الصعب على النماذج التعميم بين معدلات المعاينة.
**إعادة المعاينة** هي عملية مطابقة معدلات المعاينة، وهي جزء من [معالجة مسبقة](preprocessing#resampling-the-audio-data) لبيانات الصوت.

## الشدة وعمق البت

بينما يخبرك معدل المعاينة عن مدى تكرار أخذ العينات، ما هي القيم الموجودة في كل عينة بالضبط؟

يتم إنشاء الصوت عن طريق التغييرات في ضغط الهواء بترددات يمكن للإنسان سماعها. **شدة** الصوت تصف
مستوى ضغط الصوت في أي لحظة معينة ويقاس بالديسيبل (ديسيبل). ندرك الشدة على أنها ارتفاع الصوت.
لإعطائك مثالاً، فإن صوت التحدث العادي أقل من 60 ديسيبل، ويمكن أن يصل صوت حفل موسيقي صاخب إلى حوالي 125 ديسيبل، مما يدفع
حدود السمع البشري.

في الصوت الرقمي، يسجل كل عينة صوتية شدة موجة الصوت في نقطة زمنية. **عمق البت** للعينة
يحدد بدقة هذه القيمة الشدة التي يمكن وصفها. كلما زاد عمق البت، كلما كان التمثيل الرقمي
يقترب من الموجة الصوتية المستمرة الأصلية.

أعماق البت الصوتية الأكثر شيوعًا هي 16 بت و 24 بت. كل منها مصطلح ثنائي، يمثل عدد الخطوات المحتملة
التي يمكن تحويل قيمة الشدة إليها عند تحويلها من مستمر إلى منفصل: 65,536 خطوة للصوت 16 بت،
24 بت، خطوات مذهلة تبلغ 16,777,216 خطوة. لأن التحويل إلى أرقام صحيحة ينطوي على تقريب القيمة المستمرة إلى قيمة منفصلة
، فإن عملية المعاينة تُدخل ضوضاء. كلما زاد عمق البت، كلما صغرت هذه الضوضاء الكمية. في الممارسة العملية،
ضوضاء التحويل إلى أرقام صحيحة للصوت 16 بت صغيرة بالفعل لدرجة أنها غير مسموعة، واستخدام أعماق بت أعلى
غير ضروري بشكل عام.

قد تصادف أيضًا صوت 32 بت. يقوم هذا بتخزين العينات كقيم ذات فاصلة عائمة، في حين أن الصوت 16 بت و 24 بت
يستخدم عينات صحيحة. دقة قيمة الفاصلة العائمة 32 بت هي 24 بت، مما يعطيها نفس عمق البت مثل الصوت 24 بت.
من المتوقع أن تكون عينات الصوت ذات الفاصلة العائمة ضمن النطاق [-1.0, 1.0]. نظرًا لأن نماذج التعلم الآلي تعمل بشكل طبيعي
على بيانات الفاصلة العائمة، يجب تحويل الصوت أولاً إلى تنسيق الفاصلة العائمة قبل استخدامه لتدريب
النموذج. سنرى كيفية القيام بذلك في القسم التالي حول [معالجة مسبقة](preprocessing).

تماماً مثل إشارات الصوت المستمرة، يتم التعبير عن شدة الصوت الرقمي عادةً بالديسيبل (ديسيبل). نظرًا لأن
السمع البشري هو لوغاريتمي في الطبيعة - أذننا أكثر حساسية للتقلبات الصغيرة في الأصوات الهادئة من الأصوات العالية
- من الأسهل تفسير ارتفاع الصوت إذا كانت الشدات بالديسيبل، والتي تكون أيضًا لوغاريتمية.
يبدأ مقياس الديسيبل للصوت في العالم الحقيقي عند 0 ديسيبل، والذي يمثل أخف صوت يمكن للإنسان سماعه، والأصوات الأعلى لها قيم أكبر.
ومع ذلك، بالنسبة لإشارات الصوت الرقمية، فإن 0 ديسيبل هو أعلى شدة ممكنة، في حين أن جميع
الشدة الأخرى سلبية. كقاعدة عامة: كل -6 ديسيبل هو نصف الشدة، وأي شيء أقل من -60 ديسيبل
غير مسموع بشكل عام ما لم تقم برفع مستوى الصوت.

## الصوت كموجة

قد تكون رأيت الأصوات مرئية كـ **موجة**، والتي ترسم قيم العينات بمرور الوقت وتوضح التغييرات
في شدة الصوت. هذا ما يسمى أيضًا تمثيل *مجال الوقت* للصوت.

هذا النوع من التصور مفيد لتحديد ميزات محددة لإشارة الصوت مثل توقيت أحداث الصوت الفردية،
شدة الإشارة الإجمالية، وأي مخالفات أو ضوضاء موجودة في الصوت.

لرسم الموجة لإشارة صوتية، يمكننا استخدام مكتبة بايثون تسمى `librosa`:

```bash
pip install librosa
```

دعنا نأخذ مثالًا صوتيًا يسمى "trumpet" يأتي مع المكتبة:

```py
import librosa

array, sampling_rate = librosa.load(librosa.ex("trumpet"))
```

يتم تحميل المثال كمجموعة من السلاسل الزمنية الصوتية (هنا نسميها `array`)، ومعدل المعاينة (`sampling_rate`).
دعنا نلقي نظرة على موجة هذا الصوت باستخدام دالة `waveshow()` في مكتبة `librosa`:

```py
import matplotlib.pyplot as plt
import librosa.display

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```
<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/waveform_plot.png" alt="رسم بياني للموجة">
</div>

هذا الرسم البياني يمثل سعة الإشارة على المحور الرأسي والزمن على المحور الأفقي. وبعبارة أخرى، كل نقطة تقابل
قيمة عينة واحدة تم أخذها عندما تم أخذ عينة من هذا الصوت. لاحظ أيضًا أن مكتبة ليبروسا (librosa) تعيد الصوت كـ
قيم ذات فاصلة عائمة بالفعل، وأن قيم السعة تقع بالفعل ضمن النطاق [-1.0, 1.0].

يمكن أن تكون عملية تصور الصوت إلى جانب الاستماع إليه أداة مفيدة لفهم البيانات التي تعمل عليها.
يمكنك رؤية شكل الإشارة، ومراقبة الأنماط، وتعلم كيفية اكتشاف الضوضاء أو التشوه. إذا قمت بمعالجة البيانات بشكل ما،
مثل التطبيع أو إعادة أخذ العينات أو التصفية، فيمكنك التأكد بصريًا من تطبيق خطوات المعالجة المسبقة كما هو متوقع.
بعد تدريب نموذج، يمكنك أيضًا تصور العينات التي تحدث فيها الأخطاء (على سبيل المثال، في مهمة تصنيف الصوت) لتصحيح
المشكلة.

## الطيف الترددي

طريقة أخرى لتصور البيانات الصوتية هي رسم **الطيف الترددي** لإشارة صوتية، والمعروف أيضًا بتمثيل *مجال التردد*. يتم حساب الطيف باستخدام
التحويل المتقطع فورييه (DFT). يصف الترددات الفردية
التي تشكل الإشارة وقوتها.

دعنا نرسم الطيف الترددي لنفس صوت البوق عن طريق أخذ التحويل المتقطع فورييه (DFT) باستخدام دالة `rfft()` في مكتبة نومبي (numpy). على الرغم من أنه
من الممكن رسم طيف الصوت بالكامل، إلا أنه من المفيد أكثر النظر إلى منطقة صغيرة بدلاً من ذلك. هنا سنأخذ
التحويل المتقطع فورييه (DFT) على أول 4096 عينة، وهو تقريبًا طول النغمة الأولى التي يتم عزفها:

```py
import numpy as np

dft_input = array[:4096]

# حساب التحويل المتقطع فورييه (DFT)
window = np.hanning(len(dft_input))
windowed_input = dft_input * window
dft = np.fft.rfft(windowed_input)

# الحصول على طيف السعة بالديسيبل
amplitude = np.abs(dft)
amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)

# الحصول على حاويات التردد
frequency = librosa.fft_frequencies(sr=sampling_rate, n_fft=len(dft_input))

plt.figure().set_figwidth(12)
plt.plot(frequency, amplitude_db)
plt.xlabel("Frequency (Hz)")
plt.ylabel("Amplitude (dB)")
plt.xscale("log")
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/spectrum_plot.png" alt="رسم بياني للطيف">
</div>

هذا الرسم البياني يمثل قوة مكونات التردد المختلفة الموجودة في هذا الجزء من الصوت. قيم التردد على
المحور الأفقي، وعادة ما يتم رسمها على مقياس لوغاريتمي، في حين أن سعاتها على المحور الرأسي.

الطيف الترددي الذي رسمناه يظهر عدة قمم. هذه القمم تقابل التوافقيات للنغمة التي يتم
عزفها، مع كون التوافقيات الأعلى أكثر هدوءًا. بما أن القمة الأولى تقع عند حوالي 620 هرتز، فإن هذا هو الطيف الترددي لنغمة مي بيمول.

الناتج من التحويل المتقطع فورييه (DFT) هو مصفوفة من الأعداد المركبة، تتكون من مكونات حقيقية وتخيلية. أخذ
المقدار باستخدام `np.abs(dft)` يستخرج معلومات السعة من المخطط الطيفي. الزاوية بين المكونات الحقيقية والتخيلية توفر ما يسمى
بالطيف الطوري، ولكن يتم تجاهله غالبًا في تطبيقات التعلم الآلي.

استخدمت دالة `librosa.amplitude_to_db()` لتحويل قيم السعة إلى مقياس الديسيبل، مما يجعل من السهل رؤية
التفاصيل الدقيقة في الطيف. يستخدم بعض الأشخاص **الطيف القوي**، والذي يقيس الطاقة بدلاً من السعة؛
هذا ببساطة طيف مع قيم السعة مربعة.

<Tip>
💡 في الممارسة العملية، يستخدم الناس مصطلح FFT بشكل متبادل مع DFT، حيث أن FFT أو التحويل السريع فورييه هو الطريقة الوحيدة الفعالة
لحساب التحويل المتقطع فورييه (DFT) على الكمبيوتر.
</Tip>

الطيف الترددي لإشارة صوتية يحتوي على نفس المعلومات تمامًا مثل شكل الموجة الخاص بها - إنها ببساطة طريقتان مختلفتان
للنظر إلى نفس البيانات (هنا، أول 4096 عينة من صوت البوق). حيث يرسم شكل الموجة سعة
إشارة الصوت على مدار الزمن، فإن الطيف يصور سعات الترددات الفردية في نقطة زمنية ثابتة.

## المخطط الطيفي

ماذا لو أردنا أن نرى كيف تتغير الترددات في إشارة صوتية؟ يعزف البوق عدة نغمات ولديها جميعًا
ترددات مختلفة. المشكلة هي أن الطيف يظهر فقط لقطة مجمدة للترددات في لحظة معينة.
الحل هو أخذ عدة تحويلات متقطعة فورييه (DFTs)، كل منها يغطي فقط شريحة زمنية صغيرة، وتكديس الطيف الناتج معًا
في **مخطط طيفي**.

المخطط الطيفي يرسم المحتوى الترددي لإشارة صوتية كما يتغير مع الزمن. يسمح لك برؤية الزمن والتردد والسعة
جميعها على رسم بياني واحد. الخوارزمية التي تقوم بهذا الحساب هي STFT أو التحويل فورييه قصير المدى.

المخطط الطيفي هو أحد أكثر الأدوات الصوتية المعلوماتية المتاحة لك. على سبيل المثال، عند العمل مع تسجيل موسيقي،
يمكنك رؤية الآلات المختلفة والمسارات الصوتية وكيف تساهم في الصوت العام. في الكلام، يمكنك
تحديد أصوات حروف العلة المختلفة حيث يتم تمييز كل حرف علة بترددات معينة.

دعنا نرسم مخططًا طيفيًا لنفس صوت البوق، باستخدام دالتَي `stft()` و `specshow()` في مكتبة ليبروسا (librosa):

```py
import numpy as np

D = librosa.stft(array)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_db, x_axis="time", y_axis="hz")
plt.colorbar()
```
```
```
<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/spectrogram_plot.png" alt="مخطط طيفي">
</div>

في هذا المخطط، يمثل المحور السيني الوقت كما في تصور الموجة، ولكن الآن يمثل المحور الصادي التردد بالهرتز.
تكشف شدة اللون عن سعة أو قوة المكون الترددي في كل نقطة زمنية، مقاسة بالديسيبل (dB).

يتم إنشاء المخطط الطيفي عن طريق أخذ مقاطع قصيرة من الإشارة الصوتية، عادة ما تستمر لعدة مللي ثانية، وحساب
التحويل المتقطع فورييه لكل مقطع للحصول على طيفه الترددي. ثم يتم تكديس الطيف الناتج
معًا على المحور الزمني لإنشاء المخطط الطيفي. كل شريحة عمودية في هذه الصورة تقابل طيف تردد واحد
، كما يُرى من الأعلى. بشكل افتراضي، يقسم `librosa.stft()` إشارة الصوت إلى مقاطع من 2048 عينة، مما
يعطي توازنًا جيدًا بين دقة التردد ودقة الوقت.

بما أن المخطط الطيفي والموجة هما وجهان مختلفان لنفس البيانات، فمن الممكن تحويل المخطط الطيفي مرة أخرى
إلى الموجة الأصلية باستخدام STFT العكسي. ومع ذلك، يتطلب هذا معلومات الطور بالإضافة إلى معلومات السعة.
إذا تم إنشاء المخطط الطيفي بواسطة نموذج تعلم آلي، فإنه عادةً ما يخرج السعات فقط. في
تلك الحالة، يمكننا استخدام خوارزمية إعادة بناء الطور مثل خوارزمية Griffin-Lim الكلاسيكية، أو باستخدام شبكة عصبية
تسمى vocoder، لإعادة بناء الموجة من المخطط الطيفي.

لا تُستخدم المخططات الطيفية للتصور فقط. العديد من نماذج التعلم الآلي ستأخذ المخططات الطيفية كمدخلات - على عكس
الموجات - وتنتج مخططات طيفية كناتج.

الآن بعد أن عرفنا ما هو المخطط الطيفي وكيف يتم إنشاؤه، دعنا نلقي نظرة على أحد تنوعاته المستخدمة على نطاق واسع في معالجة الكلام: المخطط الطيفي ميل.

## المخطط الطيفي ميل

المخطط الطيفي ميل هو تباين للمخطط الطيفي الذي يستخدم عادة في معالجة الكلام ومهام التعلم الآلي.
يشبه المخطط الطيفي في أنه يظهر المحتوى الترددي لإشارة صوتية بمرور الوقت، ولكن على محور تردد مختلف.

في المخطط الطيفي القياسي، يكون محور التردد خطيًا ويقاس بالهرتز (Hz). ومع ذلك، فإن النظام السمعي البشري
أكثر حساسية للتغيرات في الترددات المنخفضة مقارنة بالترددات العالية، وتقل هذه الحساسية بشكل لوغاريتمي
مع زيادة التردد. مقياس ميل هو مقياس إدراكي يقارب استجابة التردد غير الخطية للأذن البشرية.

لإنشاء مخطط طيفي ميل، يتم استخدام STFT كما هو الحال من قبل، عن طريق تقسيم الصوت إلى مقاطع قصيرة للحصول على تسلسل
من الطيف الترددي. بالإضافة إلى ذلك، يتم إرسال كل طيف عبر مجموعة من المرشحات، ما يسمى بنك مرشحات ميل،
لتحويل الترددات إلى مقياس ميل.

دعنا نرى كيف يمكننا رسم مخطط طيفي ميل باستخدام دالة `melspectrogram()` في مكتبة ليبروسا، والتي تقوم بجميع هذه الخطوات من أجلنا:

```py
S = librosa.feature.melspectrogram(y=array, sr=sampling_rate, n_mels=128, fmax=8000)
S_dB = librosa.power_to_db(S, ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_dB, x_axis="time", y_axis="mel", sr=sampling_rate, fmax=8000)
plt.colorbar()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/mel-spectrogram.png" alt="مخطط طيفي ميل">
</div>


في المثال أعلاه، `n_mels` يمثل عدد نطاقات ميل المطلوب إنشاؤها. نطاقات ميل تحدد مجموعة من نطاقات التردد
التي تقسم الطيف إلى مكونات ذات معنى إدراكي، باستخدام مجموعة من المرشحات التي يتم اختيار شكلها ومسافاتها
لتحاكي طريقة استجابة الأذن البشرية لترددات مختلفة. القيم الشائعة لـ `n_mels` هي 40 أو 80. `fmax`
يشير إلى أعلى تردد (بالهرتز) الذي نهتم به.

كما هو الحال مع المخطط الطيفي العادي، من الشائع التعبير عن قوة مكونات تردد ميل
بالديسيبل. ويشار إلى هذا عادة باسم **مخطط طيفي ميل لوغاريتمي**، لأن التحويل إلى ديسيبل يتضمن عملية لوغاريتمية. المثال أعلاه استخدم `librosa.power_to_db()` لأن `librosa.feature.melspectrogram()` ينشئ مخطط طيفي للقوة.

<Tip>
💡 ليس كل المخططات الطيفية ميل متشابهة! هناك مقياسان مختلفان لميل قيد الاستخدام الشائع ("htk" و "slaney")،
وبدلاً من مخطط طيفي القوة، يمكن استخدام مخطط طيفي السعة. التحويل إلى مخطط طيفي ميل لوغاريتمي لا
يحسب دائمًا الديسيبل الحقيقي ولكن قد يأخذ ببساطة اللوغاريتم `log`. لذلك، إذا كان نموذج التعلم الآلي يتوقع مخطط طيفي ميل
كمدخل، تأكد مرتين من أنك تحسبه بنفس الطريقة.
</Tip>

إنشاء مخطط طيفي ميل هو عملية فاقدة للمعلومات لأنه ينطوي على تصفية الإشارة. تحويل مخطط طيفي ميل مرة أخرى
إلى موجة أكثر صعوبة من القيام بذلك لمخطط طيفي عادي، حيث يتطلب تقدير الترددات
التي تم التخلص منها. هذا هو السبب في أن نماذج التعلم الآلي مثل HiFiGAN vocoder مطلوبة لإنتاج موجة من مخطط طيفي ميل.

مقارنة بالمخطط الطيفي القياسي، يمكن للمخطط الطيفي ميل التقاط ميزات أكثر دلالة للإشارة الصوتية
للإدراك البشري، مما يجعله خيارًا شائعًا في مهام مثل التعرف على الكلام، وتحديد المتحدث، وتصنيف نوع الموسيقى.

الآن بعد أن تعلمت كيفية تصور أمثلة بيانات صوتية، يمكنك المضي قدمًا ومحاولة رؤية كيف تبدو أصواتك المفضلة. :)
