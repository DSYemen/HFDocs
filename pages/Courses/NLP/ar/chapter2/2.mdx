<FrameworkSwitchCourse {fw} />

# ุฎูู ุงูููุงููุณ[[behind-the-pipeline]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb"},
]} />

{/if}

<Tip>
ูุฐุง ูู ุงููุณู ุงูุฃูู ุงูุฐู ูุฎุชูู ููู ุงููุญุชูู ููููุงู ุจูุงุกู ุนูู ูุง ุฅุฐุง ููุช ุชุณุชุฎุฏู PyTorch ุฃู TensorFlow. ูู ุจุงูุชุจุฏูู ุจูู ุงูุฎูุงุฑุงุช ูู ุงูุฃุนูู ูุงุฎุชูุงุฑ ุงูููุตุฉ ุงูุชู ุชูุถููุง!
</Tip>

{#if fw === 'pt'}
<Youtube id="1pedAIvTWXk"/>
{:else}
<Youtube id="wVN12smEvqg"/>
{/if}

ุฏุนููุง ูุจุฏุฃ ุจูุซุงู ูุงููุ ููููู ูุธุฑุฉ ุนูู ูุง ุญุฏุซ ุฎูู ุงูููุงููุณ ุนูุฏูุง ูููุง ุจุชูููุฐ ุงูููุฏ ุงูุชุงูู ูู [ุงููุตู 1](/course/chapter1):

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)
```

ูุญุตููุง ุนูู:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

ููุง ุฑุฃููุง ูู [ุงููุตู 1](/course/chapter1)ุ ูุฅู ูุฐุง ุงูุฃูุจูุจ ูุฌูุน ุจูู ุซูุงุซ ุฎุทูุงุช: ูุง ูุจู ุงููุนุงูุฌุฉุ ูุฅุฏุฎุงู ุงููุฏุฎูุงุช ุนุจุฑ ุงููููุฐุฌุ ููุง ุจุนุฏ ุงููุนุงูุฌุฉ:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="ุฃูุจูุจ NLP ุงููุงูู: ุชูุณูู ุงููุต ุฅูู ุฑููุฒุ ูุชุญูููู ุฅูู ูุนุฑูุงุชุ ูุงููุฑูุฑ ุนุจุฑ ูููุฐุฌ Transformer ูุฑุฃุณ ุงููููุฐุฌ."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg" alt="ุฃูุจูุจ NLP ุงููุงูู: ุชูุณูู ุงููุต ุฅูู ุฑููุฒุ ูุชุญูููู ุฅูู ูุนุฑูุงุชุ ูุงููุฑูุฑ ุนุจุฑ ูููุฐุฌ Transformer ูุฑุฃุณ ุงููููุฐุฌ."/>
</div>

ุฏุนููุง ูููู ูุธุฑุฉ ุณุฑูุนุฉ ุนูู ูู ูู ูุฐู ุงูุฎุทูุงุช.

## ูุง ูุจู ุงููุนุงูุฌุฉ ุจุงุณุชุฎุฏุงู ุงููุนุงูุฌ ุงููุบูู[[preprocessing-with-a-tokenizer]]

ูุซู ุงูุดุจูุงุช ุงูุนุตุจูุฉ ุงูุฃุฎุฑูุ ูุง ูููู ูููุงุฐุฌ Transformer ูุนุงูุฌุฉ ุงููุต ุงูุฎุงู ูุจุงุดุฑุฉุ ูุฐูู ูุฅู ุงูุฎุทูุฉ ุงูุฃููู ูู ุฃูุจูุจูุง ูู ุชุญููู ุฅุฏุฎุงูุงุช ุงููุต ุฅูู ุฃุฑูุงู ูููู ูููููุฐุฌ ููููุง. ููููุงู ุจุฐููุ ูุณุชุฎุฏู *ูุนุงูุฌูุง ูุบูููุง*ุ ูุงูุฐู ุณูููู ูุณุคููุงู ุนู:

- ุชูุณูู ุงูุฅุฏุฎุงู ุฅูู ูููุงุชุ ุฃู ุฑููุฒ ูุฑุนูุฉุ ุฃู ุฑููุฒ (ูุซู ุนูุงูุงุช ุงูุชุฑููู) ูุงูุชู ุชุณูู *ุฑููุฒ*
- ุชุนููู ูู ุฑูุฒ ุฅูู ุนุฏุฏ ุตุญูุญ
- ุฅุถุงูุฉ ุฅุฏุฎุงูุงุช ุฅุถุงููุฉ ูุฏ ุชููู ูููุฏุฉ ูููููุฐุฌ

ูุฌุจ ุฅุฌุฑุงุก ูู ูุฐู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุจููุณ ุงูุทุฑููุฉ ุชูุงููุง ููุง ุชู ุนูุฏ ุงูุชุฏุฑูุจ ุงููุณุจู ูููููุฐุฌุ ูุฐูู ูุญุชุงุฌ ุฃููุงู ุฅูู ุชูุฒูู ุชูู ุงููุนูููุงุช ูู [ูุฑูุฒ ุงูููุงุฐุฌ](https://huggingface.co/models). ููููุงู ุจุฐููุ ูุณุชุฎุฏู ูุฆุฉ `AutoTokenizer` ูุทุฑููุชูุง `from_pretrained()`. ุจุงุณุชุฎุฏุงู ุงุณู ููุทุฉ ุงูุชุญูู ููููุฐุฌูุงุ ุณูููู ุชููุงุฆููุง ุจุฌูุจ ุงูุจูุงูุงุช ุงููุฑุชุจุทุฉ ุจูุนุงูุฌ ุงููููุฐุฌ ูุชุฎุฒูููุง ูุคูุชูุง (ูุฐูู ูุชู ุชูุฒูููุง ููุท ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชููู ูููุง ุจุชุดุบูู ุงูููุฏ ุฃุฏูุงู).

ูุธุฑูุง ูุฃู ููุทุฉ ุงูุชุญูู ุงูุงูุชุฑุงุถูุฉ ูุฃูุจูุจ `sentiment-analysis` ูู `distilbert-base-uncased-finetuned-sst-2-english` (ููููู ุงูุงุทูุงุน ุนูู ุจุทุงูุฉ ุงููููุฐุฌ ุงูุฎุงุตุฉ ุจู [ููุง](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english))ุ ูุฅููุง ูููู ุจุชุดุบูู ูุง ููู:

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

ุจูุฌุฑุฏ ุญุตูููุง ุนูู ุงููุนุงูุฌ ุงููุบููุ ูููููุง ุชูุฑูุฑ ุฌูููุง ุฅููู ูุจุงุดุฑุฉ ูุณูุญุตู ุนูู ูุงููุณ ุฌุงูุฒ ูุฅุฏุฎุงูู ูู ูููุฐุฌูุง! ูู ูุง ุชุจูู ูู ุชุญููู ูุงุฆูุฉ ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุฅูู ูุตูููุงุช.

ููููู ุงุณุชุฎุฏุงู ๐ค Transformers ุฏูู ุงูููู ุจุดุฃู ุฅุทุงุฑ ุนูู ุงูุชุนูู ุงูุขูู ุงููุณุชุฎุฏู ูุฎูููุฉุ ููุฏ ูููู PyTorch ุฃู TensorFlowุ ุฃู Flax ูุจุนุถ ุงูููุงุฐุฌ. ููุน ุฐููุ ูุฅู ููุงุฐุฌ Transformer ุชูุจู ููุท *ุงููุตูููุงุช* ูุฅุฏุฎุงู. ุฅุฐุง ูุงูุช ูุฐู ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุณูุน ูููุง ุนู ุงููุตูููุงุชุ ููููู ุงุนุชุจุงุฑูุง ูุตูููุงุช NumPy ุจุฏูุงู ูู ุฐูู. ูููู ุฃู ุชููู ูุตูููุฉ NumPy ูููุงู ุณูููุฉ (0D)ุ ุฃู ูุชุฌูุฉ (1D)ุ ุฃู ูุตูููุฉ (2D)ุ ุฃู ุฐุงุช ุฃุจุนุงุฏ ุฃูุซุฑ. ุฅููุง ูุตูููุฉ ูุนุงูุฉุ ูุชุชุตุฑู ูุตูููุงุช ุงูุฃุทุฑ ุงูุฃุฎุฑู ููุชุนูู ุงูุขูู ุจุดูู ูุดุงุจูุ ูุนุงุฏุฉ ูุง ุชููู ุจุณูุทุฉ ูุซู ูุตูููุงุช NumPy.

ูุชุญุฏูุฏ ููุน ุงููุตูููุงุช ุงูุชู ูุฑูุฏ ุงูุญุตูู ุนูููุง (PyTorchุ TensorFlowุ ุฃู ูุตูููุงุช NumPy ุงูุนุงุฏูุฉ)ุ ูุณุชุฎุฏู ุญุฌุฉ `return_tensors`:

{#if fw === 'pt'}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```
{:else}
```python
raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)
```
{/if}

ูุง ุชููู ุจุดุฃู ุงูุญุดู ูุงูุชูููู ุงูุขูุ ุณูุดุฑุญ ุฐูู ูุงุญููุง. ุงูุฃุดูุงุก ุงูุฑุฆูุณูุฉ ุงูุชู ูุฌุจ ุชุฐูุฑูุง ููุง ูู ุฃูู ููููู ุชูุฑูุฑ ุฌููุฉ ูุงุญุฏุฉ ุฃู ูุงุฆูุฉ ูู ุงูุฌููุ ููุฐูู ุชุญุฏูุฏ ููุน ุงููุตูููุงุช ุงูุชู ุชุฑูุฏ ุงูุญุตูู ุนูููุง (ุฅุฐุง ูู ูุชู ุชูุฑูุฑ ุฃู ููุนุ ูุณุชุญุตู ุนูู ูุงุฆูุฉ ูู ุงูููุงุฆู ููุชูุฌุฉ).

{#if fw === 'pt'}

ููุฐุง ุชุจุฏู ุงููุชุงุฆุฌ ููุตูููุงุช PyTorch:

```python out
{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]), 
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}
```
{:else}

ููุฐุง ุชุจุฏู ุงููุชุงุฆุฌ ููุตูููุงุช TensorFlow:

```python out
{
    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
        ], dtype=int32)>, 
    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
        ], dtype=int32)>
}
```
{/if}

ุงููุงุชุฌ ููุณู ูู ูุงููุณ ูุญุชูู ุนูู ููุชุงุญููุ `input_ids` ู `attention_mask`. ูุญุชูู `input_ids` ุนูู ุตููู ูู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ (ูุงุญุฏ ููู ุฌููุฉ) ููู ุงููุนุฑูุงุช ุงููุฑูุฏุฉ ููุฑููุฒ ูู ูู ุฌููุฉ. ุณูุดุฑุญ ูุง ูู `attention_mask` ูุงุญููุง ูู ูุฐุง ุงููุตู.

## ุงููุฑูุฑ ุนุจุฑ ุงููููุฐุฌ[[going-through-the-model]]

{#if fw === 'pt'}
ูููููุง ุชูุฒูู ูููุฐุฌูุง ุงููุฏุฑุจ ูุณุจููุง ุจููุณ ุงูุทุฑููุฉ ุงูุชู ูููุง ุจูุง ูุน ุงููุนุงูุฌ ุงููุบูู. ูููุฑ ๐ค Transformers ูุฆุฉ `AutoModel` ูุงูุชู ุชุญุชูู ุฃูุถูุง ุนูู ุทุฑููุฉ `from_pretrained()`:

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```
{:else}
ูููููุง ุชูุฒูู ูููุฐุฌูุง ุงููุฏุฑุจ ูุณุจููุง ุจููุณ ุงูุทุฑููุฉ ุงูุชู ูููุง ุจูุง ูุน ุงููุนุงูุฌ ุงููุบูู. ูููุฑ ๐ค Transformers ูุฆุฉ `TFAutoModel` ูุงูุชู ุชุญุชูู ุฃูุถูุง ุนูู ุทุฑููุฉ `from_pretrained`:

```python
from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)
ูู ูุฐุง ุงูุฌุฒุก ูู ุงูููุฏุ ูููุง ุจุชุญููู ููุณ ููุทุฉ ุงูุชููู ุงูุชู ุงุณุชุฎุฏููุงูุง ูู ุฎุท ุฃูุงุจูุจูุง ูุจู ุฐูู (ูุงู ูู ุงูููุชุฑุถ ุฃู ุชููู ูุฎุฒูุฉ ูุคูุชูุง ุจุงููุนู) ููููุง ุจุชุดููู ูููุฐุฌ ุจุงุณุชุฎุฏุงููุง.

ุชุญุชูู ูุฐู ุงูุจููุฉ ููุท ุนูู ูุญุฏุฉ Transformer ุงูุฃุณุงุณูุฉ: ุจุงููุธุฑ ุฅูู ุจุนุถ ุงููุฏุฎูุงุชุ ูุฅููุง ุชูุชุฌ ูุง ุณูุทูู ุนููู *ุญุงูุงุช ูุฎููุฉ*ุ ูุงููุนุฑููุฉ ุฃูุถูุง ุจุงุณู *ุงูููุฒุงุช*. ุจุงููุณุจุฉ ููู ูุฏุฎู ูููููุฐุฌุ ุณูุญุตู ุนูู ูุชุฌู ุนุงูู ุงูุฃุจุนุงุฏ ููุซู **ุงูููู ุงูุณูุงูู ูุฐูู ุงููุฏุฎู ุจูุงุณุทุฉ ูููุฐุฌ Transformer**.

ุฅุฐุง ูู ููู ูุฐุง ููุทูููุงุ ูุง ุชููู ุจุดุฃูู. ุณูุดุฑุญู ูุงุญููุง.

ูู ุญูู ุฃู ูุฐู ุงูุญุงูุงุช ุงููุฎููุฉ ูููู ุฃู ุชููู ูููุฏุฉ ูู ุญุฏ ุฐุงุชูุงุ ููู ุนุงุฏุฉ ูุง ุชููู ูุฏุฎูุงุช ูุฌุฒุก ุขุฎุฑ ูู ุงููููุฐุฌุ ูุงููุนุฑูู ุจุงุณู *ุงูุฑุฃุณ*. ูู [ุงููุตู 1](/course/chapter1)ุ ูุงู ูู ุงููููู ุฃุฏุงุก ุงูููุงู ุงููุฎุชููุฉ ุจุงุณุชุฎุฏุงู ููุณ ุงูุจููุฉุ ูููู ูู ูู ูุฐู ุงูููุงู ุณูููู ููุง ุฑุฃุณ ูุฎุชูู ูุฑุชุจุท ุจูุง.

### ูุชุฌู ุนุงูู ุงูุฃุจุนุงุฏุ[[a-high-dimensional-vector]]

ุงููุชุฌู ุงููุงุชุฌ ุนู ูุญุฏุฉ Transformer ูููู ุนุงุฏุฉ ูุจูุฑูุง. ูุนุงุฏุฉ ูุง ูููู ูู ุซูุงุซุฉ ุฃุจุนุงุฏ:

- **ุญุฌู ุงูุฏูุนุฉ**: ุนุฏุฏ ุงูุณูุงุณู ุงูุชู ุชุชู ูุนุงูุฌุชูุง ูู ููุช ูุงุญุฏ (2 ูู ูุซุงููุง).
- **ุทูู ุงูุณูุณูุฉ**: ุทูู ุงูุชูุซูู ุงูุฑููู ููุณูุณูุฉ (16 ูู ูุซุงููุง).
- **ุญุฌู ุงูุญุงูุฉ ุงููุฎููุฉ**: ุงูุจุนุฏ ุงููุชุฌูู ููู ูุฏุฎู ูููููุฐุฌ.

ููุงู ุฃูู "ุนุงูู ุงูุฃุจุนุงุฏ" ุจุณุจุจ ุงููููุฉ ุงูุฃุฎูุฑุฉ. ูููู ุฃู ูููู ุญุฌู ุงูุญุงูุฉ ุงููุฎููุฉ ูุจูุฑูุง ุฌุฏูุง (768 ูู ุงูุญุฌู ุงูุดุงุฆุน ูููููุฐุฌ ุงูุฃุตุบุฑุ ููู ุงูููุงุฐุฌ ุงูุฃูุจุฑ ูููู ุฃู ูุตู ุฅูู 3072 ุฃู ุฃูุซุฑ).

ูููููุง ุฑุคูุฉ ุฐูู ุฅุฐุง ูููุง ุจุฅุฏุฎุงู ุงููุฏุฎูุงุช ุงูุชู ูููุง ุจูุนุงูุฌุชูุง ูุณุจููุง ุฅูู ูููุฐุฌ:

{#if fw === 'pt'}
```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```

```python out
torch.Size([2, 16, 768])
```
{:else}
```py
outputs = model(inputs)
print(outputs.last_hidden_state.shape)
```

```python out
(2, 16, 768)
```
{/if}

ูุงุญุธ ุฃู ูุฎุฑุฌุงุช ููุงุฐุฌ ๐ค Transformers ุชุชุตุฑู ูุซู `namedtuple`s ุฃู ุงูููุงููุณ. ููููู ุงููุตูู ุฅูู ุงูุนูุงุตุฑ ุนู ุทุฑูู ุงูุณูุงุช (ููุง ูุนููุง) ุฃู ุนู ุทุฑูู ุงูููุชุงุญ (`outputs["last_hidden_state"]`)ุ ุฃู ุญุชู ุนู ุทุฑูู ุงูููุฑุณ ุฅุฐุง ููุช ุชุนุฑู ุจุงูุถุจุท ููุงู ุงูุดูุก ุงูุฐู ุชุจุญุซ ุนูู (`outputs[0]`).

### ุฑุคูุณ ุงููููุฐุฌ: ููู ุงูุฃุฑูุงู[[model-heads-making-sense-out-of-numbers]]

ุชุฃุฎุฐ ุฑุคูุณ ุงููููุฐุฌ ุงููุชุฌู ุนุงูู ุงูุฃุจุนุงุฏ ููุญุงูุงุช ุงููุฎููุฉ ููุฏุฎู ูุชููู ุจุฅุณูุงุทูุง ุนูู ุจุนุฏ ูุฎุชูู. ูุนุงุฏุฉ ูุง ุชุชููู ูู ุทุจูุฉ ุฎุทูุฉ ูุงุญุฏุฉ ุฃู ุจุถุน ุทุจูุงุช ุฎุทูุฉ:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" alt="ุดุจูุฉ Transformer ุจุฌุงูุจ ุฑุฃุณูุง."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg" alt="ุดุจูุฉ Transformer ุจุฌุงูุจ ุฑุฃุณูุง."/>
</div>

ูุชู ุฅุฑุณุงู ูุฎุฑุฌุงุช ูููุฐุฌ Transformer ูุจุงุดุฑุฉ ุฅูู ุฑุฃุณ ุงููููุฐุฌ ููุชู ูุนุงูุฌุชูุง.

ูู ูุฐุง ุงููุฎุทุทุ ูุชู ุชูุซูู ุงููููุฐุฌ ุจุทุจูุฉ ุชุถูููู ูุงูุทุจูุงุช ุงููุงุญูุฉ. ุชููู ุทุจูุฉ ุงูุชุถููู ุจุชุญููู ูู ูุนุฑู ูุฏุฎู ูู ุงููุฏุฎู ุงููุนูู ุฅูู ูุชุฌู ููุซู ุงูุฑูุฒ ุงููุฑุชุจุท ุจู. ูุชููู ุงูุทุจูุงุช ุงููุงุญูุฉ ุจุชุดููู ุชูู ุงููุชุฌูุงุช ุจุงุณุชุฎุฏุงู ุขููุฉ ุงูุงูุชุจุงู ูุฅูุชุงุฌ ุงูุชูุซูู ุงูููุงุฆู ููุฌูู.

ููุงู ุงูุนุฏูุฏ ูู ุงูุจูู ุงููุฎุชููุฉ ุงููุชุงุญุฉ ูู ๐ค Transformersุ ุญูุซ ุชู ุชุตููู ูู ูููุง ุญูู ูุนุงูุฌุฉ ูููุฉ ูุญุฏุฏุฉ. ูููุง ููู ูุงุฆูุฉ ุบูุฑ ุดุงููุฉ:

- `*Model` (ุงุณุชุฑุฌุงุน ุงูุญุงูุงุช ุงููุฎููุฉ)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- ูุบูุฑูุง ๐ค

{#if fw === 'pt'}
ุจุงููุณุจุฉ ููุซุงููุงุ ุณูุญุชุงุฌ ุฅูู ูููุฐุฌ ุจุฑุฃุณ ุชุตููู ุงูุณูุณูุฉ (ููููู ูุงุฏุฑูุง ุนูู ุชุตููู ุงูุฌูู ุนูู ุฃููุง ุฅูุฌุงุจูุฉ ุฃู ุณูุจูุฉ). ูุฐููุ ูู ูุณุชุฎุฏู ูู ุงููุงูุน ูุฆุฉ `AutoModel`ุ ูููู `AutoModelForSequenceClassification`:

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```
{:else}
ุจุงููุณุจุฉ ููุซุงููุงุ ุณูุญุชุงุฌ ุฅูู ูููุฐุฌ ุจุฑุฃุณ ุชุตููู ุงูุณูุณูุฉ (ููููู ูุงุฏุฑูุง ุนูู ุชุตููู ุงูุฌูู ุนูู ุฃููุง ุฅูุฌุงุจูุฉ ุฃู ุณูุจูุฉ). ูุฐููุ ูู ูุณุชุฎุฏู ูู ุงููุงูุน ูุฆุฉ `TFAutoModel`ุ ูููู `TFAutoModelForSequenceClassification`:

```python
from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)
```
{/if}

ุงูุขู ุฅุฐุง ูุธุฑูุง ุฅูู ุดูู ุงููุฎุฑุฌุงุชุ ุณุชููู ุงูุฃุจุนุงุฏ ุฃูู ุจูุซูุฑ: ูุฃุฎุฐ ุฑุฃุณ ุงููููุฐุฌ ููุฏุฎู ุงููุชุฌูุงุช ุนุงููุฉ ุงูุฃุจุนุงุฏ ุงูุชู ุฑุฃููุงูุง ูู ูุจูุ ูููุชุฌ ูุชุฌูุงุช ุชุญุชูู ุนูู ูููุชูู (ูุงุญุฏุฉ ููู ุชุณููุฉ):

```python
print(outputs.logits.shape)
```

{#if fw === 'pt'}
```python out
torch.Size([2, 2])
```
{:else}
```python out
(2, 2)
```
{/if}

ูุธุฑูุง ูุฃู ูุฏููุง ุฌููุชูู ูุชุณููุชูู ููุทุ ูุฅู ุงููุชูุฌุฉ ุงูุชู ูุญุตู ุนูููุง ูู ูููุฐุฌูุง ุชููู ุนูู ุดูู 2x2.

## ูุนุงูุฌุฉ ูุฎุฑุฌุงุช ุงููููุฐุฌ[[postprocessing-the-output]]

ุงูููู ุงูุชู ูุญุตู ุนูููุง ููุฎุฑุฌุงุช ูู ูููุฐุฌูุง ูุง ุชููู ููุทููุฉ ุจุงูุถุฑูุฑุฉ ูู ุญุฏ ุฐุงุชูุง. ุฏุนูุง ูููู ูุธุฑุฉ:

```python
print(outputs.logits)
```

{#if fw === 'pt'}
```python out
tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```
{:else}
```python out
<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[-1.5606991,  1.6122842],
           [ 4.169231 , -3.3464472]], dtype=float32)>
```
{/if}

ุชููุน ูููุฐุฌูุง `[โ1.5607, 1.6123]` ููุฌููุฉ ุงูุฃููู ู`[4.1692, โ3.3464]` ููุฌููุฉ ุงูุซุงููุฉ. ูุฐู ููุณุช ุงุญุชูุงูุงุช ูููู *logits*ุ ููู ุงูุฏุฑุฌุงุช ุงูุฎุงู ูุบูุฑ ุงููุนูุงุฑูุฉ ุงูุชู ููุชุฌูุง ุงูุทุจูุฉ ุงูุฃุฎูุฑุฉ ูู ุงููููุฐุฌ. ููุชุญููููุง ุฅูู ุงุญุชูุงูุงุชุ ูุฌุจ ุฃู ุชูุฑ ุนุจุฑ ุทุจูุฉ [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) (ุฌููุน ููุงุฐุฌ ๐ค Transformers ุชูุชุฌ logitsุ ุญูุซ ุชููู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ููุชุฏุฑูุจ ุจุฏูุฌ ุฏุงูุฉ ุงูุชูุดูุท ุงูุฃุฎูุฑุฉุ ูุซู SoftMaxุ ูุน ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุงููุนููุฉุ ูุซู ุงูุงูุชุฑูุจูุง ุงููุชูุงุทุนุฉ):

{#if fw === 'pt'}
```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```
{:else}
```py
import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)
```
{/if}

{#if fw === 'pt'}
```python out
tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```
{:else}
```python out
tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
 [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)
```
{/if}

ุงูุขู ูููููุง ุฃู ูุฑู ุฃู ุงููููุฐุฌ ุชููุน `[0.0402, 0.9598]` ููุฌููุฉ ุงูุฃููู ู`[0.9995, 0.0005]` ููุฌููุฉ ุงูุซุงููุฉ. ูุฐู ูู ุฏุฑุฌุงุช ุงูุงุญุชูุงูุงุช ุงููุนุฑููุฉ.

ููุญุตูู ุนูู ุงูุชุณููุงุช ุงูููุงุจูุฉ ููู ููุถุนุ ูููููุง ูุญุต ุณูุฉ `id2label` ูุชูููู ุงููููุฐุฌ (ุณูุชุญุฏุซ ุฃูุซุฑ ุนู ูุฐุง ูู ุงููุณู ุงูุชุงูู):

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

ุงูุขู ูููููุง ุฃู ูุณุชูุชุฌ ุฃู ุงููููุฐุฌ ุชููุน ูุง ููู:

- ุงูุฌููุฉ ุงูุฃููู: NEGATIVE: 0.0402, POSITIVE: 0.9598
- ุงูุฌููุฉ ุงูุซุงููุฉ: NEGATIVE: 0.9995, POSITIVE: 0.0005

ููุฏ ูุฌุญูุง ูู ุฅุนุงุฏุฉ ุฅูุชุงุฌ ุงูุฎุทูุงุช ุงูุซูุงุซ ูุฎุท ุงูุฃูุงุจูุจ: ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุจุงุณุชุฎุฏุงู ุงููุนููุ ูุฅุฏุฎุงู ุงููุฏุฎูุงุช ุนุจุฑ ุงููููุฐุฌุ ููุนุงูุฌุฉ ูุฎุฑุฌุงุช ุงููููุฐุฌ! ุงูุขู ุฏุนูุง ูุฃุฎุฐ ุจุนุถ ุงูููุช ููุบูุต ุจุดูู ุฃุนูู ูู ูู ูู ูุฐู ุงูุฎุทูุงุช.

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ุงุฎุชุฑ ูุตูู (ุฃู ุฃูุซุฑ) ุฎุงุตูู ุจู ููู ุจุชุดุบููููุง ุนุจุฑ ุฎุท ุฃูุงุจูุจ `sentiment-analysis`. ุซู ูู ุจุชูุฑุงุฑ ุงูุฎุทูุงุช ุงูุชู ุฑุฃูุชูุง ููุง ุจููุณู ูุชุฃูุฏ ูู ุญุตููู ุนูู ููุณ ุงููุชุงุฆุฌ!

</Tip>