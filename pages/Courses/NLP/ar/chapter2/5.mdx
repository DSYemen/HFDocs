<FrameworkSwitchCourse {fw} />

# ุงูุชุนุงูู ูุน ุชุณูุณูุงุช ูุชุนุฏุฏุฉ [[handling-multiple-sequences]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={2}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section5_tf.ipynb"},
]} />

{/if}

{#if fw === 'pt'}
<Youtube id="M6adb1j2jPI"/>
{:else}
<Youtube id="ROxrFOEbsQE"/>
{/if}

ูู ุงููุณู ุงูุณุงุจูุ ุงุณุชูุดููุง ุฃุจุณุท ุญุงูุงุช ุงูุงุณุชุฎุฏุงู: ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุนูู ุชุณูุณู ูุงุญุฏ ุจุทูู ุตุบูุฑ. ููุน ุฐููุ ุชุธูุฑ ุจุนุถ ุงูุฃุณุฆูุฉ ุจุงููุนู:

- ููู ูุชุนุงูู ูุน ุชุณูุณูุงุช ูุชุนุฏุฏุฉุ
- ููู ูุชุนุงูู ูุน ุชุณูุณูุงุช ูุชุนุฏุฏุฉ *ุจุฃุทูุงู ูุฎุชููุฉ*ุ
- ูู ูุคุดุฑุงุช ุงูููุฑุฏุงุช ูู ุงููุฏุฎูุงุช ุงููุญูุฏุฉ ุงูุชู ุชุณูุญ ููููุงุฐุฌ ุจุงูุนูู ุจุดูู ุฌูุฏุ
- ูู ููุงู ุดูุก ูุซู ุชุณูุณู ุทููู ุฌุฏูุงุ

ุฏุนููุง ูุฑู ูุง ูู ุฃููุงุน ุงููุดุงูู ุงูุชู ุชุทุฑุญูุง ูุฐู ุงูุฃุณุฆูุฉุ ูููู ูููููุง ุญููุง ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ๐ค Transformers.

## ุงูููุงุฐุฌ ุชุชููุน ุฏูุนุฉ ูู ุงููุฏุฎูุงุช [[models-expect-a-batch-of-inputs]]

ูู ุงูุชูุฑูู ุงูุณุงุจูุ ุฑุฃูุช ููู ูุชู ุชุฑุฌูุฉ ุงูุชุณูุณูุงุช ุฅูู ููุงุฆู ูู ุงูุฃุฑูุงู. ุฏุนูุง ูุญูู ูุฐู ุงููุงุฆูุฉ ูู ุงูุฃุฑูุงู ุฅูู ุชูุณูุฑ ููุฑุณููุง ุฅูู ุงููููุฐุฌ:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.tensor(ids)
# This line will fail.
model(input_ids)
```

```python out
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = tf.constant(ids)
# This line will fail.
model(input_ids)
```

```py out
InvalidArgumentError: Input to reshape is a tensor with 14 values, but the requested shape has 196 [Op:Reshape]
```
{/if}

ูุง ุฅููู! ููุงุฐุง ูุดู ูุฐุงุ ููุฏ ุงุชุจุนูุง ุงูุฎุทูุงุช ูู ุฎุท ุงูุฃูุงุจูุจ ูู ุงููุณู 2.

ุงููุดููุฉ ูู ุฃููุง ุฃุฑุณููุง ุชุณูุณููุง ูุงุญุฏูุง ุฅูู ุงููููุฐุฌุ ูู ุญูู ุฃู ููุงุฐุฌ ๐ค Transformers ุชุชููุน ุนุฏุฉ ุฌูู ุจุดูู ุงูุชุฑุงุถู. ููุง ุญุงูููุง ุงูููุงู ุจูู ูุง ูุนูู ุงููุนุงูุฌ ูู ุงูุฎูููุฉ ุนูุฏูุง ุทุจููุงู ุนูู `sequence`. ูููู ุฅุฐุง ูุธุฑุช ุนู ูุซุจุ ูุณุชุฑู ุฃู ุงููุนุงูุฌ ูู ููู ููุท ุจุชุญููู ูุงุฆูุฉ ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุฅูู ุชูุณูุฑุ ุจู ุฃุถุงู ุจูุนุฏูุง ูููู:

{#if fw === 'pt'}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="pt")
print(tokenized_inputs["input_ids"])
```

```python out
tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,
          2607,  2026,  2878,  2166,  1012,   102]])
```
{:else}
```py
tokenized_inputs = tokenizer(sequence, return_tensors="tf")
print(tokenized_inputs["input_ids"])
```

```py out
<tf.Tensor: shape=(1, 16), dtype=int32, numpy=
array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,
        12172,  2607,  2026,  2878,  2166,  1012]], dtype=int32)>
```
{/if}

ุฏุนููุง ูุญุงูู ูุฑุฉ ุฃุฎุฑู ููุถูู ุจูุนุฏูุง ุฌุฏูุฏูุง:

{#if fw === 'pt'}
```py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = torch.tensor([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{:else}
```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = tf.constant([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)
```
{/if}

ูุทุจุน ูุนุฑูุงุช ุงูุฅุฏุฎุงู ููุฐูู ุงูููุบุงุฑูุชูุงุช ุงููุงุชุฌุฉ - ุฅููู ุงููุฎุฑุฌุงุช:

{#if fw === 'pt'}
```python out
Input IDs: [[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607, 2026,  2878,  2166,  1012]]
Logits: [[-2.7276,  2.8789]]
```
{:else}
```py out
Input IDs: tf.Tensor(
[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878
   2166  1012]], shape=(1, 14), dtype=int32)
Logits: tf.Tensor([[-2.7276208  2.8789377]], shape=(1, 2), dtype=float32)
```
{/if}

*Batching* ูู ูุนู ุฅุฑุณุงู ุฌูู ูุชุนุฏุฏุฉ ุนุจุฑ ุงููููุฐุฌุ ุฏูุนุฉ ูุงุญุฏุฉ. ุฅุฐุง ูุงู ูุฏูู ุฌููุฉ ูุงุญุฏุฉ ููุทุ ูููููู ููุท ุจูุงุก ุฏูุนุฉ ูุน ุชุณูุณู ูุงุญุฏ:

```
batched_ids = [ids, ids]
```

ูุฐู ูู ุฏูุนุฉ ูู ุชุณูุณููู ูุชุทุงุจููู!

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ูู ุจุชุญููู ูุงุฆูุฉ `batched_ids` ูุฐู ุฅูู ุชูุณูุฑ ููุฑุฑูุง ุนุจุฑ ูููุฐุฌู. ุชุญูู ูู ุญุตููู ุนูู ููุณ ุงูููุบุงุฑูุชูุงุช ููุง ูู ุงูุณุงุจู (ูููู ูุฑุชูู)!

</Tip>

ูุณูุญ ุงูุชุฌููุน ูููููุฐุฌ ุจุงูุนูู ุนูุฏูุง ุชููู ุจุฅุทุนุงูู ุฌูู ูุชุนุฏุฏุฉ. ุงุณุชุฎุฏุงู ุชุณูุณูุงุช ูุชุนุฏุฏุฉ ุจุณูุท ูุซู ุจูุงุก ุฏูุนุฉ ูุน ุชุณูุณู ูุงุญุฏ. ููุงู ูุดููุฉ ุซุงููุฉุ ุนูู ุงูุฑุบู ูู ุฐูู. ุนูุฏูุง ุชุญุงูู ุชุฌููุน ุฌููุชูู (ุฃู ุฃูุซุฑ) ูุนูุงุ ููุฏ ุชููู ุจุฃุทูุงู ูุฎุชููุฉ. ุฅุฐุง ููุช ูุฏ ุนููุช ูุน ุชูุณูุฑุงุช ูู ูุจูุ ูุฃูุช ุชุนูู ุฃููุง ุชุญุชุงุฌ ุฅูู ุฃู ุชููู ุฐุงุช ุดูู ูุณุชุทููุ ูุฐุง ูู ุชุชููู ูู ุชุญููู ูุงุฆูุฉ ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุฅูู ุชูุณูุฑ ูุจุงุดุฑุฉ. ููุงูุชูุงู ุญูู ูุฐู ุงููุดููุฉุ ุนุงุฏุฉ ูุง ูููู *ุจุฅุถุงูุฉ* ุงููุฏุฎูุงุช.

## ุฅุถุงูุฉ ุงููุฏุฎูุงุช [[padding-the-inputs]]

ูุง ูููู ุชุญููู ูุงุฆูุฉ ุงูููุงุฆู ุงูุชุงููุฉ ุฅูู ุชูุณูุฑ:

```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200]
]
```

ูู ุฃุฌู ุงูุงูุชูุงู ุญูู ูุฐุงุ ุณูุณุชุฎุฏู *padding* ูุฌุนู ุชูุณูุฑุงุชูุง ุฐุงุช ุดูู ูุณุชุทูู. ูุถูู ุงูุชุนุจุฆุฉ ุฃู ุชููู ุฌููุน ุฌูููุง ุจููุณ ุงูุทูู ุนู ุทุฑูู ุฅุถุงูุฉ ูููุฉ ุฎุงุตุฉ ุชุณูู *ุฑูุฒ ุงูุชุนุจุฆุฉ* ุฅูู ุงูุฌูู ุฐุงุช ุงูููู ุงูุฃูู. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู ูุฏูู 10 ุฌูู ูู 10 ูููุงุช ูุฌููุฉ ูุงุญุฏุฉ ูู 20 ูููุฉุ ูุณุชุถูู ุงูุชุนุจุฆุฉ ุฃู ุชููู ุฌููุน ุงูุฌูู 20 ูููุฉ. ูู ูุซุงููุงุ ูุจุฏู ุงูุชูุณูุฑ ุงููุงุชุฌ ุนูู ุงููุญู ุงูุชุงูู:

```py no-format
padding_id = 100

batched_ids = [
    [200, 200, 200],
    [200, 200, padding_id],
]
```

ูููู ุงูุนุซูุฑ ุนูู ูุนุฑู ุฑูุฒ ุงูุชุนุจุฆุฉ ูู `tokenizer.pad_token_id`. ุฏุนููุง ูุณุชุฎุฏูู ููุฑุณู ุฌููุชูู ูู ุฎูุงู ุงููููุฐุฌ ุจุดูู ูุฑุฏู ููุฌูุนุฉ ูุนูุง:

{#if fw === 'pt'}
```py no-format
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(torch.tensor(sequence1_ids)).logits)
print(model(torch.tensor(sequence2_ids)).logits)
print(model(torch.tensor(batched_ids)).logits)
```

```python out
tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward>)
tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
tensor([[ 1.5694, -1.3895],
        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(tf.constant(sequence1_ids)).logits)
print(model(tf.constant(sequence2_ids)).logits)
print(model(tf.constant(batched_ids)).logits)
```

```py out
tf.Tensor([[ 1.5693678 -1.3894581]], shape=(1, 2), dtype=float32)
tf.Tensor([[ 0.5803005  -0.41252428]], shape=(1, 2), dtype=float32)
tf.Tensor(
[[ 1.5693681 -1.3894582]
 [ 1.3373486 -1.2163193]], shape=(2, 2), dtype=float32)
```
{/if}

ููุงู ุฎุทุฃ ูุง ูู ููู ุงูููุบุงุฑูุชูุงุช ูู ุชูุจุคุงุชูุง ุงููุฌูุนุฉ: ูุฌุจ ุฃู ูููู ุงูุตู ุงูุซุงูู ูุทุงุจููุง ูููู ุงูููุบุงุฑูุชูุงุช ููุฌููุฉ ุงูุซุงููุฉุ ููู ูุฏููุง ููู ูุฎุชููุฉ ุชูุงููุง!

ูุฐุง ูุฃู ุงูููุฒุฉ ุงูุฑุฆูุณูุฉ ูููุงุฐุฌ ุงููุญูู ูู ุทุจูุงุช ุงูุงูุชุจุงู ุงูุชู *ุชุถูู ุงูุณูุงู* ุนูู ูู ุฑูุฒ. ุณุชุฑุงุนู ูุฐู ุงูุทุจูุงุช ุฑููุฒ ุงูุญุดู ูุฃููุง ุชุฑูุฒ ุนูู ุฌููุน ุฑููุฒ ุงูุชุณูุณู. ููุญุตูู ุนูู ููุณ ุงููุชูุฌุฉ ุนูุฏ ุชูุฑูุฑ ุฌูู ูุฑุฏูุฉ ุฐุงุช ุฃุทูุงู ูุฎุชููุฉ ุนุจุฑ ุงููููุฐุฌ ุฃู ุนูุฏ ุชูุฑูุฑ ุฏูุนุฉ ุจููุณ ุงูุฌูู ูุงูุญุดู ุงููุทุจูุ ูุญุชุงุฌ ุฅูู ุฅุฎุจุงุฑ ุทุจูุงุช ุงูุงูุชุจุงู ูุฐู ุจุชุฌุงูู ุฑููุฒ ุงูุญุดู. ูุชู ุฐูู ุจุงุณุชุฎุฏุงู ููุงุน ุงูุงูุชุจุงู.

## ุฃููุนุฉ ุงูุงูุชุจุงู[[attention-masks]]

*ุฃููุนุฉ ุงูุงูุชุจุงู* ูู ูุตูููุงุช ุฐุงุช ููุณ ุงูุดูู ุชูุงููุง ูุซู ูุตูููุฉ ุฑููุฒ ุงูุฅุฏุฎุงูุ ูููุฆุฉ ุจุงูุฃุตูุงุฑ ูุงูุขุญุงุฏ: ุชุดูุฑ ุงูุขุญุงุฏ ุฅูู ุงูุฑููุฒ ุงูููุงุจูุฉ ุงูุชู ูุฌุจ ุงูุงูุชุจุงู ุฅูููุงุ ูุชุดูุฑ ุงูุฃุตูุงุฑ ุฅูู ุงูุฑููุฒ ุงูููุงุจูุฉ ุงูุชู ูุง ูุฌุจ ุงูุงูุชุจุงู ุฅูููุง (ุฃู ูุฌุจ ุชุฌุงูููุง ุจูุงุณุทุฉ ุทุจูุงุช ุงูุงูุชุจุงู ูู ุงููููุฐุฌ).

ุฏุนูุง ูููู ุงููุซุงู ุงูุณุงุจู ุจููุงุน ุงูุงูุชุจุงู:

{#if fw === 'pt'}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))
print(outputs.logits)
```

```python out
tensor([[ 1.5694, -1.3895],
        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
```
{:else}
```py no-format
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(tf.constant(batched_ids), attention_mask=tf.constant(attention_mask))
print(outputs.logits)
```

```py out
tf.Tensor(
[[ 1.5693681  -1.3894582 ]
 [ 0.5803021  -0.41252586]], shape=(2, 2), dtype=float32)
```
{/if}

ุงูุขู ูุญุตู ุนูู ููุณ ููู ุงูููุบุงุฑูุชูุงุช ููุฌููุฉ ุงูุซุงููุฉ ูู ุงูุฏูุนุฉ.

ูุงุญุธ ููู ุฃู ุงููููุฉ ุงูุฃุฎูุฑุฉ ูู ุงูุชุณูุณู ุงูุซุงูู ูู ูุนุฑู ุงูุญุดูุ ููู ูููุฉ ุตูุฑูุฉ ูู ููุงุน ุงูุงูุชุจุงู.

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ูู ุจุชุทุจูู ุงูุชุฌุฒุฆุฉ ูุฏูููุง ุนูู ุงูุฌููุชูู ุงููุณุชุฎุฏูุชูู ูู ุงููุณู 2 ("I've been waiting for a HuggingFace course my whole life." ู"I hate this so much!"). ูุฑุฑูุง ุนุจุฑ ุงููููุฐุฌ ูุชุฃูุฏ ูู ุญุตููู ุนูู ููุณ ููู ุงูููุบุงุฑูุชูุงุช ููุง ูู ุงููุณู 2. ุงูุขู ูู ุจุชุฌููุนูุง ูุนูุง ุจุงุณุชุฎุฏุงู ุฑูุฒ ุงูุญุดูุ ุซู ูู ุจุฅูุดุงุก ููุงุน ุงูุงูุชุจุงู ุงูููุงุณุจ. ุชุญูู ูู ุญุตููู ุนูู ููุณ ุงููุชุงุฆุฌ ุนูุฏ ุงููุฑูุฑ ุนุจุฑ ุงููููุฐุฌ!

</Tip>

## ุชุณูุณูุงุช ุฃุทูู[[longer-sequences]]

ูุน ููุงุฐุฌ ุงููุญููุ ููุงู ุญุฏ ูุฃุทูุงู ุงูุชุณูุณูุงุช ุงูุชู ูููููุง ุชูุฑูุฑูุง ุฅูู ุงูููุงุฐุฌ. ุชุชุนุงูู ูุนุธู ุงูููุงุฐุฌ ูุน ุชุณูุณูุงุช ูุตู ุทูููุง ุฅูู 512 ุฃู 1024 ุฑูุฒูุงุ ูุณุชุชุนุทู ุนูุฏ ุทูุจ ูุนุงูุฌุฉ ุชุณูุณูุงุช ุฃุทูู. ููุงู ุญูุงู ููุฐู ุงููุดููุฉ:

- ุงุณุชุฎุฏุงู ูููุฐุฌ ุจุทูู ุชุณูุณู ูุฏุนูู ุฃุทูู.
- ุงูุชุทุงุน ุชุณูุณูุงุชู.

ุชุฎุชูู ุงูููุงุฐุฌ ูู ุฃุทูุงู ุงูุชุณูุณูุงุช ุงููุฏุนููุฉุ ููุชุฎุตุต ุจุนุถูุง ูู ุงูุชุนุงูู ูุน ุงูุชุณูุณูุงุช ุงูุทูููุฉ ุฌุฏูุง. [Longformer](https://huggingface.co/docs/transformers/model_doc/longformer) ูู ุฃุญุฏ ุงูุฃูุซูุฉุ ูุขุฎุฑ ูู [LED](https://huggingface.co/docs/transformers/model_doc/led). ุฅุฐุง ููุช ุชุนูู ุนูู ูููุฉ ุชุชุทูุจ ุชุณูุณูุงุช ุทูููุฉ ุฌุฏูุงุ ูุฅููุง ููุตู ุจุฅููุงุก ูุธุฑุฉ ุนูู ุชูู ุงูููุงุฐุฌ.

ูุฅูุงุ ูุฅููุง ููุตู ุจุงูุชุทุงุน ุชุณูุณูุงุชู ุนู ุทุฑูู ุชุญุฏูุฏ ูุนููุฉ `max_sequence_length`:

```py
sequence = sequence[:max_sequence_length]
```