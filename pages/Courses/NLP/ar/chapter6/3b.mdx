<FrameworkSwitchCourse {fw} />

# ูุนุงูุฌุงุช ุณุฑูุนุฉ ูู ุฎุท ุฃูุงุจูุจ QA[[fast-tokenizers-in-the-qa-pipeline]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={6}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter6/section3b_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter6/section3b_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={6}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter6/section3b_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter6/section3b_tf.ipynb"},
]} />

{/if}

ุงูุขู ุณูุบูุต ูู ุฎุท ุฃูุงุจูุจ `question-answering` ููุฑู ููู ูููููุง ุงูุงุณุชูุงุฏุฉ ูู ุงูุฅุฒุงุญุงุช ูุงูุชูุงุท ุงูุฅุฌุงุจุฉ ุนูู ุงูุณุคุงู ุงููุทุฑูุญ ูู ุงูุณูุงูุ ููููุงู ูุซููุง ูุนููุง ููููุงูุงุช ุงููุฌูุนุฉ ูู ุงููุณู ุงูุณุงุจู. ุจุนุฏ ุฐููุ ุณูุฑู ููู ูููููุง ุงูุชุนุงูู ูุน ุงูุณูุงูุงุช ุงูุทูููุฉ ุฌุฏูุง ุงูุชู ุชูุชูู ุจูุทุนูุง. ููููู ุชุฎุทู ูุฐุง ุงููุณู ุฅุฐุง ูู ุชูู ููุชููุง ุจูููุฉ ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ.

{#if fw === 'pt'}

<Youtube id="_wxyB3j3mk4"/>

{:else}

<Youtube id="b3u8RzBCX9Y"/>

{/if}

## ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ `question-answering`[[using-the-question-answering-pipeline]]

ููุง ุฑุฃููุง ูู [ุงููุตู 1](/course/chapter1)ุ ูููููุง ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ `question-answering` ูุซู ูุฐุง ููุญุตูู ุนูู ุฅุฌุงุจุฉ ุนูู ุณุคุงู:

```py
from transformers import pipeline

question_answerer = pipeline("question-answering")
context = """
๐ค Transformers ูุฏุนูู ูู ููุชุจุงุช ุงูุชุนูู ุงูุนููู ุงูุซูุงุซ ุงูุฃูุซุฑ ุดุนุจูุฉ - Jax ู PyTorch ู TensorFlow - ูุน ุชูุงูู ุณูุณ
ุจูููู. ูู ุงูุณูู ุชุฏุฑูุจ ููุงุฐุฌู ุจุงุณุชุฎุฏุงู ุฃุญุฏูุง ูุจู ุชุญููููุง ููุชูููุฐ ุจุงุณุชุฎุฏุงู ุงูุขุฎุฑ.
"""
question = "ูุง ูู ููุชุจุงุช ุงูุชุนูู ุงูุนููู ุงูุชู ุชุฏุนู ๐ค Transformersุ"
question_answerer(question=question, context=context)
```

```python out
{'score': 0.97773,
 'start': 78,
 'end': 105,
 'answer': 'Jax ู PyTorch ู TensorFlow'}
```

ุนูู ุนูุณ ุฎุทูุท ุงูุฃูุงุจูุจ ุงูุฃุฎุฑูุ ุงูุชู ูุง ูููููุง ุชูุทูุน ูุชูุณูู ุงููุตูุต ุงูุชู ุชููู ุฃุทูู ูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ููุจูู ุงููููุฐุฌ (ูุจุงูุชุงูู ูุฏ ุชููุฏ ุงููุนูููุงุช ูู ููุงูุฉ ุงููุณุชูุฏ)ุ ูููู ููุฐุง ุงูุฎุท ุฃูุงุจูุจ ุงูุชุนุงูู ูุน ุงูุณูุงูุงุช ุงูุทูููุฉ ุฌุฏูุง ูุณูุนูุฏ ุงูุฅุฌุงุจุฉ ุนูู ุงูุณุคุงู ุญุชู ุฅุฐุง ูุงูุช ูู ุงูููุงูุฉ:

```py
long_context = """
๐ค Transformers: State of the Art NLP

๐ค Transformers ูููุฑ ุงูุขูุงู ูู ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ูุฃุฏุงุก ููุงู ุนูู ุงููุตูุต ูุซู ุงูุชุตูููุ ูุงุณุชุฎุฑุงุฌ ุงููุนูููุงุชุ
ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉุ ูุงูุชูุฎูุตุ ูุงูุชุฑุฌูุฉุ ูุชูููุฏ ุงููุต ูุฃูุซุฑ ูู ุฐูู ูู ุฃูุซุฑ ูู 100 ูุบุฉ.
ูุฏููุง ูู ุฌุนู NLP ุงูุฑุงุฆุฏ ุฃุณูู ูู ุงูุงุณุชุฎุฏุงู ููุฌููุน.

๐ค Transformers ูููุฑ ูุงุฌูุงุช ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ูุชูุฒูู ูุงุณุชุฎุฏุงู ุชูู ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ุนูู ูุต ูุนููุ ูุชุนุฏูููุง ุนูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู
ุซู ูุดุงุฑูุชูุง ูุน ุงููุฌุชูุน ุนูู ูุฑูุฒ ููุงุฐุฌูุง. ูู ููุณ ุงูููุชุ ูู ูุญุฏุฉ ุจุงูุซูู ุชุญุฏุฏ ููุฏุณุฉ ูุณุชููุฉ ุชูุงููุง ููููู
ุชุนุฏูููุง ูุชูููู ุชุฌุงุฑุจ ุงูุฃุจุญุงุซ ุงูุณุฑูุนุฉ.

ููุงุฐุง ูุฌุจ ุฃู ุฃุณุชุฎุฏู ุงููุญููุงุชุ

1. ููุงุฐุฌ ุฑุงุฆุฏุฉ ุณููุฉ ุงูุงุณุชุฎุฏุงู:
  - ุฃุฏุงุก ุนุงูู ูู ููุงู NLU ู NLG.
  - ุญุงุฌุฒ ููุฎูุถ ููุฏุฎูู ูููุฑุจูู ูุงูููุงุฑุณูู.
  - ุนุฏุฏ ูููู ูู ุงูุชุฌุฑูุฏุงุช ุงูุชู ููุงุฌููุง ุงููุณุชุฎุฏู ูุน ุซูุงุซ ูุฆุงุช ููุท ููุชุนูู.
  - ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ููุญุฏุฉ ูุงุณุชุฎุฏุงู ุฌููุน ููุงุฐุฌูุง ุงููุณุจูุฉ ุงูุชุฏุฑูุจ.
  - ุชูุงููู ุญูุณุจุฉ ุฃููุ ูุจุตูุฉ ูุฑุจูููุฉ ุฃุตุบุฑ:

2. ูููู ููุจุงุญุซูู ูุดุงุฑูุฉ ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ุจุฏูุงู ูู ุฅุนุงุฏุฉ ุงูุชุฏุฑูุจ ุฏุงุฆููุง.
  - ูููู ููููุงุฑุณูู ุชูููู ููุช ุงูุญูุณุจุฉ ูุชูุงููู ุงูุฅูุชุงุฌ.
  - ุนุดุฑุงุช ุงูููุฏุณุงุช ุงููุนูุงุฑูุฉ ูุน ุฃูุซุฑ ูู 10000 ูููุฐุฌ ูุณุจู ุงูุชุฏุฑูุจุ ุจุนุถูุง ูู ุฃูุซุฑ ูู 100 ูุบุฉ.

3. ุงุฎุชุฑ ุงูุฅุทุงุฑ ุงูุตุญูุญ ููู ุฌุฒุก ูู ุนูุฑ ุงููููุฐุฌ:
  - ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงูุฑุงุฆุฏุฉ ูู 3 ุฃุณุทุฑ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ.
  - ููู ูููุฐุฌ ูุงุญุฏ ุจูู ุฅุทุงุฑุงุช TF2.0/PyTorch ุญุณุจ ุงูุฑุบุจุฉ.
  - ุงุฎุชุฑ ุงูุฅุทุงุฑ ุงูุตุญูุญ ููุชุฏุฑูุจ ูุงูุชูููู ูุงูุฅูุชุงุฌ ุจุณูุงุณุฉ.

4. ูู ุจุชุฎุตูุต ูููุฐุฌ ุฃู ูุซุงู ุจุณูููุฉ ููููุง ูุงุญุชูุงุฌุงุชู:
  - ูููุฑ ุฃูุซูุฉ ููู ููุฏุณุฉ ูุฅุนุงุฏุฉ ุฅูุชุงุฌ ุงููุชุงุฆุฌ ุงูุชู ูุดุฑูุง ูุคููููุง ุงูุฃุตูููู.
  - ูุชู ุนุฑุถ ุฏุงุฎููุงุช ุงููููุฐุฌ ุจุดูู ูุชุณู ูุฏุฑ ุงูุฅููุงู.
  - ูููู ุงุณุชุฎุฏุงู ูููุงุช ุงููููุฐุฌ ุจุดูู ูุณุชูู ุนู ุงูููุชุจุฉ ูุชุฌุงุฑุจ ุณุฑูุนุฉ.

๐ค Transformers ูุฏุนูู ูู ููุชุจุงุช ุงูุชุนูู ุงูุนููู ุงูุซูุงุซ ุงูุฃูุซุฑ ุดุนุจูุฉ - Jax ู PyTorch ู TensorFlow - ูุน ุชูุงูู ุณูุณ
ุจูููู. ูู ุงูุณูู ุชุฏุฑูุจ ููุงุฐุฌู ุจุงุณุชุฎุฏุงู ุฃุญุฏูุง ูุจู ุชุญููููุง ููุชูููุฐ ุจุงุณุชุฎุฏุงู ุงูุขุฎุฑ.
"""
question_answerer(question=question, context=long_context)
```

```python out
{'score': 0.97149,
 'start': 1892,
 'end': 1919,
 'answer': 'Jax ู PyTorch ู TensorFlow'}
```

ุฏุนููุง ูุฑู ููู ูููู ุจูู ูุฐุง!

## ุงุณุชุฎุฏุงู ูููุฐุฌ ููุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ[[using-a-model-for-question-answering]]

ูุซู ุฃู ุฎุท ุฃูุงุจูุจ ุขุฎุฑุ ูุจุฏุฃ ุจุชูุณูู ูุฏุฎูุงุชูุง ุฅูู ุฑููุฒ ุซู ูุฑุณููุง ุนุจุฑ ุงููููุฐุฌ. ููุทุฉ ุงูุชูุชูุด ุงููุณุชุฎุฏูุฉ ุจุดูู ุงูุชุฑุงุถู ูุฎุท ุฃูุงุจูุจ `question-answering` ูู [`distilbert-base-cased-distilled-squad`](https://huggingface.co/distilbert-base-cased-distilled-squad) (ูุฃุชู "squad" ูู ุงูุงุณู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชู ุชู ุถุจุท ุงููููุฐุฌ ุนูููุงุ ุณูุชุญุฏุซ ุฃูุซุฑ ุนู ูุฌููุนุฉ ุจูุงูุงุช SQuAD ูู [ุงููุตู 7](/course/chapter7/7)):

{#if fw === 'pt'}

```py
from transformers import AutoTokenizer, AutoModelForQuestionAnswering

model_checkpoint = "distilbert-base-cased-distilled-squad"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)

inputs = tokenizer(question, context, return_tensors="pt")
outputs = model(**inputs)
```

{:else}

```py
from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering

model_checkpoint = "distilbert-base-cased-distilled-squad"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)

inputs = tokenizer(question, context, return_tensors="tf")
outputs = model(**inputs)
```

{/if}

ูุงุญุธ ุฃููุง ููุณู ุงูุณุคุงู ูุงูุณูุงู ูุฒูุฌุ ูุน ุงูุณุคุงู ุฃููุงู.

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/question_tokens.svg" alt="ูุซุงู ุนูู ุชูุณูู ุงูุณุคุงู ูุงูุณูุงู"/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/question_tokens-dark.svg" alt="ูุซุงู ุนูู ุชูุณูู ุงูุณุคุงู ูุงูุณูุงู"/>
</div>

ุชุนูู ุงูููุงุฐุฌ ููุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุจุดูู ูุฎุชูู ููููุงู ุนู ุงูููุงุฐุฌ ุงูุชู ุฑุฃููุงูุง ุญุชู ุงูุขู. ุจุงุณุชุฎุฏุงู ุงูุตูุฑุฉ ุฃุนูุงู ููุซุงูุ ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ููุชูุจุค ุจูุคุดุฑ ุงูุฑูุฒ ุงูุฐู ูุจุฏุฃ ุงูุฅุฌุงุจุฉ (ููุง 21) ููุคุดุฑ ุงูุฑูุฒ ุงูุฐู ุชูุชูู ุนูุฏู ุงูุฅุฌุงุจุฉ (ููุง 24). ููุฐุง ุงูุณุจุจ ูุง ุชุนูุฏ ูุฐู ุงูููุงุฐุฌ ูุตูููุฉ ูุงุญุฏุฉ ูู ุงูููุบุงุฑูุชูุงุช ูููู ุงุซูุชูู: ูุงุญุฏุฉ ูููุบุงุฑูุชูุงุช ุงูููุงุจูุฉ ููุฑูุฒ ุงูุฃูู ููุฅุฌุงุจุฉุ ููุงุญุฏุฉ ูููุบุงุฑูุชูุงุช ุงูููุงุจูุฉ ููุฑูุฒ ุงูุฃุฎูุฑ ููุฅุฌุงุจุฉ. ูุธุฑูุง ูุฃูู ูู ูุฐู ุงูุญุงูุฉ ูุฏููุง ูุฏุฎู ูุงุญุฏ ูุญุชูู ุนูู 66 ุฑูุฒูุงุ ูุญุตู ุนูู:

```py
start_logits = outputs.start_logits
end_logits = outputs.end_logits
print(start_logits.shape, end_logits.shape)
```

{#if fw === 'pt'}

```python out
torch.Size([1, 66]) torch.Size([1, 66])
```

{:else}

```python out
(1, 66) (1, 66)
```
{:else}

```python out
(1, 66) (1, 66)
```

{/if}

ูุชุญููู ูุฐู ุงูููุบุงุฑูุชูุงุช ุฅูู ุงุญุชูุงูุงุชุ ุณูุทุจู ุฏุงูุฉ softmax - ูููู ูุจู ุฐููุ ูุญุชุงุฌ ุฅูู ุงูุชุฃูุฏ ูู ุฃููุง ููููุน ุงููุคุดุฑุงุช ุงูุชู ููุณุช ุฌุฒุกูุง ูู ุงูุณูุงู. ูุฏุฎููุง ูู `[CLS] ุงูุณุคุงู [SEP] ุงูุณูุงู [SEP]`ุ ูุฐูู ูุญุชุงุฌ ุฅูู ููุงุน ุฑููุฒ ุงูุณุคุงู ููุฐูู ุงูุฑูุฒ `[SEP]`. ุณูุญุชูุธ ุจุงูุฑูุฒ `[CLS]`ุ ููุน ุฐููุ ุญูุซ ุชุณุชุฎุฏู ุจุนุถ ุงูููุงุฐุฌ ููุฅุดุงุฑุฉ ุฅูู ุฃู ุงูุฅุฌุงุจุฉ ููุณุช ูู ุงูุณูุงู.

ุจูุง ุฃููุง ุณูุทุจู softmax ูุงุญููุงุ ูุฅููุง ูุญุชุงุฌ ููุท ุฅูู ุงุณุชุจุฏุงู ุงูููุบุงุฑูุชูุงุช ุงูุชู ูุฑูุฏ ููุงุนูุง ุจุฑูู ุณูุจู ูุจูุฑ. ููุงุ ูุณุชุฎุฏู `-10000`:

{#if fw === 'pt'}

```py
import torch

sequence_ids = inputs.sequence_ids()
# ููุงุน ูู ุดูุก ุจุงุณุชุซูุงุก ุฑููุฒ ุงูุณูุงู
mask = [i != 1 for i in sequence_ids]
# ุฅุฒุงูุฉ ููุงุน ุงูุฑูุฒ [CLS]
mask[0] = False
mask = torch.tensor(mask)[None]

start_logits[mask] = -10000
end_logits[mask] = -10000
```

{:else}

```py
import tensorflow as tf

sequence_ids = inputs.sequence_ids()
# ููุงุน ูู ุดูุก ุจุงุณุชุซูุงุก ุฑููุฒ ุงูุณูุงู
mask = [i != 1 for i in sequence_ids]
# ุฅุฒุงูุฉ ููุงุน ุงูุฑูุฒ [CLS]
mask[0] = False
mask = tf.constant(mask)[None]

start_logits = tf.where(mask, -10000, start_logits)
end_logits = tf.where(mask, -10000, end_logits)
```

{/if}

ุงูุขู ุจุนุฏ ุฃู ูููุง ุจููุงุน ุงูููุบุงุฑูุชูุงุช ุงูููุงุจูุฉ ููููุงุถุน ุงูุชู ูุง ูุฑูุฏ ุงูุชูุจุค ุจูุง ุจุดูู ุตุญูุญุ ูููููุง ุชุทุจูู softmax:

{#if fw === 'pt'}

```py
start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]
end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]
```

{:else}

```py
start_probabilities = tf.math.softmax(start_logits, axis=-1)[0].numpy()
end_probabilities = tf.math.softmax(end_logits, axis=-1)[0].numpy()
```

{/if}

ูู ูุฐู ุงููุฑุญูุฉุ ูููููุง ุฃุฎุฐ argmax ูู ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ - ูููู ูุฏ ููุชูู ุจูุง ุงูุฃูุฑ ุจูุคุดุฑ ุจุฏุงูุฉ ุฃูุจุฑ ูู ูุคุดุฑ ุงูููุงูุฉุ ูุฐูู ูุญุชุงุฌ ุฅูู ุงุชุฎุงุฐ ุจุนุถ ุงูุงุญุชูุงุทุงุช ุงูุฅุถุงููุฉ. ุณูุญุณุจ ุงุญุชูุงูุงุช ูู `start_index` ู`end_index` ุงููุญุชููุฉ ุญูุซ `start_index <= end_index`ุ ุซู ูุฃุฎุฐ ุงูุฒูุฌ `(start_index, end_index)` ูุน ุงูุงุญุชูุงู ุงูุฃุนูู.

ุจุงูุชุฑุงุถ ุฃู ุงูุฃุญุฏุงุซ "ุชุจุฏุฃ ุงูุฅุฌุงุจุฉ ูู `start_index`" ู"ุชูุชูู ุงูุฅุฌุงุจุฉ ูู `end_index`" ุชููู ูุณุชููุฉุ ูุฅู ุงุญุชูุงู ุฃู ุชุจุฏุฃ ุงูุฅุฌุงุจุฉ ูู `start_index` ูุชูุชูู ูู `end_index` ูู:

$$\mathrm{start\_probabilities}[\mathrm{start\_index}] \times \mathrm{end\_probabilities}[\mathrm{end\_index}]$$ 

ูุฐููุ ูุญุณุงุจ ุฌููุน ุงูุฏุฑุฌุงุชุ ูุญุชุงุฌ ููุท ุฅูู ุญุณุงุจ ุฌููุน ุงูููุชุฌุงุช 
$$\mathrm{start\_probabilities}[\mathrm{start\_index}] \times \mathrm{end\_probabilities}[\mathrm{end\_index}]$$
ุญูุซ `start_index <= end_index`.

ุฃููุงูุ ุฏุนูุง ูุญุณุจ ุฌููุน ุงูููุชุฌุงุช ุงููุญุชููุฉ:

```py
scores = start_probabilities[:, None] * end_probabilities[None, :]
```

{#if fw === 'pt'}

ุซู ุณูููู ุจููุงุน ุงูููู ุญูุซ `start_index > end_index` ุนู ุทุฑูู ุชุนููููุง ุฅูู `0` (ุงูุงุญุชูุงูุงุช ุงูุฃุฎุฑู ูู ุฌููุน ุงูุฃุฑูุงู ุงูุฅูุฌุงุจูุฉ). ุชุนูุฏ ุฏุงูุฉ `torch.triu()` ุงูุฌุฒุก ุงูุนููู ุงููุซูุซ ูู ุงููุตูููุฉ ุซูุงุฆูุฉ ุงูุฃุจุนุงุฏ ุงูุชู ุชู ุชูุฑูุฑูุง ูุญุฌุฉุ ูุฐูู ุณุชููู ุจุนูููุฉ ุงูููุงุน ูุฐู ูู ุฃุฌููุง:

```py
scores = torch.triu(scores)
```

{:else}

ุซู ุณูููู ุจููุงุน ุงูููู ุญูุซ `start_index > end_index` ุนู ุทุฑูู ุชุนููููุง ุฅูู `0` (ุงูุงุญุชูุงูุงุช ุงูุฃุฎุฑู ูู ุฌููุน ุงูุฃุฑูุงู ุงูุฅูุฌุงุจูุฉ). ุชุนูุฏ ุฏุงูุฉ `np.triu()` ุงูุฌุฒุก ุงูุนููู ุงููุซูุซ ูู ุงููุตูููุฉ ุซูุงุฆูุฉ ุงูุฃุจุนุงุฏ ุงูุชู ุชู ุชูุฑูุฑูุง ูุญุฌุฉุ ูุฐูู ุณุชููู ุจุนูููุฉ ุงูููุงุน ูุฐู ูู ุฃุฌููุง:

```py
import numpy as np

scores = np.triu(scores)
```

{/if}

ุงูุขู ูุญุชุงุฌ ููุท ุฅูู ุงูุญุตูู ุนูู ูุคุดุฑ ุงููููุฉ ุงููุตูู. ูุธุฑูุง ูุฃู PyTorch ุณุชุนูุฏ ุงููุคุดุฑ ูู ุงููุตูููุฉ ุงููุณุทุญุฉุ ูุฅููุง ูุญุชุงุฌ ุฅูู ุงุณุชุฎุฏุงู ุนูููุชู ุงููุณูุฉ ุนูู ุงูุฃุฑุถูุฉ `%` ููุญุตูู ุนูู `start_index` ู`end_index`:

```py
max_index = scores.argmax().item()
start_index = max_index // scores.shape[1]
end_index = max_index % scores.shape[1]
print(scores[start_index, end_index])
```

ูู ููุชู ุจุนุฏุ ูููู ุนูู ุงูุฃูู ูุฏููุง ุงููุชูุฌุฉ ุงูุตุญูุญุฉ ููุฅุฌุงุจุฉ (ููููู ุงูุชุญูู ูู ุฐูู ุนู ุทุฑูู ููุงุฑูุชูุง ุจุงููุชูุฌุฉ ุงูุฃููู ูู ุงููุณู ุงูุณุงุจู):

```python out
0.97773
```

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ุงุญุณุจ ูุคุดุฑุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ููุฅุฌุงุจุงุช ุงูุฎูุณ ุงูุฃูุซุฑ ุงุญุชูุงููุง.

</Tip>

ูุฏููุง `start_index` ู`end_index` ููุฅุฌุงุจุฉ ูู ุญูุซ ุงูุฑููุฒุ ูุฐูู ุงูุขู ูุญุชุงุฌ ููุท ุฅูู ุชุญููููุง ุฅูู ูุคุดุฑุงุช ุงูุฃุญุฑู ูู ุงูุณูุงู. ููุง ุณุชููู ุงูุฅุฒุงุญุงุช ูููุฏุฉ ููุบุงูุฉ. ูููููุง ุงูุญุตูู ุนูููุง ูุงุณุชุฎุฏุงููุง ููุง ูุนููุง ูู ูููุฉ ุชุตููู ุงูุฑููุฒ:

```py
inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)
offsets = inputs_with_offsets["offset_mapping"]

start_char, _ = offsets[start_index]
_, end_char = offsets[end_index]
answer = context[start_char:end_char]
```

ุงูุขู ูุญุชุงุฌ ููุท ุฅูู ุชูุณูู ูู ุดูุก ููุญุตูู ุนูู ุงููุชูุฌุฉ:

```py
result = {
    "answer": answer,
    "start": start_char,
    "end": end_char,
    "score": scores[start_index, end_index],
}
print(result)
```

```python out
{'answer': 'Jax, PyTorch and TensorFlow',
 'start': 78,
 'end': 105,
 'score': 0.97773}
```

ุฑุงุฆุน! ูุฐุง ูู ููุณ ูุซุงููุง ุงูุฃูู!

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ุงุณุชุฎุฏู ุฃูุถู ุงูุฏุฑุฌุงุช ุงูุชู ุญุณุจุชูุง ุณุงุจููุง ูุนุฑุถ ุงูุฅุฌุงุจุงุช ุงูุฎูุณ ุงูุฃูุซุฑ ุงุญุชูุงููุง. ููุชุญูู ูู ูุชุงุฆุฌูุ ุนุฏ ุฅูู ุงูุฃูุจูุจ ุงูุฃูู ููุฑุฑู ูู `top_k=5` ุนูุฏ ุงุณุชุฏุนุงุฆู.

</Tip>

## ุงูุชุนุงูู ูุน ุงูุณูุงูุงุช ุงูุทูููุฉ[[handling-long-contexts]]

ุฅุฐุง ุญุงูููุง ุชููููุฒ ุงูุณุคุงู ูุงูุณูุงู ุงูุทููู ุงูุฐู ุงุณุชุฎุฏููุงู ููุซุงู ุณุงุจููุงุ ูุณูุญุตู ุนูู ุนุฏุฏ ูู ุงูุฑููุฒ ุฃุนูู ูู ุงูุทูู ุงูุฃูุตู ุงููุณุชุฎุฏู ูู ุฃูุจูุจ `question-answering` (ุงูุฐู ูุจูุบ 384):

```py
inputs = tokenizer(question, long_context)
print(len(inputs["input_ids"]))
```

```python out
461
```

ูุฐููุ ุณูุญุชุงุฌ ุฅูู ุชูุตูุฑ ูุฏุฎูุงุชูุง ุนูุฏ ูุฐุง ุงูุทูู ุงูุฃูุตู. ููุงู ุนุฏุฉ ุทุฑู ูููููุง ุงูููุงู ุจุฐููุ ูููููุง ูุง ูุฑูุฏ ุชูุตูุฑ ุงูุณุคุงูุ ููุท ุงูุณูุงู. ูุธุฑูุง ูุฃู ุงูุณูุงู ูู ุงูุฌููุฉ ุงูุซุงููุฉุ ูุณูุณุชุฎุฏู ุฅุณุชุฑุงุชูุฌูุฉ ุงูุชูุตูุฑ `"only_second"`. ุงููุดููุฉ ุงูุชู ุชูุดุฃ ุจุนุฏ ุฐูู ูู ุฃู ุงูุฅุฌุงุจุฉ ุนูู ุงูุณุคุงู ูุฏ ูุง ุชููู ูู ุงูุณูุงู ุงูููุชุทุน. ููุงุ ุนูู ุณุจูู ุงููุซุงูุ ุงุฎุชุฑูุง ุณุคุงููุง ุชููู ููู ุงูุฅุฌุงุจุฉ ูู ููุงูุฉ ุงูุณูุงูุ ูุนูุฏูุง ูููู ุจุชูุตูุฑู ูุง ุชููู ุชูู ุงูุฅุฌุงุจุฉ ููุฌูุฏุฉ:

```py
inputs = tokenizer(question, long_context, max_length=384, truncation="only_second")
print(tokenizer.decode(inputs["input_ids"]))
```

```python out
"""
[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP

[UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,
question answering, summarization, translation, text generation and more in over 100 languages.
Its aim is to make cutting-edge NLP easier to use for everyone.

[UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and
then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and
can be modified to enable quick research experiments.

Why should I use transformers?

1. Easy-to-use state-of-the-art models:
  - High performance on NLU and NLG tasks.
  - Low barrier to entry for educators and practitioners.
  - Few user-facing abstractions with just three classes to learn.
  - A unified API for using all our pretrained models.
  - Lower compute costs, smaller carbon footprint:

2. Researchers can share trained models instead of always retraining.
  - Practitioners can reduce compute time and production costs.
  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.

3. Choose the right framework for every part of a model's lifetime:
  - Train state-of-the-art models in 3 lines of code.
  - Move a single model between TF2.0/PyTorch frameworks at will.
  - Seamlessly pick the right framework for training, evaluation and production.

4. Easily customize a model or an example to your needs:
  - We provide examples for each architecture to reproduce the results published by its original authors.
  - Model internal [SEP]
"""
```
ูุฐุง ูุนูู ุฃู ุงููููุฐุฌ ุณููุงุฌู ุตุนูุจุฉ ูู ุงุฎุชูุงุฑ ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ. ููุญู ูุฐู ุงููุดููุฉุ ุชุณูุญ ููุง ุฎุท ุฃูุงุจูุจ `question-answering` ุจุชูุณูู ุงูุณูุงู ุฅูู ุฃุฌุฒุงุก ุฃุตุบุฑุ ูุน ุชุญุฏูุฏ ุงูุทูู ุงูุฃูุตู. ูููุชุฃูุฏ ูู ุฃููุง ูุง ููุณู ุงูุณูุงู ูู ุงูููุงู ุงูุฎุงุทุฆ ุชูุงููุงุ ููุง ูุฌุนู ูู ุงููุณุชุญูู ุงูุนุซูุฑ ุนูู ุงูุฅุฌุงุจุฉุ ูุฅูู ูุชุถูู ุฃูุถูุง ุจุนุถ ุงูุชุฏุงุฎู ุจูู ุงูุฃุฌุฒุงุก.

ูููููุง ุฃู ูุฌุนู ุงููุฌุฒุก ุงููุบูู (ุณุฑูุน ุฃู ุจุทูุก) ูููู ุจุฐูู ูู ุฃุฌููุง ุนู ุทุฑูู ุฅุถุงูุฉ `return_overflowing_tokens=True`ุ ููููููุง ุชุญุฏูุฏ ุงูุชุฏุงุฎู ุงูุฐู ูุฑูุฏู ุจุงุณุชุฎุฏุงู ุญุฌุฉ `stride`. ุฅููู ูุซุงูุ ุจุงุณุชุฎุฏุงู ุฌููุฉ ุฃุตุบุฑ:

```py
sentence = "This sentence is not too long but we are going to split it anyway."
inputs = tokenizer(
    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2
)

for ids in inputs["input_ids"]:
    print(tokenizer.decode(ids))
```

```python out
'[CLS] ูุฐู ุงูุฌููุฉ ููุณุช [SEP]'
'[CLS] ููุณุช ุทูููุฉ ุฌุฏูุง [SEP]'
'[CLS] ุทูููุฉ ุฌุฏูุง ูููููุง [SEP]'
'[CLS] ูููููุง ุณููุณููุง [SEP]'
'[CLS] ุณููุณููุง ุนูู ุฃู [SEP]'
'[CLS] ุนูู ุฃู ุญุงู. [SEP]'
```

ููุง ูุฑูุ ุชู ุชูุณูู ุงูุฌููุฉ ุฅูู ุฃุฌุฒุงุก ุจุญูุซ ูุญุชูู ูู ุฅุฏุฎุงู ูู `inputs["input_ids"]` ุนูู 6 ุฑููุฒ ูุญุฏ ุฃูุตู (ุณูุญุชุงุฌ ุฅูู ุฅุถุงูุฉ ุงูุญุดู ูุฌุนู ุงูุฅุฏุฎุงู ุงูุฃุฎูุฑ ุจููุณ ุญุฌู ุงูุฅุฏุฎุงูุงุช ุงูุฃุฎุฑู) ูููุงู ุชุฏุงุฎู ูู ุฑูุฒูู ุจูู ูู ุฅุฏุฎุงู.

ุฏุนูุง ูููู ูุธุฑุฉ ูุงุญุตุฉ ุนูู ูุชูุฌุฉ ุงูุชุญููู ุงููุบูู:

```py
print(inputs.keys())
```

```python out
dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])
```

ููุง ูู ูุชููุนุ ูุญุตู ุนูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ูููุงุน ุงูุงูุชุจุงู. ุงูููุชุงุญ ุงูุฃุฎูุฑุ `overflow_to_sample_mapping`ุ ูู ุฎุฑูุทุฉ ุชุฎุจุฑูุง ุจุฃู ุฌููุฉ ุชุชูุงูู ูุน ูู ูู ุงููุชุงุฆุฌ - ููุง ูุฏููุง 7 ูุชุงุฆุฌ ุชุฃุชู ุฌููุนูุง ูู ุงูุฌููุฉ (ุงููุญูุฏุฉ) ุงูุชู ูุฑุฑูุงูุง ุฅูู ุงููุฌุฒุก ุงููุบูู:

```py
print(inputs["overflow_to_sample_mapping"])
```

```python out
[0, 0, 0, 0, 0, 0, 0]
```

ูุฐุง ุฃูุซุฑ ูุงุฆุฏุฉ ุนูุฏูุง ูููู ุจุชุญููู ุนุฏุฉ ุฌูู ูุนูุง. ุนูู ุณุจูู ุงููุซุงูุ ูุฐุง:

```py
sentences = [
    "This sentence is not too long but we are going to split it anyway.",
    "This sentence is shorter but will still get split.",
]
inputs = tokenizer(
    sentences, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2
)

print(inputs["overflow_to_sample_mapping"])
```

ูุญุตู ููุง ุนูู:

```python out
[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]
```

ููุฐุง ูุนูู ุฃู ุงูุฌููุฉ ุงูุฃููู ููุณูุฉ ุฅูู 7 ุฃุฌุฒุงุก ููุง ูู ุงูุญุงู ูู ูุจูุ ูุงูุฃุฌุฒุงุก ุงูุฃุฑุจุนุฉ ุงูุชุงููุฉ ุชุฃุชู ูู ุงูุฌููุฉ ุงูุซุงููุฉ.

ุงูุขู ุฏุนูุง ูุนูุฏ ุฅูู ุณูุงููุง ุงูุทููู. ุจุดูู ุงูุชุฑุงุถูุ ุชุณุชุฎุฏู ุฎุท ุฃูุงุจูุจ `question-answering` ุทูููุง ุฃูุตู ูุจูุบ 384ุ ููุง ุฐูุฑูุง ุณุงุจููุงุ ูุฎุทูุฉ ุชุจูุบ 128ุ ูุงูุชู ุชุชูุงูู ูุน ุงูุทุฑููุฉ ุงูุชู ุชู ุจูุง ุถุจุท ุงููููุฐุฌ ุงูุฏููู (ููููู ุถุจุท ุชูู ุงููุนููุงุช ุนู ุทุฑูู ุชูุฑูุฑ ุญุฌุฌ `max_seq_len` ู `stride` ุนูุฏ ุงุณุชุฏุนุงุก ุฎุท ุงูุฃูุงุจูุจ). ูุจุงูุชุงููุ ุณูุณุชุฎุฏู ูุฐู ุงููุนููุงุช ุนูุฏ ุงูุชุญููู. ุณูุถูู ุฃูุถูุง ุงูุญุดู (ููุญุตูู ุนูู ุนููุงุช ุจููุณ ุงูุทููุ ุจุญูุซ ูููููุง ุจูุงุก ุงููุตูููุงุช) ููุฐูู ูุทูุจ ุงูุฅุฒุงุญุงุช:

```py
inputs = tokenizer(
    question,
    long_context,
    stride=128,
    max_length=384,
    padding="longest",
    truncation="only_second",
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)
```

ุณุชุญุชูู ูุฐู ุงูุฅุฏุฎุงูุงุช ุนูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ูุฃููุนุฉ ุงูุงูุชุจุงู ุงูุชู ูุชููุนูุง ุงููููุฐุฌุ ุจุงูุฅุถุงูุฉ ุฅูู ุงูุฅุฒุงุญุงุช ู `overflow_to_sample_mapping` ุงูุชู ุชุญุฏุซูุง ุนููุง ููุชู. ูุธุฑูุง ูุฃู ูุฐูู ุงูุฃูุฑูู ููุณุง ูุนููุงุช ูุณุชุฎุฏููุง ุงููููุฐุฌุ ูุณูููู ุจุฅุฒุงูุชููุง ูู ุงูุฅุฏุฎุงูุงุช (ููู ูุฎุฒู ุงูุฎุฑูุทุฉุ ูุฃููุง ุบูุฑ ูููุฏุฉ ููุง) ูุจู ุชุญููููุง ุฅูู ูุตูููุฉ:

{#if fw === 'pt'}

```py
_ = inputs.pop("overflow_to_sample_mapping")
offsets = inputs.pop("offset_mapping")

inputs = inputs.convert_to_tensors("pt")
print(inputs["input_ids"].shape)
```
```python out
torch.Size([2, 384])
```
{:else}

```py
_ = inputs.pop("overflow_to_sample_mapping")
offsets = inputs.pop("offset_mapping")

inputs = inputs.convert_to_tensors("tf")
print(inputs["input_ids"].shape)
```

```python out
(2, 384)
```

{/if}

ุชู ุชูุณูู ุณูุงููุง ุงูุทููู ุฅูู ูุณูููุ ููุง ูุนูู ุฃูู ุจุนุฏ ูุฑูุฑู ุนุจุฑ ูููุฐุฌูุงุ ุณูุญุตู ุนูู ูุฌููุนุชูู ูู ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ:

```py
outputs = model(**inputs)

start_logits = outputs.start_logits
end_logits = outputs.end_logits
print(start_logits.shape, end_logits.shape)
```

{#if fw === 'pt'}

```python out
torch.Size([2, 384]) torch.Size([2, 384])
```

{:else}

```python out
(2, 384) (2, 384)
```

{/if}

ููุง ูู ุงูุญุงู ูู ูุจูุ ูููู ุฃููุงู ุจููุงุน ุงูุฑููุฒ ุงูุชู ููุณุช ุฌุฒุกูุง ูู ุงูุณูุงู ูุจู ุฃุฎุฐ softmax. ูููู ุฃูุถูุง ุจููุงุน ุฌููุน ุฑููุฒ ุงูุญุดู (ููุง ูู ูุญุฏุฏ ุจูุงุณุทุฉ ููุงุน ุงูุงูุชุจุงู):

{#if fw === 'pt'}

```py
sequence_ids = inputs.sequence_ids()
# Mask everything apart from the tokens of the context
mask = [i != 1 for i in sequence_ids]
# Unmask the [CLS] token
mask[0] = False
# Mask all the [PAD] tokens
mask = torch.logical_or(torch.tensor(mask)[None], (inputs["attention_mask"] == 0))

start_logits[mask] = -10000
end_logits[mask] = -10000
```

{:else}

```py
sequence_ids = inputs.sequence_ids()
# Mask everything apart from the tokens of the context
mask = [i != 1 for i in sequence_ids]
# Unmask the [CLS] token
mask[0] = False
# Mask all the [PAD] tokens
mask = tf.math.logical_or(tf.constant(mask)[None], inputs["attention_mask"] == 0)

start_logits = tf.where(mask, -10000, start_logits)
end_logits = tf.where(mask, -10000, end_logits)
```

{/if}

ุจุนุฏ ุฐููุ ูููููุง ุงุณุชุฎุฏุงู softmax ูุชุญููู ุงุญุชูุงูุงุชูุง ุฅูู ุงุญุชูุงูุงุช:

{#if fw === 'pt'}

```py
start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)
end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)
```

{:else}

```py
start_probabilities = tf.math.softmax(start_logits, axis=-1).numpy()
end_probabilities = tf.math.softmax(end_logits, axis=-1).numpy()
```

{/if}

ุงูุฎุทูุฉ ุงูุชุงููุฉ ุชุดุจู ูุง ูููุง ุจู ููุณูุงู ุงูุตุบูุฑุ ูููููุง ููุฑุฑูุง ููู ูู ุฌุฒุฃููุง. ูุนุทู ุฏุฑุฌุฉ ูุฌููุน ุงููุทุงูุงุช ุงููุญุชููุฉ ููุฅุฌุงุจุฉุ ุซู ูุฃุฎุฐ ุงููุทุงู ุฐู ุงูุฏุฑุฌุฉ ุงูุฃุนูู:

{#if fw === 'pt'}

```py
candidates = []
for start_probs, end_probs in zip(start_probabilities, end_probabilities):
    scores = start_probs[:, None] * end_probs[None, :]
    idx = torch.triu(scores).argmax().item()

    start_idx = idx // scores.shape[1]
    end_idx = idx % scores.shape[1]
    score = scores[start_idx, end_idx].item()
    candidates.append((start_idx, end_idx, score))

print(candidates)
```

{:else}

```py
candidates = []
for start_probs, end_probs in zip(start_probabilities, end_probabilities):
    scores = start_probs[:, None] * end_probs[None, :]
    idx = np.triu(scores).argmax().item()

    start_idx = idx // scores.shape[1]
    end_idx = idx % scores.shape[1]
    score = scores[start_idx, end_idx].item()
    candidates.append((start_idx, end_idx, score))

print(candidates)
```

{/if}

```python out
[(0, 18, 0.33867), (173, 184, 0.97149)]
```

ูุฐุงู ุงููุฑุดุญุงู ูุชูุงููุงู ูุน ุฃูุถู ุฅุฌุงุจุงุช ุชููู ุงููููุฐุฌ ูู ุงูุนุซูุฑ ุนูููุง ูู ูู ุฌุฒุก. ุงููููุฐุฌ ุฃูุซุฑ ุซูุฉ ุจุฃู ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ ููุฌูุฏุฉ ูู ุงูุฌุฒุก ุงูุซุงูู (ููุฐู ุนูุงูุฉ ุฌูุฏุฉ!). ุงูุขูุ ูู ูุง ุนูููุง ูุนูู ูู ูุทุงุจูุฉ ูุฐูู ุงููุทุงููู ูู ุงูุฑููุฒ ูุน ูุทุงูุงุช ุงูุฃุญุฑู ูู ุงูุณูุงู (ูุญุชุงุฌ ููุท ุฅูู ูุทุงุจูุฉ ุงููุทุงู ุงูุซุงูู ููุญุตูู ุนูู ุฅุฌุงุจุชูุงุ ูููู ูู ุงููุซูุฑ ููุงูุชูุงู ุฃู ูุฑู ูุง ุงุฎุชุงุฑู ุงููููุฐุฌ ูู ุงูุฌุฒุก ุงูุฃูู).

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ูู ุจุชุนุฏูู ุงูููุฏ ุฃุนูุงู ูุฅุฑุฌุงุน ุงูุฏุฑุฌุงุช ูุงููุทุงูุงุช ููุฅุฌุงุจุงุช ุงูุฎูุณ ุงูุฃูุซุฑ ุงุญุชูุงููุง (ูู ุงููุฌููุนุ ูููุณ ููู ุฌุฒุก).

</Tip>

ุฅู `ุงูุฅุฒุงุญุงุช` ุงูุชู ุญุตููุง ุนูููุง ูู ููุช ุณุงุจู ูู ูู ุงููุงูุน ูุงุฆูุฉ ูู ุงูุฅุฒุงุญุงุชุ ูุน ูุงุฆูุฉ ูุงุญุฏุฉ ููู ุฌุฒุก ูู ุงููุต:

```py
for candidate, offset in zip(candidates, offsets):
    start_token, end_token, score = candidate
    start_char, _ = offset[start_token]
    _, end_char = offset[end_token]
    answer = long_context[start_char:end_char]
    result = {"answer": answer, "start": start_char, "end": end_char, "score": score}
    print(result)
```

```python out
{'answer': '\n๐ค Transformers: State of the Art NLP', 'start': 0, 'end': 37, 'score': 0.33867}
{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1892, 'end': 1919, 'score': 0.97149}
```
ุฅุฐุง ุชุฌุงูููุง ุงููุชูุฌุฉ ุงูุฃูููุ ุณูุญุตู ุนูู ููุณ ุงููุชูุฌุฉ ุงูุชู ุญุตููุง ุนูููุง ูู ุฎุท ุฃูุงุจูุจูุง ููุฐุง ุงูุณูุงู ุงูุทููู -- ูุง ูู ูู ุฃูุฑ ุฑุงุฆุน!

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ุงุณุชุฎุฏู ุฃูุถู ุงููุชุงุฆุฌ ุงูุชู ุญุณุจุชูุง ุณุงุจูุงู ูุนุฑุถ ุงูุฅุฌุงุจุงุช ุงูุฎูุณ ุงูุฃูุซุฑ ุงุญุชูุงููุฉ (ููุณูุงู ุจุงููุงููุ ูููุณ ููู ุฌุฒุก). ููุชุญูู ูู ูุชุงุฆุฌูุ ุนุฏ ุฅูู ุฎุท ุงูุฃูุงุจูุจ ุงูุฃูู ูุฃุฏุฎู `top_k=5` ุนูุฏ ุงุณุชุฏุนุงุฆู.

</Tip>

ูุฐุง ูุฎุชุชู ุบูุตูุง ุงูุนููู ูู ูุฏุฑุงุช ุงููุนุงูุฌ ุงูููุทุนู. ุณูุถุน ูู ูุฐุง ููุถุน ุงูููุงุฑุณุฉ ูุฑุฉ ุฃุฎุฑู ูู ุงููุตู ุงูุชุงููุ ุนูุฏูุง ูุฑููู ููููุฉ ุถุจุท ูููุฐุฌ ุนูู ูุทุงู ูุงุณุน ูู ููุงู ูุนุงูุฌุฉ ุงููุบุงุช ุงูุทุจูุนูุฉ.
