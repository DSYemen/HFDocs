<FrameworkSwitchCourse {fw} />

# ุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช Trainer[[fine-tuning-a-model-with-the-trainer-api]]

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

๐ค ูููุฑ Transformers ูุฆุฉ `Trainer` ููุณุงุนุฏุชู ูู ุถุจุท ุฃู ูู ุงูููุงุฐุฌ ุงูููุฏุฑุจุฉ ูุณุจููุง ุงูุชู ูููุฑูุง ุนูู ูุฌููุนุฉ ุจูุงูุงุชู. ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฌููุน ุฃุนูุงู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุจูุงูุงุช ูู ุงููุณู ุงูุฃุฎูุฑุ ุณุชุชุจูู ูู ุฎุทูุงุช ููููุฉ ููุท ูุชุญุฏูุฏ `Trainer`. ููู ุงููุฑุฌุญ ุฃู ูููู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุฅุนุฏุงุฏ ุงูุจูุฆุฉ ูุชุดุบูู `Trainer.train()`ุ ุญูุซ ุณูุณุชุบุฑู ููุชูุง ุทูููุงู ููุบุงูุฉ ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ. ุฅุฐุง ูู ููู ูุฏูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ููุนุฏุฉุ ููููู ุงูุญุตูู ุนูู ูุตูู ูุฌุงูู ุฅูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ุฃู ูุญุฏุงุช ูุนุงูุฌุฉ ุงููุตูููุงุช (TPUs) ุนูู [Google Colab](https://colab.research.google.com/).

ุชูุชุฑุถ ุฃูุซูุฉ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุฏูุงู ุฃูู ูุฏ ููุฐุช ุจุงููุนู ุงูุฃูุซูุฉ ูู ุงููุณู ุงูุณุงุจู. ูููุง ููู ููุฎุต ูุตูุฑ ูุณุชุนุฑุถ ูุง ุชุญุชุงุฌ ุฅููู:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### ุงูุชุฏุฑูุจ[[training]]

ุงูุฎุทูุฉ ุงูุฃููู ูุจู ุฃู ูุชููู ูู ุชุญุฏูุฏ `Trainer` ุงูุฎุงุต ุจูุง ูู ุชุญุฏูุฏ ูุฆุฉ `TrainingArguments` ุงูุชู ุณุชุชุถูู ุฌููุน ุงููุนููุงุช ุงูุชู ุณูุณุชุฎุฏููุง `Trainer` ููุชุฏุฑูุจ ูุงูุชูููู. ุงูุญุฌุฉ ุงููุญูุฏุฉ ุงูุชู ูุฌุจ ุฃู ุชููุฑูุง ูู ุฏููู ุญูุซ ุณูุชู ุญูุธ ุงููููุฐุฌ ุงููุฏุฑุจุ ุจุงูุฅุถุงูุฉ ุฅูู ููุงุท ุงูุชูุชูุด ุนูู ุทูู ุงูุทุฑูู. ุจุงููุณุจุฉ ูุจููุฉ ุงูุฃููุฑุ ููููู ุชุฑู ุงูุฅุนุฏุงุฏุงุช ุงูุงูุชุฑุงุถูุฉุ ูุงูุชู ูุฌุจ ุฃู ุชุนูู ุจุดูู ุฌูุฏ ุฌุฏูุง ูุถุจุท ุฃุณุงุณู.

```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

<Tip>

๐ก ุฅุฐุง ููุช ุชุฑุบุจ ูู ุชุญููู ูููุฐุฌู ุชููุงุฆููุง ุฅูู ุงููุฑูุฒ ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูู ุจุชูุฑูุฑ `push_to_hub=True` ูู `TrainingArguments`. ุณูุชุนูู ุงููุฒูุฏ ุนู ูุฐุง ูู [ุงููุตู 4](/course/chapter4/3)

</Tip>

ุงูุฎุทูุฉ ุงูุซุงููุฉ ูู ุชุญุฏูุฏ ูููุฐุฌูุง. ููุง ูู [ุงููุตู ุงูุณุงุจู](/course/chapter2)ุ ุณูุณุชุฎุฏู ูุฆุฉ `AutoModelForSequenceClassification`ุ ูุน ุนูุงูุชูู:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

ุณุชูุงุญุธ ุฃูู ุนูู ุนูุณ [ุงููุตู 2](/course/chapter2)ุ ุณุชุญุตู ุนูู ุชุญุฐูุฑ ุจุนุฏ ุฅูุดุงุก ูุฐุง ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง. ูุฐูู ูุฃู BERT ูู ูุชู ุชุฏุฑูุจู ูุณุจููุง ุนูู ุชุตููู ุฃุฒูุงุฌ ุงูุฌููุ ูุฐุง ุชู ุงูุชุฎูุต ูู ุฑุฃุณ ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ูุชูุช ุฅุถุงูุฉ ุฑุฃุณ ุฌุฏูุฏ ููุงุณุจ ูุชุตููู ุงูุชุณูุณู ุจุฏูุงู ูู ุฐูู. ุชุดูุฑ ุงูุชุญุฐูุฑุงุช ุฅูู ุฃู ุจุนุถ ุงูุฃูุฒุงู ูู ุชูุณุชุฎุฏู (ุงูุชู ุชุชูุงูู ูุน ุฑุฃุณ ุงูุชุฏุฑูุจ ุงููุณุจู ุงูููุณูุท) ูุฃู ุจุนุถูุง ุงูุขุฎุฑ ุชู ุชููุฆุชู ุนุดูุงุฆููุง (ุงูุชู ุชุชูุงูู ูุน ุงูุฑุฃุณ ุงูุฌุฏูุฏ). ููุฎุชุชู ุจุชุดุฌูุนู ุนูู ุชุฏุฑูุจ ุงููููุฐุฌุ ููู ูุง ุณูููู ุจู ุงูุขู ุจุงูุถุจุท.

ุจูุฌุฑุฏ ุญุตูููุง ุนูู ูููุฐุฌูุงุ ูููููุง ุชุญุฏูุฏ `Trainer` ูู ุฎูุงู ุชูุฑูุฑ ุฌููุน ุงูุฃุดูุงุก ุงูุชู ุชู ุฅูุดุงุคูุง ุญุชู ุงูุขู - `model`ุ ู`training_args`ุ ููุฌููุนุงุช ุจูุงูุงุช ุงูุชุฏุฑูุจ ูุงูุชุญููุ ู`data_collator`ุ ู`tokenizer`:

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

ูุงุญุธ ุฃูู ุนูุฏ ุชูุฑูุฑ `tokenizer` ููุง ูุนููุง ููุงุ ุณูููู `data_collator` ุงูุงูุชุฑุงุถู ุงูุฐู ูุณุชุฎุฏูู `Trainer` ูู `DataCollatorWithPadding` ููุง ุชู ุชุญุฏูุฏู ุณุงุจููุงุ ูุฐุง ููููู ุชุฎุทู ุงูุณุทุฑ `data_collator=data_collator` ูู ูุฐู ุงูููุงููุฉ. ูุงู ูู ุงูููู ุฃู ููุธูุฑ ูู ูุฐุง ุงูุฌุฒุก ูู ุงููุนุงูุฌุฉ ูู ุงููุณู 2!

ูุถุจุท ุงููููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุชูุงุ ูู ูุง ุนูููุง ูุนูู ูู ุงุณุชุฏุนุงุก ุทุฑููุฉ `train()` ุงูุฎุงุตุฉ ุจู `Trainer`:

```py
trainer.train()
```

ุณูุจุฏุฃ ูุฐุง ุงูุถุจุท (ุงูุฐู ูุฌุจ ุฃู ูุณุชุบุฑู ุจุถุน ุฏูุงุฆู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช) ูุณูุจูุบ ุนู ุฎุณุงุฑุฉ ุงูุชุฏุฑูุจ ูู 500 ุฎุทูุฉ. ููุน ุฐููุ ูู ูุฎุจุฑู ุจูุฏู ุฌูุฏุฉ (ุฃู ุณูุก) ุฃุฏุงุก ูููุฐุฌู. ูุฐูู ูุฃู:

1. ูู ูุฎุจุฑ `Trainer` ุจุฅุฌุฑุงุก ุงูุชูููู ุฃุซูุงุก ุงูุชุฏุฑูุจ ูู ุฎูุงู ุชุนููู `evaluation_strategy` ุฅูุง ุฅูู `"steps"` (ุชูููู ูู `eval_steps`) ุฃู `"epoch"` (ุชูููู ูู ููุงูุฉ ูู ุญูุจุฉ).
2. ูู ูุฒูุฏ `Trainer` ุจูุธููุฉ `compute_metrics()` ูุญุณุงุจ ูููุงุณ ุฃุซูุงุก ุงูุชูููู ุงููุฐููุฑ (ูุฅูุง ูุฅู ุงูุชูููู ูุงู ุณููุทุจุน ุงูุฎุณุงุฑุฉ ููุทุ ููู ููุณ ุฑูููุง ุจุฏููููุง).


### ุงูุชูููู[[evaluation]]

ุฏุนููุง ูุฑู ููู ูููููุง ุจูุงุก ูุธููุฉ `compute_metrics()` ูููุฏุฉ ูุงุณุชุฎุฏุงููุง ูู ุงููุฑุฉ ุงููุงุฏูุฉ ุงูุชู ูุฏุฑุจ ูููุง. ูุฌุจ ุฃู ุชุฃุฎุฐ ุงููุธููุฉ ูุงุฆู `EvalPrediction` (ููู ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ููุณูุงุฉ ูุน ุญูู `predictions` ูุญูู `label_ids`) ูุณุชุนูุฏ ูุงููุณูุง ูููู ุจุชุนููู ุงูุณูุงุณู ุฅูู ุฃุฑูุงู ุนุงุฆูุฉ (ุงูุณูุงุณู ูู ุฃุณูุงุก ุงูููุงููุณ ุงููุนุงุฏุฉุ ูุงูุฃุฑูุงู ุงูุนุงุฆูุฉ ูู ููููุง). ููุญุตูู ุนูู ุจุนุถ ุงูุชููุนุงุช ูู ูููุฐุฌูุงุ ูููููุง ุงุณุชุฎุฏุงู ุฃูุฑ `Trainer.predict()`:

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```

ููุฎุฑุฌ ุทุฑููุฉ `predict()` ูู ูุฌููุนุฉ ููุณูุงุฉ ุฃุฎุฑู ูุน ุซูุงุซุฉ ุญููู: `predictions`ุ ู`label_ids`ุ ู`metrics`. ุณูุญุชูู ุญูู `metrics` ููุท ุนูู ุงูุฎุณุงุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููููุฑุฑุฉุ ุจุงูุฅุถุงูุฉ ุฅูู ุจุนุถ ุงูููุงููุณ ุงูุฒูููุฉ (ุงููุฏุฉ ุงูุชู ุงุณุชุบุฑููุง ุงูุชูุจุคุ ูู ุงูุฅุฌูุงูู ููุชูุณุท). ุจูุฌุฑุฏ ุงูุชูุงู ูุธููุฉ `compute_metrics()` ุงูุฎุงุตุฉ ุจูุง ูุชูุฑูุฑูุง ุฅูู `Trainer`ุ ุณูุชุถูู ุฐูู ุงูุญูู ุฃูุถูุง ุงูููุงููุณ ุงูุชู ุฃุนุงุฏุชูุง `compute_metrics()`.

ููุง ุชุฑูุ ูุฅู `predictions` ุนุจุงุฑุฉ ุนู ูุตูููุฉ ุซูุงุฆูุฉ ุงูุฃุจุนุงุฏ ุฐุงุช ุดูู 408 ร 2 (408 ูู ุนุฏุฏ ุงูุนูุงุตุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชู ุงุณุชุฎุฏููุงูุง). ุชูู ูู ุงูููุบุงุฑูุชูุงุช ููู ุนูุตุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชู ูุฑุฑูุงูุง ุฅูู `predict()` (ููุง ุฑุฃูุช ูู [ุงููุตู ุงูุณุงุจู](/course/chapter2)ุ ุชุนูุฏ ุฌููุน ููุงุฐุฌ ุงููุญูู ุงูููุบุงุฑูุชูุงุช). ูุชุญููููุง ุฅูู ุชูุจุคุงุช ูููููุง ููุงุฑูุชูุง ุจุนูุงูุงุชูุงุ ูุญุชุงุฌ ุฅูู ุฃุฎุฐ ุงูููุฑุณ ุจุงููููุฉ ุงููุตูู ุนูู ุงููุญูุฑ ุงูุซุงูู:

```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

ุงูุขู ูููููุง ููุงุฑูุฉ ุชูู `preds` ุจุงูุนูุงูุงุช. ูุจูุงุก ูุธููุฉ `compute_metric()` ุงูุฎุงุตุฉ ุจูุงุ ุณูุนุชูุฏ ุนูู ุงูููุงููุณ ูู ููุชุจุฉ ๐ค [Evaluate](https://github.com/huggingface/evaluate/). ูููููุง ุชุญููู ุงูููุงููุณ ุงููุฑุชุจุทุฉ ุจูุฌููุนุฉ ุจูุงูุงุช MRPC ุจุณูููุฉ ููุง ูููุง ุจุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุฐู ุงููุฑุฉ ุจุงุณุชุฎุฏุงู ูุธููุฉ `evaluate.load()`. ูุญุชูู ุงููุงุฆู ุงูููุนุงุฏ ุนูู ุทุฑููุฉ `compute()` ูููููุง ุงุณุชุฎุฏุงููุง ูุฅุฌุฑุงุก ุญุณุงุจ ุงููููุงุณ:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

ูุฏ ุชุฎุชูู ุงููุชุงุฆุฌ ุงูุฏูููุฉ ุงูุชู ุชุญุตู ุนูููุงุ ุญูุซ ูุฏ ูุคุฏู ุงูุชููุฆุฉ ุงูุนุดูุงุฆูุฉ ูุฑุฃุณ ุงููููุฐุฌ ุฅูู ุชุบููุฑ ุงูููุงููุณ ุงูุชู ุญูููุง. ููุงุ ูููููุง ุฃู ูุฑู ุฃู ูููุฐุฌูุง ูุฏูู ุฏูุฉ 85.78% ุนูู ูุฌููุนุฉ ุงูุชุญูู ููููุงุณ F1 ูุจูุบ 89.97. ูุฐุงู ููุง ุงููููุงุณุงู ุงููุณุชุฎุฏููู ูุชูููู ุงููุชุงุฆุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช MRPC ููููุงุณ GLUE. ุฃุจูุบ ุงูุฌุฏูู ูู [ูุฑูุฉ BERT](https://arxiv.org/pdf/1810.04805.pdf) ุนู ูููุงุณ F1 ูุจูุบ 88.9 ูููููุฐุฌ ุงูุฃุณุงุณู. ูุงู ุฐูู ูู ุงููููุฐุฌ `uncased` ุจูููุง ูุณุชุฎุฏู ุญุงูููุง ุงููููุฐุฌ `cased`ุ ููุง ููุณุฑ ุงููุชูุฌุฉ ุงูุฃูุถู.

ุจุฌูุน ูู ุดูุก ูุนูุงุ ูุญุตู ุนูู ูุธููุฉ `compute_metrics()` ุงูุฎุงุตุฉ ุจูุง:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```
ููุฑุคูุฉ ุงุณุชุฎุฏุงูู ูู ุงูุฅุจูุงุบ ุนู ุงูููุงููุณ ูู ููุงูุฉ ูู ุญูุจุฉุ ุฅููู ููููุฉ ุชุนุฑูููุง ููุฏุฑุจ `Trainer` ุฌุฏูุฏ ุจูุธููุฉ `compute_metrics()` ูุฐู:

```py
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

ูุงุญุธ ุฃููุง ููุดุฆ `TrainingArguments` ุฌุฏูุฏุฉ ูุน ุฅุนุฏุงุฏ `evaluation_strategy` ุงูุฎุงุต ุจูุง ุฅูู `"epoch"` ููููุฐุฌ ุฌุฏูุฏ - ูุฅูุง ูุฅููุง ุณููุงุตู ููุท ุชุฏุฑูุจ ุงููููุฐุฌ ุงูุฐู ูููุง ุจุชุฏุฑูุจู ุจุงููุนู. ูุจุฏุก ุนูููุฉ ุชุฏุฑูุจ ุฌุฏูุฏุฉุ ูููุฐ:

```py
trainer.train()
```

ูุฐู ุงููุฑุฉุ ุณูููู ุจุงูุฅุจูุงุบ ุนู ุฎุณุงุฑุฉ ุงูุชุญูู ูุงูููุงููุณ ูู ููุงูุฉ ูู ุญูุจุฉ ุจุงูุฅุถุงูุฉ ุฅูู ุฎุณุงุฑุฉ ุงูุชุฏุฑูุจ. ูุฑุฉ ุฃุฎุฑูุ ูุฏ ุชุฎุชูู ุฏูุฉ/ุฏุฑุฌุฉ F1 ุงูุชู ุชุตู ุฅูููุง ููููุงู ุนูุง ูุฌุฏูุงูุ ุจุณุจุจ ุงูุชููุฆุฉ ุงูุนุดูุงุฆูุฉ ููุฑุฃุณ ูู ุงููููุฐุฌุ ูููู ูุฌุจ ุฃู ุชููู ูู ููุณ ุงููุฌุงู.

ุณูุนูู ุงููุฏุฑุจ `Trainer` ูุจุงุดุฑุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPUs) ุฃู ูุญุฏุงุช ูุนุงูุฌุฉ ุงููุตูููุงุช (TPUs) ุงููุชุนุฏุฏุฉุ ููููุฑ ุงููุซูุฑ ูู ุงูุฎูุงุฑุงุชุ ูุซู ุงูุชุฏุฑูุจ ุนุงูู ุงูุฏูุฉ (ุงุณุชุฎุฏู `fp16 = True` ูู ุญุฌุฌ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู). ุณููุฑ ุนูู ูู ูุง ูุฏุนูู ูู ุงููุตู 10.

ูุฐุง ูุฎุชุชู ุงูููุฏูุฉ ูุถุจุท ุงูุฏูุฉ ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช `Trainer` API. ุณูุชู ุชูุฏูู ูุซุงู ุนูู ุงูููุงู ุจุฐูู ููุนุธู ููุงู ูุนุงูุฌุฉ ุงููุบุงุช ุงูุทุจูุนูุฉ ุงูุดุงุฆุนุฉ ูู [ุงููุตู 7] (/course/chapter7)ุ ูููู ุฏุนูุง ูููู ูุธุฑุฉ ุงูุขู ุนูู ููููุฉ ุงูููุงู ุจููุณ ุงูุดูุก ูู ุจุงู ุชูุฑุชุด ุงูููู.

<Tip>

โ๏ธ **ุฌุฑุจูุง!** ูู ุจุถุจุท ุฏูุฉ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช GLUE SST-2ุ ุจุงุณุชุฎุฏุงู ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุชู ููุช ุจูุง ูู ุงููุณู 2.

</Tip>