<FrameworkSwitchCourse {fw} />

# تصحيح أخطاء خط أنابيب التدريب [[debugging-the-training-pipeline]]

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
]} />

لقد كتبت سيناريو جميلًا لتدريب أو ضبط نموذج على مهمة معينة، مع اتباع النصيحة من [الفصل 7](/course/chapter7) بكل دقة. ولكن عندما تطلق الأمر `trainer.train()`، يحدث شيء فظيع: تحصل على خطأ 😱! أو ما هو أسوأ، يبدو أن كل شيء على ما يرام، ويتم التدريب دون أخطاء، ولكن النموذج الناتج سيء. في هذا القسم، سنريكم ما يمكنكم فعله لتصحيح هذه الأنواع من المشاكل.

## تصحيح أخطاء خط أنابيب التدريب [[debugging-the-training-pipeline]]

<Youtube id="L-WSwUWde1U"/>

المشكلة عند مواجهة خطأ في `trainer.train()` هي أنه قد يأتي من مصادر متعددة، حيث أن `Trainer` عادة ما يجمع الكثير من الأشياء. فهو يحول مجموعات البيانات إلى محملات بيانات، لذا قد تكون المشكلة خطأ ما في مجموعة بياناتك، أو مشكلة ما عند محاولة تجميع عناصر مجموعات البيانات معًا. ثم يأخذ دفعة من البيانات ويغذيها إلى النموذج، لذا قد تكون المشكلة في كود النموذج. بعد ذلك، يحسب المشتقات ويؤدي خطوة التحسين، لذا قد تكون المشكلة أيضًا في محسنك. وحتى إذا سار كل شيء على ما يرام للتدريب، قد يحدث خطأ ما أثناء التقييم إذا كان هناك مشكلة في مقياسك.

أفضل طريقة لتصحيح خطأ يحدث في `trainer.train()` هي المرور يدويًا عبر هذا الخط الكامل لرؤية المكان الذي حدثت فيه الأمور بشكل خاطئ. بعد ذلك، يكون الخطأ غالبًا سهل الحل للغاية.

لإثبات ذلك، سنستخدم السيناريو التالي الذي (يحاول) ضبط نموذج DistilBERT على [مجموعة بيانات MNLI](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

إذا حاولت تنفيذه، فستقابل خطأ غامض إلى حد ما:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### تحقق من بياناتك [[check-your-data]]

هذا واضح دون قول، ولكن إذا كانت بياناتك فاسدة، فلن يتمكن `Trainer` من تشكيل دفعات، ناهيك عن تدريب نموذجك. لذا، يجب عليك أولاً وقبل كل شيء، أن تلقي نظرة على ما بداخل مجموعة التدريب الخاصة بك.

لتجنب قضاء ساعات لا حصر لها في محاولة إصلاح شيء ليس مصدر الخطأ، نوصي باستخدام `trainer.train_dataset` لعمليات التحقق الخاصة بك ولا شيء آخر. لذا دعونا نفعل ذلك هنا:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

هل تلاحظ شيئًا خاطئًا؟ هذا، بالإضافة إلى رسالة الخطأ حول `input_ids` المفقودة، يجب أن يجعلك تدرك أن هذه نصوص، وليست أرقامًا يمكن للنموذج فهمها. هنا، الخطأ الأصلي مضلل للغاية لأن `Trainer` يزيل تلقائيًا الأعمدة التي لا تتطابق مع توقيع النموذج (أي الحجج المتوقعة من قبل النموذج). وهذا يعني هنا، تم التخلص من كل شيء باستثناء العلامات. لذا لم تكن هناك مشكلة في إنشاء دفعات ثم إرسالها إلى النموذج، الذي اشتكى بدوره من أنه لم يتلق الإدخال الصحيح.

لماذا لم تتم معالجة البيانات؟ لقد استخدمنا طريقة `Dataset.map()` على مجموعات البيانات لتطبيق المعالج على كل عينة. ولكن إذا نظرت عن كثب إلى الكود، فسترى أننا ارتكبنا خطأً عند تمرير مجموعات التدريب والتقييم إلى `Trainer`. بدلاً من استخدام `tokenized_datasets` هنا، استخدمنا `raw_datasets` 🤦. لذا دعونا نصلح هذا!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

سيمنحك هذا الكود الجديد خطأ مختلفًا الآن (تقدم!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

بالنظر إلى تتبع الخطأ، يمكننا أن نرى أن الخطأ يحدث في خطوة تجميع البيانات:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch
```

لذا، يجب أن ننتقل إلى ذلك. ولكن قبل أن نفعل ذلك، دعونا ننهي فحص بياناتنا، فقط لنكون متأكدين بنسبة 100% من أنها صحيحة.

هناك شيء يجب عليك دائمًا فعله عند تصحيح خطأ في جلسة تدريب وهو إلقاء نظرة على الإدخالات المشفرة لنموذجك. لا يمكننا فهم الأرقام التي نغذيها مباشرة، لذا يجب أن ننظر إلى ما تمثله تلك الأرقام. في الرؤية الحاسوبية، على سبيل المثال، يعني ذلك النظر إلى الصور المشفرة للبكسلات التي تمر بها، في الكلام يعني الاستماع إلى عينات الصوت المشفرة، ولمثال NLP هنا يعني استخدام المعالج الخاص بنا لفك تشفير الإدخالات:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

لذا يبدو ذلك صحيحًا. يجب عليك فعل ذلك لجميع المفاتيح في الإدخالات:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

لاحظ أن المفاتيح التي لا تتطابق مع الإدخالات المقبولة من قبل النموذج سيتم التخلص منها تلقائيًا، لذا هنا سنحتفظ فقط بـ `input_ids`، و`attention_mask`، و`label` (والتي سيتم إعادة تسميتها إلى `labels`). للتحقق المزدوج من توقيع النموذج، يمكنك طباعة فئة نموذجك، ثم التحقق من وثائقه:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

لذلك في حالتنا، يمكننا التحقق من المعاملات المقبولة على [هذه الصفحة](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). كما سيقوم الـ `Trainer` بتسجيل الأعمدة التي يتم تجاهلها.

لقد تحققنا من أن معرفات الإدخال صحيحة من خلال فك تشفيرها. التالي هو `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
إذا كنت تشغل هذا الكود في دفتر ملاحظات، فقد تحصل على خطأ CUDA مشابه للخطأ الذي رأيناه سابقًا، وفي هذه الحالة، ستحتاج إلى إعادة تشغيل دفتر الملاحظات وإعادة تنفيذ المقتطف الأخير بدون سطر `trainer.train()`. هذا هو ثاني أكثر الأشياء إزعاجًا بشأن أخطاء CUDA: فهي تُفسد نواة حاسوبك بشكل لا يمكن إصلاحه. أكثر الأشياء إزعاجًا بشأنها هو أنها صعبة التصحيح.

لماذا؟ هذا له علاقة بطريقة عمل وحدات معالجة الرسومات (GPUs). فهي فعالة للغاية في تنفيذ العديد من العمليات بالتوازي، ولكن العيب هو أنه عندما تؤدي إحدى تلك التعليمات إلى خطأ، لن تعرف ذلك على الفور. فقط عندما يستدعي البرنامج مزامنة العمليات المتعددة على وحدة معالجة الرسومات (GPU) سيدرك أن شيئًا ما قد حدث خطأ، لذا فإن الخطأ يظهر فعليًا في مكان لا علاقة له بما أنشأه. على سبيل المثال، إذا نظرنا إلى تتبع الأخطاء السابق لدينا، فقد ظهر الخطأ أثناء عملية العودة، ولكننا سنرى في دقيقة واحدة أنه ينبع فعليًا من شيء في عملية التغذية الأمامية.

إذن، كيف يمكننا تصحيح هذه الأخطاء؟ الإجابة سهلة: لا نفعل ذلك. ما لم يكن خطأ CUDA لديك هو خطأ نفاد الذاكرة (وهو ما يعني عدم وجود ذاكرة كافية في وحدة معالجة الرسومات (GPU) لديك)، يجب أن تعود دائمًا إلى وحدة المعالجة المركزية (CPU) لتصحيح الخطأ.

لفعل ذلك في حالتنا، علينا فقط إعادة النموذج إلى وحدة المعالجة المركزية (CPU) واستدعاؤه على دفعتنا -- الدفعة التي أعادها `DataLoader` لم يتم نقلها إلى وحدة معالجة الرسومات (GPU) بعد:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

لذا، فإن الصورة أصبحت أكثر وضوحًا. بدلاً من حدوث خطأ CUDA، لدينا الآن `IndexError` في حساب الخسارة (لذا لا علاقة له بعملية العودة، كما ذكرنا سابقًا). وبشكل أكثر دقة، يمكننا أن نرى أن الهدف 2 هو الذي يسبب الخطأ، لذا فهذه لحظة جيدة للتحقق من عدد تسميات نموذجنا:

```python
trainer.model.config.num_labels
```

```python out
2
```

مع وجود تسميتين، يُسمح فقط بالأصفار والواحدات كأهداف، ولكن وفقًا لرسالة الخطأ التي حصلنا عليها، حصلنا على 2. الحصول على 2 هو أمر طبيعي: إذا تذكرنا أسماء التسميات التي استخرجناها سابقًا، كان هناك ثلاثة، لذا لدينا المؤشرات 0 و1 و2 في مجموعتنا البيانات. المشكلة هي أننا لم نخبر ذلك لنموذجنا، والذي كان يجب إنشاؤه بثلاث تسميات. لذا دعنا نصلح ذلك!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

نحن لا نزال لا ندرج سطر `trainer.train()`، لنأخذ الوقت الكافي للتحقق من أن كل شيء يبدو جيدًا. إذا طلبنا دفعة ومررناها إلى نموذجنا، فإنه يعمل الآن بدون خطأ!

```py
for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)
```

الخطوة التالية هي العودة إلى وحدة معالجة الرسومات (GPU) والتحقق من أن كل شيء لا يزال يعمل:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

إذا كنت لا تزال تحصل على خطأ، تأكد من إعادة تشغيل دفتر الملاحظات الخاص بك وتشغيل الإصدار الأخير من النص البرمجي فقط.

### تنفيذ خطوة واحدة للتحسين

الآن بعد أن عرفنا أنه يمكننا بناء دفعات تمر بالفعل عبر النموذج، نحن مستعدون للخطوة التالية في خط أنابيب التدريب: حساب المشتقات وتنفيذ خطوة التحسين.

الجزء الأول هو مجرد مسألة استدعاء طريقة `backward()` على الخسارة:

```py
loss = outputs.loss
loss.backward()
```

من النادر الحصول على خطأ في هذه المرحلة، ولكن إذا حصلت على خطأ، فتأكد من العودة إلى وحدة المعالجة المركزية (CPU) للحصول على رسالة خطأ مفيدة.

لتنفيذ خطوة التحسين، نحتاج فقط إلى إنشاء المحسن واستدعاء طريقة `step()` الخاصة به:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

مرة أخرى، إذا كنت تستخدم المحسن الافتراضي في `Trainer`، فلا يجب أن تحصل على خطأ في هذه المرحلة، ولكن إذا كان لديك محسن مخصص، فقد تكون هناك بعض المشكلات التي تحتاج إلى تصحيح هنا. لا تنسَ العودة إلى وحدة المعالجة المركزية (CPU) إذا حصلت على خطأ غريب في CUDA في هذه المرحلة. وبالحديث عن أخطاء CUDA، ذكرنا سابقًا حالة خاصة. دعنا نلقي نظرة على ذلك الآن.

### التعامل مع أخطاء نفاد الذاكرة في CUDA

في كل مرة تحصل على رسالة خطأ تبدأ بـ `RuntimeError: CUDA out of memory`، فإن هذا يشير إلى أنك نفدت ذاكرة وحدة معالجة الرسومات (GPU). هذا ليس مرتبطًا بشكل مباشر بكودك، ويمكن أن يحدث مع نص برمجي يعمل بشكل مثالي. هذا الخطأ يعني أنك حاولت وضع الكثير من الأشياء في الذاكرة الداخلية لوحدة معالجة الرسومات (GPU) لديك، مما أدى إلى حدوث خطأ. مثل أخطاء CUDA الأخرى، ستحتاج إلى إعادة تشغيل نواة حاسوبك لتكون في مكان يمكنك فيه تشغيل التدريب مرة أخرى.

لحل هذه المشكلة، تحتاج فقط إلى استخدام مساحة أقل لوحدة معالجة الرسومات (GPU) -- وهو أمر غالبًا ما يكون أسهل قولًا من فعله. أولاً، تأكد من عدم وجود نموذجين على وحدة معالجة الرسومات (GPU) في نفس الوقت (ما لم يكن ذلك مطلوبًا لمشكلتك، بالطبع). بعد ذلك، يجب عليك على الأرجح تقليل حجم دفعتك، حيث أنه يؤثر بشكل مباشر على أحجام جميع المخرجات الوسيطة للنموذج ومشتقاتها. إذا استمرت المشكلة، ففكر في استخدام إصدار أصغر من نموذجك.

<Tip>

في الجزء التالي من الدورة التدريبية، سنلقي نظرة على تقنيات أكثر تقدمًا يمكن أن تساعدك على تقليل بصمة الذاكرة الخاصة بك والسماح لك بضبط أكبر النماذج.

</Tip>

### تقييم النموذج

الآن بعد أن حللنا جميع المشكلات في كودنا، كل شيء مثالي ويجب أن يسير التدريب بسلاسة، أليس كذلك؟ ليس بهذه السرعة! إذا قمت بتشغيل أمر `trainer.train()`، فسيبدو كل شيء جيدًا في البداية، ولكن بعد فترة، ستحصل على ما يلي:

```py
# This will take a long time and error out, so you shouldn't run this cell
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

ستدرك أن هذا الخطأ يظهر أثناء مرحلة التقييم، لذا فهذا هو آخر شيء سنحتاج إلى تصحيحه.

يمكنك تشغيل حلقة التقييم الخاصة بـ `Trainer` بشكل مستقل عن التدريب مثل هذا:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```


<Tip>

💡 يجب أن تتأكد دائمًا من إمكانية تشغيل `trainer.evaluate()` قبل تشغيل `trainer.train()`، لتجنب إهدار الكثير من موارد الحوسبة قبل حدوث خطأ.

</Tip>

قبل محاولة تصحيح مشكلة في حلقة التقييم، يجب أن تتأكد أولاً من أنك قد ألقيت نظرة على البيانات، وقادر على تكوين دفعة بشكل صحيح، ويمكنك تشغيل نموذجك عليها. لقد أكملنا كل هذه الخطوات، لذا يمكن تنفيذ الكود التالي بدون أخطاء:

```py
for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)
```

يحدث الخطأ لاحقًا، في نهاية مرحلة التقييم، وإذا نظرنا إلى تتبع الخطأ، سنرى هذا:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431         """
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()
```

هذا يخبرنا أن الخطأ ينشأ في وحدة `datasets/metric.py` -- لذا هذه مشكلة في دالتنا `compute_metrics()`. تأخذ هذه الدالة زوجًا من المصفوفات اللوغاريتمية والتصنيفات كمدخلات، لذا دعنا نحاول إطعامها ذلك:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: يمكن تحويل المصفوفات ذات الحجم 1 فقط إلى مقادير سلمية في بايثون
```

نحصل على نفس الخطأ، لذا فإن المشكلة بالتأكيد تكمن في تلك الدالة. إذا نظرنا إلى كودها مرة أخرى، فإننا نرى أنها تقوم فقط بإعادة توجيه `predictions` و`labels` إلى `metric.compute()`. لذا هل هناك مشكلة في تلك الطريقة؟ ليس حقاً. دعنا نلقي نظرة سريعة على الأشكال:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

توقعاتنا لا تزال لوغاريتمات، وليست التوقعات الفعلية، وهذا هو السبب في أن المقياس يعيد هذا الخطأ (الغامض إلى حد ما). الحل سهل جدًا؛ يجب علينا فقط إضافة argmax في دالة `compute_metrics()`:

```py
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

الآن تم إصلاح خطئنا! كان هذا هو الأخير، لذا فإن نصنا البرمجي سيقوم الآن بتدريب نموذج بشكل صحيح.

للإشارة، إليك النص البرمجي الكامل بعد الإصلاح:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

في هذه الحالة، لا توجد مشاكل أخرى، وسيقوم نصنا البرمجي بتعديل نموذج يجب أن يعطي نتائج معقولة. ولكن ماذا يمكننا أن نفعل عندما يستمر التدريب بدون أي خطأ، ولا يؤدي النموذج المدرب إلى نتائج جيدة على الإطلاق؟ هذا هو الجزء الأصعب في التعلم الآلي، وسنريكم بعض التقنيات التي يمكن أن تساعد.

<Tip>

💡 إذا كنت تستخدم حلقة تدريب يدوية، تنطبق نفس الخطوات لتصحيح خط أنابيب التدريب الخاصة بك، ولكن من الأسهل فصلها. تأكد من أنك لم تنس `model.eval()` أو `model.train()` في الأماكن الصحيحة، أو `zero_grad()` في كل خطوة!

</Tip>

## تصحيح الأخطاء الصامتة أثناء التدريب[[debugging-silent-errors-during-training]]

ماذا يمكننا أن نفعل لتصحيح تدريب يكتمل بدون أخطاء ولكن لا يحقق نتائج جيدة؟ سنعطيك بعض الإرشادات هنا، ولكن كن على دراية بأن هذا النوع من التصحيح هو الجزء الأصعب في التعلم الآلي، ولا يوجد إجابة سحرية.

### تحقق من بياناتك (مرة أخرى!)[[check-your-data-again]]

لن يتعلم نموذجك شيئًا إلا إذا كان من الممكن بالفعل تعلم أي شيء من بياناتك. إذا كان هناك خطأ يؤدي إلى تلف البيانات أو يتم تعيين التصنيفات عشوائيًا، فمن المحتمل جدًا ألا تحصل على أي تدريب للنموذج على مجموعة بياناتك. لذا ابدأ دائمًا بالتحقق المزدوج من مدخلاتك وعلاماتك المشفرة، واسأل نفسك الأسئلة التالية:

- هل البيانات المشفرة مفهومة؟
- هل توافق على التصنيفات؟
- هل هناك تصنيف واحد أكثر شيوعًا من التصنيفات الأخرى؟
- ما هي الخسارة/المقياس الذي يجب أن يكون عليه إذا تنبأ النموذج بإجابة عشوائية/نفس الإجابة دائمًا؟

<Tip warning={true}>

⚠️ إذا كنت تقوم بتدريب موزع، فقم بطباعة عينات من مجموعة بياناتك في كل عملية وتحقق ثلاث مرات من أنك تحصل على نفس الشيء. أحد الأخطاء الشائعة هو وجود مصدر عشوائي في إنشاء البيانات مما يجعل كل عملية لديها نسخة مختلفة من مجموعة البيانات.

</Tip>

بعد النظر إلى بياناتك، مر عبر بعض تنبؤات النموذج وقم بتشفيرها أيضًا. إذا كان النموذج يتنبأ دائمًا بنفس الشيء، فقد يكون ذلك لأن مجموعة بياناتك متحيزة نحو فئة واحدة (لمشاكل التصنيف)؛ قد تساعد التقنيات مثل الإفراط في أخذ عينات من الفئات النادرة.

إذا كانت الخسارة/المقياس الذي تحصل عليه في نموذجك الأولي مختلف جدًا عن الخسارة/المقياس الذي تتوقعه للتنبؤات العشوائية، فقم بالتحقق المزدوج من طريقة حساب الخسارة أو المقياس، حيث من المحتمل أن يكون هناك خطأ هناك. إذا كنت تستخدم عدة خسائر تضيفها في النهاية، فتأكد من أنها بنفس المقياس.

عندما تكون متأكدًا من أن بياناتك مثالية، يمكنك أن ترى ما إذا كان النموذج قادرًا على التدريب عليها باختبار بسيط واحد.

### قم بضبط نموذجك على دفعة واحدة[[overfit-your-model-on-one-batch]]

الضبط المفرط هو عادة شيء نحاول تجنبه عند التدريب، لأنه يعني أن النموذج لا يتعلم التعرف على الميزات العامة التي نريد منه أن يتعلمها، ولكنه بدلاً من ذلك يقوم فقط بحفظ عينات التدريب. ومع ذلك، فإن محاولة تدريب نموذجك على دفعة واحدة مرارًا وتكرارًا هو اختبار جيد للتحقق مما إذا كانت المشكلة كما صغتها يمكن حلها بواسطة النموذج الذي تحاول تدريبه. سيساعدك ذلك أيضًا على رؤية ما إذا كان معدل التعلم الأولي الخاص بك مرتفعًا جدًا.

القيام بذلك بمجرد تحديد `Trainer` الخاص بك سهل للغاية؛ فقط احصل على دفعة من بيانات التدريب، ثم قم بتشغيل حلقة تدريب يدوية صغيرة باستخدام تلك الدفعة فقط لشيء مثل 20 خطوة:

```py
for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()
```

<Tip>

💡 إذا كانت بيانات التدريب غير متوازنة، فتأكد من بناء دفعة من بيانات التدريب تحتوي على جميع التصنيفات.

</Tip>

يجب أن يكون النموذج الناتج ذو نتائج قريبة من الكمال على نفس `batch`. دعنا نحسب المقياس على التنبؤات الناتجة:

```py
with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```


100% دقة، هذا مثال جيد على الإفراط في الملاءمة (بمعنى أنه إذا قمت بتجربة نموذجك على أي جملة أخرى، فمن المحتمل جدًا أن يعطيك إجابة خاطئة)!

إذا لم تتمكن من الحصول على نتائج مثالية مثل هذه من نموذجك، فهذا يعني أن هناك خطأ ما في طريقة صياغتك للمشكلة أو بياناتك، لذا يجب عليك إصلاح ذلك. فقط عندما تتمكن من اجتياز اختبار الإفراط في الملاءمة، يمكنك التأكد من أن نموذجك قادر فعليًا على التعلم.

<Tip warning={true}>

⚠️ سيتعين عليك إعادة إنشاء نموذجك و`Trainer` بعد هذا الاختبار، حيث من المحتمل ألا يتمكن النموذج الذي تم الحصول عليه من التعافي والتعلم بشكل مفيد على مجموعة البيانات الكاملة الخاصة بك.

</Tip>

### لا تضبط أي شيء حتى يكون لديك خط أساس أول [[dont-tune-anything-until-you-have-a-first-baseline]]

يتم التأكيد دائمًا على ضبط فرط المعلمات على أنه الجزء الأصعب في التعلم الآلي، ولكنه مجرد الخطوة الأخيرة لمساعدتك في تحقيق القليل من المكاسب على المقياس. في معظم الأوقات، ستعمل فرط المعلمات الافتراضية لـ`Trainer` بشكل جيد لإعطائك نتائج جيدة، لذا لا تبدأ في عملية بحث مكلفة وتستغرق وقتًا طويلاً عن فرط المعلمات حتى يكون لديك شيء يتفوق على خط الأساس الذي لديك على مجموعة البيانات الخاصة بك.

بمجرد حصولك على نموذج جيد بما فيه الكفاية، يمكنك البدء في إجراء بعض التعديلات. لا تحاول إطلاق ألف عملية بفرط معلمات مختلفة، ولكن قارن بين بضع عمليات بفرط معلمات مختلفة للحصول على فكرة عن التأثير الأكبر.

إذا كنت تقوم بتعديل النموذج نفسه، أبقه بسيطًا ولا تحاول أي شيء لا يمكنك تبريره بشكل معقول. تأكد دائمًا من العودة إلى اختبار الإفراط في الملاءمة للتحقق من أن التغيير الذي أجريته لم يكن له أي عواقب غير مقصودة.

### اطلب المساعدة [[ask-for-help]]

نأمل أن تكون قد وجدت بعض النصائح في هذا القسم التي ساعدتك في حل مشكلتك، ولكن إذا لم يكن الأمر كذلك، تذكر أنه يمكنك دائمًا طلب المساعدة من المجتمع على [المنتديات](https://discuss.huggingface.co/).

هنا بعض الموارد الإضافية التي قد تكون مفيدة:

- ["القابلية للتكرار كوسيلة لأفضل الممارسات الهندسية"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) بواسطة جويل جروس
- ["قائمة مراجعة لتصحيح أخطاء الشبكات العصبية"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) بواسطة سيسيليا شاو
- ["كيفية اختبار وحدة التعلم الآلي"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) بواسطة تشيس روبرتس
- ["وصفة لتدريب الشبكات العصبية"](http://karpathy.github.io/2019/04/25/recipe/) بواسطة أندري كارباثي

بالطبع، ليست كل مشكلة تواجهها عند تدريب الشبكات العصبية هي خطأك! إذا واجهت شيئًا في مكتبة 🤗 Transformers أو 🤗 Datasets لا يبدو صحيحًا، فقد تكون قد واجهت خللًا. يجب عليك بالتأكيد إخبارنا بكل شيء عنه، وفي القسم التالي سنشرح بالضبط كيفية القيام بذلك.