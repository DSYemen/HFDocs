<FrameworkSwitchCourse {fw} />

# ุชุตุญูุญ ุฃุฎุทุงุก ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ [[debugging-the-training-pipeline]]

<CourseFloatingBanner chapter={8}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter8/section4.ipynb"},
]} />

ููุฏ ูุชุจุช ุณููุงุฑูู ุฌููููุง ูุชุฏุฑูุจ ุฃู ุถุจุท ูููุฐุฌ ุนูู ูููุฉ ูุนููุฉุ ูุน ุงุชุจุงุน ุงููุตูุญุฉ ูู [ุงููุตู 7](/course/chapter7) ุจูู ุฏูุฉ. ูููู ุนูุฏูุง ุชุทูู ุงูุฃูุฑ `trainer.train()`ุ ูุญุฏุซ ุดูุก ูุธูุน: ุชุญุตู ุนูู ุฎุทุฃ ๐ฑ! ุฃู ูุง ูู ุฃุณูุฃุ ูุจุฏู ุฃู ูู ุดูุก ุนูู ูุง ูุฑุงูุ ููุชู ุงูุชุฏุฑูุจ ุฏูู ุฃุฎุทุงุกุ ูููู ุงููููุฐุฌ ุงููุงุชุฌ ุณูุก. ูู ูุฐุง ุงููุณูุ ุณูุฑููู ูุง ูููููู ูุนูู ูุชุตุญูุญ ูุฐู ุงูุฃููุงุน ูู ุงููุดุงูู.

## ุชุตุญูุญ ุฃุฎุทุงุก ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ [[debugging-the-training-pipeline]]

<Youtube id="L-WSwUWde1U"/>

ุงููุดููุฉ ุนูุฏ ููุงุฌูุฉ ุฎุทุฃ ูู `trainer.train()` ูู ุฃูู ูุฏ ูุฃุชู ูู ูุตุงุฏุฑ ูุชุนุฏุฏุฉุ ุญูุซ ุฃู `Trainer` ุนุงุฏุฉ ูุง ูุฌูุน ุงููุซูุฑ ูู ุงูุฃุดูุงุก. ููู ูุญูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุฅูู ูุญููุงุช ุจูุงูุงุชุ ูุฐุง ูุฏ ุชููู ุงููุดููุฉ ุฎุทุฃ ูุง ูู ูุฌููุนุฉ ุจูุงูุงุชูุ ุฃู ูุดููุฉ ูุง ุนูุฏ ูุญุงููุฉ ุชุฌููุน ุนูุงุตุฑ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุนูุง. ุซู ูุฃุฎุฐ ุฏูุนุฉ ูู ุงูุจูุงูุงุช ููุบุฐููุง ุฅูู ุงููููุฐุฌุ ูุฐุง ูุฏ ุชููู ุงููุดููุฉ ูู ููุฏ ุงููููุฐุฌ. ุจุนุฏ ุฐููุ ูุญุณุจ ุงููุดุชูุงุช ููุคุฏู ุฎุทูุฉ ุงูุชุญุณููุ ูุฐุง ูุฏ ุชููู ุงููุดููุฉ ุฃูุถูุง ูู ูุญุณูู. ูุญุชู ุฅุฐุง ุณุงุฑ ูู ุดูุก ุนูู ูุง ูุฑุงู ููุชุฏุฑูุจุ ูุฏ ูุญุฏุซ ุฎุทุฃ ูุง ุฃุซูุงุก ุงูุชูููู ุฅุฐุง ูุงู ููุงู ูุดููุฉ ูู ูููุงุณู.

ุฃูุถู ุทุฑููุฉ ูุชุตุญูุญ ุฎุทุฃ ูุญุฏุซ ูู `trainer.train()` ูู ุงููุฑูุฑ ูุฏูููุง ุนุจุฑ ูุฐุง ุงูุฎุท ุงููุงูู ูุฑุคูุฉ ุงูููุงู ุงูุฐู ุญุฏุซุช ููู ุงูุฃููุฑ ุจุดูู ุฎุงุทุฆ. ุจุนุฏ ุฐููุ ูููู ุงูุฎุทุฃ ุบุงูุจูุง ุณูู ุงูุญู ููุบุงูุฉ.

ูุฅุซุจุงุช ุฐููุ ุณูุณุชุฎุฏู ุงูุณููุงุฑูู ุงูุชุงูู ุงูุฐู (ูุญุงูู) ุถุจุท ูููุฐุฌ DistilBERT ุนูู [ูุฌููุนุฉ ุจูุงูุงุช MNLI](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

ุฅุฐุง ุญุงููุช ุชูููุฐูุ ูุณุชูุงุจู ุฎุทุฃ ุบุงูุถ ุฅูู ุญุฏ ูุง:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### ุชุญูู ูู ุจูุงูุงุชู [[check-your-data]]

ูุฐุง ูุงุถุญ ุฏูู ูููุ ูููู ุฅุฐุง ูุงูุช ุจูุงูุงุชู ูุงุณุฏุฉุ ููู ูุชููู `Trainer` ูู ุชุดููู ุฏูุนุงุชุ ูุงููู ุนู ุชุฏุฑูุจ ูููุฐุฌู. ูุฐุงุ ูุฌุจ ุนููู ุฃููุงู ููุจู ูู ุดูุกุ ุฃู ุชููู ูุธุฑุฉ ุนูู ูุง ุจุฏุงุฎู ูุฌููุนุฉ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู.

ูุชุฌูุจ ูุถุงุก ุณุงุนุงุช ูุง ุญุตุฑ ููุง ูู ูุญุงููุฉ ุฅุตูุงุญ ุดูุก ููุณ ูุตุฏุฑ ุงูุฎุทุฃุ ููุตู ุจุงุณุชุฎุฏุงู `trainer.train_dataset` ูุนูููุงุช ุงูุชุญูู ุงูุฎุงุตุฉ ุจู ููุง ุดูุก ุขุฎุฑ. ูุฐุง ุฏุนููุง ููุนู ุฐูู ููุง:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

ูู ุชูุงุญุธ ุดูุฆูุง ุฎุงุทุฆูุงุ ูุฐุงุ ุจุงูุฅุถุงูุฉ ุฅูู ุฑุณุงูุฉ ุงูุฎุทุฃ ุญูู `input_ids` ุงูููููุฏุฉุ ูุฌุจ ุฃู ูุฌุนูู ุชุฏุฑู ุฃู ูุฐู ูุตูุตุ ูููุณุช ุฃุฑูุงููุง ูููู ูููููุฐุฌ ููููุง. ููุงุ ุงูุฎุทุฃ ุงูุฃุตูู ูุถูู ููุบุงูุฉ ูุฃู `Trainer` ูุฒูู ุชููุงุฆููุง ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุชุทุงุจู ูุน ุชูููุน ุงููููุฐุฌ (ุฃู ุงูุญุฌุฌ ุงููุชููุนุฉ ูู ูุจู ุงููููุฐุฌ). ููุฐุง ูุนูู ููุงุ ุชู ุงูุชุฎูุต ูู ูู ุดูุก ุจุงุณุชุซูุงุก ุงูุนูุงูุงุช. ูุฐุง ูู ุชูู ููุงู ูุดููุฉ ูู ุฅูุดุงุก ุฏูุนุงุช ุซู ุฅุฑุณุงููุง ุฅูู ุงููููุฐุฌุ ุงูุฐู ุงุดุชูู ุจุฏูุฑู ูู ุฃูู ูู ูุชูู ุงูุฅุฏุฎุงู ุงูุตุญูุญ.

ููุงุฐุง ูู ุชุชู ูุนุงูุฌุฉ ุงูุจูุงูุงุชุ ููุฏ ุงุณุชุฎุฏููุง ุทุฑููุฉ `Dataset.map()` ุนูู ูุฌููุนุงุช ุงูุจูุงูุงุช ูุชุทุจูู ุงููุนุงูุฌ ุนูู ูู ุนููุฉ. ูููู ุฅุฐุง ูุธุฑุช ุนู ูุซุจ ุฅูู ุงูููุฏุ ูุณุชุฑู ุฃููุง ุงุฑุชูุจูุง ุฎุทุฃู ุนูุฏ ุชูุฑูุฑ ูุฌููุนุงุช ุงูุชุฏุฑูุจ ูุงูุชูููู ุฅูู `Trainer`. ุจุฏูุงู ูู ุงุณุชุฎุฏุงู `tokenized_datasets` ููุงุ ุงุณุชุฎุฏููุง `raw_datasets` ๐คฆ. ูุฐุง ุฏุนููุง ูุตูุญ ูุฐุง!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()
```

ุณูููุญู ูุฐุง ุงูููุฏ ุงูุฌุฏูุฏ ุฎุทุฃ ูุฎุชูููุง ุงูุขู (ุชูุฏู!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

ุจุงููุธุฑ ุฅูู ุชุชุจุน ุงูุฎุทุฃุ ูููููุง ุฃู ูุฑู ุฃู ุงูุฎุทุฃ ูุญุฏุซ ูู ุฎุทูุฉ ุชุฌููุน ุงูุจูุงูุงุช:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch
```

ูุฐุงุ ูุฌุจ ุฃู ููุชูู ุฅูู ุฐูู. ูููู ูุจู ุฃู ููุนู ุฐููุ ุฏุนููุง ูููู ูุญุต ุจูุงูุงุชูุงุ ููุท ููููู ูุชุฃูุฏูู ุจูุณุจุฉ 100% ูู ุฃููุง ุตุญูุญุฉ.

ููุงู ุดูุก ูุฌุจ ุนููู ุฏุงุฆููุง ูุนูู ุนูุฏ ุชุตุญูุญ ุฎุทุฃ ูู ุฌูุณุฉ ุชุฏุฑูุจ ููู ุฅููุงุก ูุธุฑุฉ ุนูู ุงูุฅุฏุฎุงูุงุช ุงููุดูุฑุฉ ููููุฐุฌู. ูุง ูููููุง ููู ุงูุฃุฑูุงู ุงูุชู ูุบุฐููุง ูุจุงุดุฑุฉุ ูุฐุง ูุฌุจ ุฃู ููุธุฑ ุฅูู ูุง ุชูุซูู ุชูู ุงูุฃุฑูุงู. ูู ุงูุฑุคูุฉ ุงูุญุงุณูุจูุฉุ ุนูู ุณุจูู ุงููุซุงูุ ูุนูู ุฐูู ุงููุธุฑ ุฅูู ุงูุตูุฑ ุงููุดูุฑุฉ ููุจูุณูุงุช ุงูุชู ุชูุฑ ุจูุงุ ูู ุงูููุงู ูุนูู ุงูุงุณุชูุงุน ุฅูู ุนููุงุช ุงูุตูุช ุงููุดูุฑุฉุ ูููุซุงู NLP ููุง ูุนูู ุงุณุชุฎุฏุงู ุงููุนุงูุฌ ุงูุฎุงุต ุจูุง ููู ุชุดููุฑ ุงูุฅุฏุฎุงูุงุช:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

ูุฐุง ูุจุฏู ุฐูู ุตุญูุญูุง. ูุฌุจ ุนููู ูุนู ุฐูู ูุฌููุน ุงูููุงุชูุญ ูู ุงูุฅุฏุฎุงูุงุช:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

ูุงุญุธ ุฃู ุงูููุงุชูุญ ุงูุชู ูุง ุชุชุทุงุจู ูุน ุงูุฅุฏุฎุงูุงุช ุงูููุจููุฉ ูู ูุจู ุงููููุฐุฌ ุณูุชู ุงูุชุฎูุต ูููุง ุชููุงุฆููุงุ ูุฐุง ููุง ุณูุญุชูุธ ููุท ุจู `input_ids`ุ ู`attention_mask`ุ ู`label` (ูุงูุชู ุณูุชู ุฅุนุงุฏุฉ ุชุณููุชูุง ุฅูู `labels`). ููุชุญูู ุงููุฒุฏูุฌ ูู ุชูููุน ุงููููุฐุฌุ ููููู ุทุจุงุนุฉ ูุฆุฉ ูููุฐุฌูุ ุซู ุงูุชุญูู ูู ูุซุงุฆูู:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

ูุฐูู ูู ุญุงูุชูุงุ ูููููุง ุงูุชุญูู ูู ุงููุนุงููุงุช ุงูููุจููุฉ ุนูู [ูุฐู ุงูุตูุญุฉ](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). ููุง ุณูููู ุงูู `Trainer` ุจุชุณุฌูู ุงูุฃุนูุฏุฉ ุงูุชู ูุชู ุชุฌุงูููุง.

ููุฏ ุชุญูููุง ูู ุฃู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุตุญูุญุฉ ูู ุฎูุงู ูู ุชุดููุฑูุง. ุงูุชุงูู ูู `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
ุฅุฐุง ููุช ุชุดุบู ูุฐุง ุงูููุฏ ูู ุฏูุชุฑ ููุงุญุธุงุชุ ููุฏ ุชุญุตู ุนูู ุฎุทุฃ CUDA ูุดุงุจู ููุฎุทุฃ ุงูุฐู ุฑุฃููุงู ุณุงุจููุงุ ููู ูุฐู ุงูุญุงูุฉุ ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดุบูู ุฏูุชุฑ ุงูููุงุญุธุงุช ูุฅุนุงุฏุฉ ุชูููุฐ ุงูููุชุทู ุงูุฃุฎูุฑ ุจุฏูู ุณุทุฑ `trainer.train()`. ูุฐุง ูู ุซุงูู ุฃูุซุฑ ุงูุฃุดูุงุก ุฅุฒุนุงุฌูุง ุจุดุฃู ุฃุฎุทุงุก CUDA: ููู ุชููุณุฏ ููุงุฉ ุญุงุณูุจู ุจุดูู ูุง ูููู ุฅุตูุงุญู. ุฃูุซุฑ ุงูุฃุดูุงุก ุฅุฒุนุงุฌูุง ุจุดุฃููุง ูู ุฃููุง ุตุนุจุฉ ุงูุชุตุญูุญ.

ููุงุฐุงุ ูุฐุง ูู ุนูุงูุฉ ุจุทุฑููุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPUs). ููู ูุนุงูุฉ ููุบุงูุฉ ูู ุชูููุฐ ุงูุนุฏูุฏ ูู ุงูุนูููุงุช ุจุงูุชูุงุฒูุ ูููู ุงูุนูุจ ูู ุฃูู ุนูุฏูุง ุชุคุฏู ุฅุญุฏู ุชูู ุงูุชุนูููุงุช ุฅูู ุฎุทุฃุ ูู ุชุนุฑู ุฐูู ุนูู ุงูููุฑ. ููุท ุนูุฏูุง ูุณุชุฏุนู ุงูุจุฑูุงูุฌ ูุฒุงููุฉ ุงูุนูููุงุช ุงููุชุนุฏุฏุฉ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุณูุฏุฑู ุฃู ุดูุฆูุง ูุง ูุฏ ุญุฏุซ ุฎุทุฃุ ูุฐุง ูุฅู ุงูุฎุทุฃ ูุธูุฑ ูุนูููุง ูู ููุงู ูุง ุนูุงูุฉ ูู ุจูุง ุฃูุดุฃู. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุธุฑูุง ุฅูู ุชุชุจุน ุงูุฃุฎุทุงุก ุงูุณุงุจู ูุฏููุงุ ููุฏ ุธูุฑ ุงูุฎุทุฃ ุฃุซูุงุก ุนูููุฉ ุงูุนูุฏุฉุ ูููููุง ุณูุฑู ูู ุฏูููุฉ ูุงุญุฏุฉ ุฃูู ููุจุน ูุนูููุง ูู ุดูุก ูู ุนูููุฉ ุงูุชุบุฐูุฉ ุงูุฃูุงููุฉ.

ุฅุฐูุ ููู ูููููุง ุชุตุญูุญ ูุฐู ุงูุฃุฎุทุงุกุ ุงูุฅุฌุงุจุฉ ุณููุฉ: ูุง ููุนู ุฐูู. ูุง ูู ููู ุฎุทุฃ CUDA ูุฏูู ูู ุฎุทุฃ ููุงุฏ ุงูุฐุงูุฑุฉ (ููู ูุง ูุนูู ุนุฏู ูุฌูุฏ ุฐุงูุฑุฉ ูุงููุฉ ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุฏูู)ุ ูุฌุจ ุฃู ุชุนูุฏ ุฏุงุฆููุง ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ูุชุตุญูุญ ุงูุฎุทุฃ.

ููุนู ุฐูู ูู ุญุงูุชูุงุ ุนูููุง ููุท ุฅุนุงุฏุฉ ุงููููุฐุฌ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ูุงุณุชุฏุนุงุคู ุนูู ุฏูุนุชูุง -- ุงูุฏูุนุฉ ุงูุชู ุฃุนุงุฏูุง `DataLoader` ูู ูุชู ููููุง ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุจุนุฏ:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

ูุฐุงุ ูุฅู ุงูุตูุฑุฉ ุฃุตุจุญุช ุฃูุซุฑ ูุถูุญูุง. ุจุฏูุงู ูู ุญุฏูุซ ุฎุทุฃ CUDAุ ูุฏููุง ุงูุขู `IndexError` ูู ุญุณุงุจ ุงูุฎุณุงุฑุฉ (ูุฐุง ูุง ุนูุงูุฉ ูู ุจุนูููุฉ ุงูุนูุฏุฉุ ููุง ุฐูุฑูุง ุณุงุจููุง). ูุจุดูู ุฃูุซุฑ ุฏูุฉุ ูููููุง ุฃู ูุฑู ุฃู ุงููุฏู 2 ูู ุงูุฐู ูุณุจุจ ุงูุฎุทุฃุ ูุฐุง ููุฐู ูุญุธุฉ ุฌูุฏุฉ ููุชุญูู ูู ุนุฏุฏ ุชุณููุงุช ูููุฐุฌูุง:

```python
trainer.model.config.num_labels
```

```python out
2
```

ูุน ูุฌูุฏ ุชุณููุชููุ ููุณูุญ ููุท ุจุงูุฃุตูุงุฑ ูุงููุงุญุฏุงุช ูุฃูุฏุงูุ ูููู ููููุง ูุฑุณุงูุฉ ุงูุฎุทุฃ ุงูุชู ุญุตููุง ุนูููุงุ ุญุตููุง ุนูู 2. ุงูุญุตูู ุนูู 2 ูู ุฃูุฑ ุทุจูุนู: ุฅุฐุง ุชุฐูุฑูุง ุฃุณูุงุก ุงูุชุณููุงุช ุงูุชู ุงุณุชุฎุฑุฌูุงูุง ุณุงุจููุงุ ูุงู ููุงู ุซูุงุซุฉุ ูุฐุง ูุฏููุง ุงููุคุดุฑุงุช 0 ู1 ู2 ูู ูุฌููุนุชูุง ุงูุจูุงูุงุช. ุงููุดููุฉ ูู ุฃููุง ูู ูุฎุจุฑ ุฐูู ููููุฐุฌูุงุ ูุงูุฐู ูุงู ูุฌุจ ุฅูุดุงุคู ุจุซูุงุซ ุชุณููุงุช. ูุฐุง ุฏุนูุง ูุตูุญ ุฐูู!

```py
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

ูุญู ูุง ูุฒุงู ูุง ูุฏุฑุฌ ุณุทุฑ `trainer.train()`ุ ููุฃุฎุฐ ุงูููุช ุงููุงูู ููุชุญูู ูู ุฃู ูู ุดูุก ูุจุฏู ุฌูุฏูุง. ุฅุฐุง ุทูุจูุง ุฏูุนุฉ ููุฑุฑูุงูุง ุฅูู ูููุฐุฌูุงุ ูุฅูู ูุนูู ุงูุขู ุจุฏูู ุฎุทุฃ!

```py
for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)
```

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุงูุชุญูู ูู ุฃู ูู ุดูุก ูุง ูุฒุงู ูุนูู:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

ุฅุฐุง ููุช ูุง ุชุฒุงู ุชุญุตู ุนูู ุฎุทุฃุ ุชุฃูุฏ ูู ุฅุนุงุฏุฉ ุชุดุบูู ุฏูุชุฑ ุงูููุงุญุธุงุช ุงูุฎุงุต ุจู ูุชุดุบูู ุงูุฅุตุฏุงุฑ ุงูุฃุฎูุฑ ูู ุงููุต ุงูุจุฑูุฌู ููุท.

### ุชูููุฐ ุฎุทูุฉ ูุงุญุฏุฉ ููุชุญุณูู

ุงูุขู ุจุนุฏ ุฃู ุนุฑููุง ุฃูู ูููููุง ุจูุงุก ุฏูุนุงุช ุชูุฑ ุจุงููุนู ุนุจุฑ ุงููููุฐุฌุ ูุญู ูุณุชุนุฏูู ููุฎุทูุฉ ุงูุชุงููุฉ ูู ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ: ุญุณุงุจ ุงููุดุชูุงุช ูุชูููุฐ ุฎุทูุฉ ุงูุชุญุณูู.

ุงูุฌุฒุก ุงูุฃูู ูู ูุฌุฑุฏ ูุณุฃูุฉ ุงุณุชุฏุนุงุก ุทุฑููุฉ `backward()` ุนูู ุงูุฎุณุงุฑุฉ:

```py
loss = outputs.loss
loss.backward()
```

ูู ุงููุงุฏุฑ ุงูุญุตูู ุนูู ุฎุทุฃ ูู ูุฐู ุงููุฑุญูุฉุ ูููู ุฅุฐุง ุญุตูุช ุนูู ุฎุทุฃุ ูุชุฃูุฏ ูู ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ููุญุตูู ุนูู ุฑุณุงูุฉ ุฎุทุฃ ูููุฏุฉ.

ูุชูููุฐ ุฎุทูุฉ ุงูุชุญุณููุ ูุญุชุงุฌ ููุท ุฅูู ุฅูุดุงุก ุงููุญุณู ูุงุณุชุฏุนุงุก ุทุฑููุฉ `step()` ุงูุฎุงุตุฉ ุจู:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

ูุฑุฉ ุฃุฎุฑูุ ุฅุฐุง ููุช ุชุณุชุฎุฏู ุงููุญุณู ุงูุงูุชุฑุงุถู ูู `Trainer`ุ ููุง ูุฌุจ ุฃู ุชุญุตู ุนูู ุฎุทุฃ ูู ูุฐู ุงููุฑุญูุฉุ ูููู ุฅุฐุง ูุงู ูุฏูู ูุญุณู ูุฎุตุตุ ููุฏ ุชููู ููุงู ุจุนุถ ุงููุดููุงุช ุงูุชู ุชุญุชุงุฌ ุฅูู ุชุตุญูุญ ููุง. ูุง ุชูุณู ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ุฅุฐุง ุญุตูุช ุนูู ุฎุทุฃ ุบุฑูุจ ูู CUDA ูู ูุฐู ุงููุฑุญูุฉ. ูุจุงูุญุฏูุซ ุนู ุฃุฎุทุงุก CUDAุ ุฐูุฑูุง ุณุงุจููุง ุญุงูุฉ ุฎุงุตุฉ. ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ุฐูู ุงูุขู.

### ุงูุชุนุงูู ูุน ุฃุฎุทุงุก ููุงุฏ ุงูุฐุงูุฑุฉ ูู CUDA

ูู ูู ูุฑุฉ ุชุญุตู ุนูู ุฑุณุงูุฉ ุฎุทุฃ ุชุจุฏุฃ ุจู `RuntimeError: CUDA out of memory`ุ ูุฅู ูุฐุง ูุดูุฑ ุฅูู ุฃูู ููุฏุช ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU). ูุฐุง ููุณ ูุฑุชุจุทูุง ุจุดูู ูุจุงุดุฑ ุจููุฏูุ ููููู ุฃู ูุญุฏุซ ูุน ูุต ุจุฑูุฌู ูุนูู ุจุดูู ูุซุงูู. ูุฐุง ุงูุฎุทุฃ ูุนูู ุฃูู ุญุงููุช ูุถุน ุงููุซูุฑ ูู ุงูุฃุดูุงุก ูู ุงูุฐุงูุฑุฉ ุงูุฏุงุฎููุฉ ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุฏููุ ููุง ุฃุฏู ุฅูู ุญุฏูุซ ุฎุทุฃ. ูุซู ุฃุฎุทุงุก CUDA ุงูุฃุฎุฑูุ ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดุบูู ููุงุฉ ุญุงุณูุจู ูุชููู ูู ููุงู ููููู ููู ุชุดุบูู ุงูุชุฏุฑูุจ ูุฑุฉ ุฃุฎุฑู.

ูุญู ูุฐู ุงููุดููุฉุ ุชุญุชุงุฌ ููุท ุฅูู ุงุณุชุฎุฏุงู ูุณุงุญุฉ ุฃูู ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) -- ููู ุฃูุฑ ุบุงูุจูุง ูุง ูููู ุฃุณูู ููููุง ูู ูุนูู. ุฃููุงูุ ุชุฃูุฏ ูู ุนุฏู ูุฌูุฏ ูููุฐุฌูู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูู ููุณ ุงูููุช (ูุง ูู ููู ุฐูู ูุทููุจูุง ููุดููุชูุ ุจุงูุทุจุน). ุจุนุฏ ุฐููุ ูุฌุจ ุนููู ุนูู ุงูุฃุฑุฌุญ ุชูููู ุญุฌู ุฏูุนุชูุ ุญูุซ ุฃูู ูุคุซุฑ ุจุดูู ูุจุงุดุฑ ุนูู ุฃุญุฌุงู ุฌููุน ุงููุฎุฑุฌุงุช ุงููุณูุทุฉ ูููููุฐุฌ ููุดุชูุงุชูุง. ุฅุฐุง ุงุณุชูุฑุช ุงููุดููุฉุ ูููุฑ ูู ุงุณุชุฎุฏุงู ุฅุตุฏุงุฑ ุฃุตุบุฑ ูู ูููุฐุฌู.

<Tip>

ูู ุงูุฌุฒุก ุงูุชุงูู ูู ุงูุฏูุฑุฉ ุงูุชุฏุฑูุจูุฉุ ุณูููู ูุธุฑุฉ ุนูู ุชูููุงุช ุฃูุซุฑ ุชูุฏููุง ูููู ุฃู ุชุณุงุนุฏู ุนูู ุชูููู ุจุตูุฉ ุงูุฐุงูุฑุฉ ุงูุฎุงุตุฉ ุจู ูุงูุณูุงุญ ูู ุจุถุจุท ุฃูุจุฑ ุงูููุงุฐุฌ.

</Tip>

### ุชูููู ุงููููุฐุฌ

ุงูุขู ุจุนุฏ ุฃู ุญูููุง ุฌููุน ุงููุดููุงุช ูู ููุฏูุงุ ูู ุดูุก ูุซุงูู ููุฌุจ ุฃู ูุณูุฑ ุงูุชุฏุฑูุจ ุจุณูุงุณุฉุ ุฃููุณ ูุฐููุ ููุณ ุจูุฐู ุงูุณุฑุนุฉ! ุฅุฐุง ููุช ุจุชุดุบูู ุฃูุฑ `trainer.train()`ุ ูุณูุจุฏู ูู ุดูุก ุฌูุฏูุง ูู ุงูุจุฏุงูุฉุ ูููู ุจุนุฏ ูุชุฑุฉุ ุณุชุญุตู ุนูู ูุง ููู:

```py
# This will take a long time and error out, so you shouldn't run this cell
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

ุณุชุฏุฑู ุฃู ูุฐุง ุงูุฎุทุฃ ูุธูุฑ ุฃุซูุงุก ูุฑุญูุฉ ุงูุชููููุ ูุฐุง ููุฐุง ูู ุขุฎุฑ ุดูุก ุณูุญุชุงุฌ ุฅูู ุชุตุญูุญู.

ููููู ุชุดุบูู ุญููุฉ ุงูุชูููู ุงูุฎุงุตุฉ ุจู `Trainer` ุจุดูู ูุณุชูู ุนู ุงูุชุฏุฑูุจ ูุซู ูุฐุง:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```


<Tip>

๐ก ูุฌุจ ุฃู ุชุชุฃูุฏ ุฏุงุฆููุง ูู ุฅููุงููุฉ ุชุดุบูู `trainer.evaluate()` ูุจู ุชุดุบูู `trainer.train()`ุ ูุชุฌูุจ ุฅูุฏุงุฑ ุงููุซูุฑ ูู ููุงุฑุฏ ุงูุญูุณุจุฉ ูุจู ุญุฏูุซ ุฎุทุฃ.

</Tip>

ูุจู ูุญุงููุฉ ุชุตุญูุญ ูุดููุฉ ูู ุญููุฉ ุงูุชููููุ ูุฌุจ ุฃู ุชุชุฃูุฏ ุฃููุงู ูู ุฃูู ูุฏ ุฃูููุช ูุธุฑุฉ ุนูู ุงูุจูุงูุงุชุ ููุงุฏุฑ ุนูู ุชูููู ุฏูุนุฉ ุจุดูู ุตุญูุญุ ูููููู ุชุดุบูู ูููุฐุฌู ุนูููุง. ููุฏ ุฃููููุง ูู ูุฐู ุงูุฎุทูุงุชุ ูุฐุง ูููู ุชูููุฐ ุงูููุฏ ุงูุชุงูู ุจุฏูู ุฃุฎุทุงุก:

```py
for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)
```

ูุญุฏุซ ุงูุฎุทุฃ ูุงุญููุงุ ูู ููุงูุฉ ูุฑุญูุฉ ุงูุชููููุ ูุฅุฐุง ูุธุฑูุง ุฅูู ุชุชุจุน ุงูุฎุทุฃุ ุณูุฑู ูุฐุง:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431         """
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()
```

ูุฐุง ูุฎุจุฑูุง ุฃู ุงูุฎุทุฃ ููุดุฃ ูู ูุญุฏุฉ `datasets/metric.py` -- ูุฐุง ูุฐู ูุดููุฉ ูู ุฏุงูุชูุง `compute_metrics()`. ุชุฃุฎุฐ ูุฐู ุงูุฏุงูุฉ ุฒูุฌูุง ูู ุงููุตูููุงุช ุงูููุบุงุฑูุชููุฉ ูุงูุชุตูููุงุช ููุฏุฎูุงุชุ ูุฐุง ุฏุนูุง ูุญุงูู ุฅุทุนุงููุง ุฐูู:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: ูููู ุชุญููู ุงููุตูููุงุช ุฐุงุช ุงูุญุฌู 1 ููุท ุฅูู ููุงุฏูุฑ ุณูููุฉ ูู ุจุงูุซูู
```

ูุญุตู ุนูู ููุณ ุงูุฎุทุฃุ ูุฐุง ูุฅู ุงููุดููุฉ ุจุงูุชุฃููุฏ ุชููู ูู ุชูู ุงูุฏุงูุฉ. ุฅุฐุง ูุธุฑูุง ุฅูู ููุฏูุง ูุฑุฉ ุฃุฎุฑูุ ูุฅููุง ูุฑู ุฃููุง ุชููู ููุท ุจุฅุนุงุฏุฉ ุชูุฌูู `predictions` ู`labels` ุฅูู `metric.compute()`. ูุฐุง ูู ููุงู ูุดููุฉ ูู ุชูู ุงูุทุฑููุฉุ ููุณ ุญูุงู. ุฏุนูุง ูููู ูุธุฑุฉ ุณุฑูุนุฉ ุนูู ุงูุฃุดูุงู:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

ุชููุนุงุชูุง ูุง ุชุฒุงู ููุบุงุฑูุชูุงุชุ ูููุณุช ุงูุชููุนุงุช ุงููุนููุฉุ ููุฐุง ูู ุงูุณุจุจ ูู ุฃู ุงููููุงุณ ูุนูุฏ ูุฐุง ุงูุฎุทุฃ (ุงูุบุงูุถ ุฅูู ุญุฏ ูุง). ุงูุญู ุณูู ุฌุฏูุงุ ูุฌุจ ุนูููุง ููุท ุฅุถุงูุฉ argmax ูู ุฏุงูุฉ `compute_metrics()`:

```py
import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

ุงูุขู ุชู ุฅุตูุงุญ ุฎุทุฆูุง! ูุงู ูุฐุง ูู ุงูุฃุฎูุฑุ ูุฐุง ูุฅู ูุตูุง ุงูุจุฑูุฌู ุณูููู ุงูุขู ุจุชุฏุฑูุจ ูููุฐุฌ ุจุดูู ุตุญูุญ.

ููุฅุดุงุฑุฉุ ุฅููู ุงููุต ุงูุจุฑูุฌู ุงููุงูู ุจุนุฏ ุงูุฅุตูุงุญ:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()
```

ูู ูุฐู ุงูุญุงูุฉุ ูุง ุชูุฌุฏ ูุดุงูู ุฃุฎุฑูุ ูุณูููู ูุตูุง ุงูุจุฑูุฌู ุจุชุนุฏูู ูููุฐุฌ ูุฌุจ ุฃู ูุนุทู ูุชุงุฆุฌ ูุนูููุฉ. ูููู ูุงุฐุง ูููููุง ุฃู ููุนู ุนูุฏูุง ูุณุชูุฑ ุงูุชุฏุฑูุจ ุจุฏูู ุฃู ุฎุทุฃุ ููุง ูุคุฏู ุงููููุฐุฌ ุงููุฏุฑุจ ุฅูู ูุชุงุฆุฌ ุฌูุฏุฉ ุนูู ุงูุฅุทูุงูุ ูุฐุง ูู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ูุณูุฑููู ุจุนุถ ุงูุชูููุงุช ุงูุชู ูููู ุฃู ุชุณุงุนุฏ.

<Tip>

๐ก ุฅุฐุง ููุช ุชุณุชุฎุฏู ุญููุฉ ุชุฏุฑูุจ ูุฏููุฉุ ุชูุทุจู ููุณ ุงูุฎุทูุงุช ูุชุตุญูุญ ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุ ูููู ูู ุงูุฃุณูู ูุตููุง. ุชุฃูุฏ ูู ุฃูู ูู ุชูุณ `model.eval()` ุฃู `model.train()` ูู ุงูุฃูุงูู ุงูุตุญูุญุฉุ ุฃู `zero_grad()` ูู ูู ุฎุทูุฉ!

</Tip>

## ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุตุงูุชุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ[[debugging-silent-errors-during-training]]

ูุงุฐุง ูููููุง ุฃู ููุนู ูุชุตุญูุญ ุชุฏุฑูุจ ููุชูู ุจุฏูู ุฃุฎุทุงุก ูููู ูุง ูุญูู ูุชุงุฆุฌ ุฌูุฏุฉุ ุณูุนุทูู ุจุนุถ ุงูุฅุฑุดุงุฏุงุช ููุงุ ูููู ูู ุนูู ุฏุฑุงูุฉ ุจุฃู ูุฐุง ุงูููุน ูู ุงูุชุตุญูุญ ูู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ููุง ููุฌุฏ ุฅุฌุงุจุฉ ุณุญุฑูุฉ.

### ุชุญูู ูู ุจูุงูุงุชู (ูุฑุฉ ุฃุฎุฑู!)[[check-your-data-again]]

ูู ูุชุนูู ูููุฐุฌู ุดูุฆูุง ุฅูุง ุฅุฐุง ูุงู ูู ุงููููู ุจุงููุนู ุชุนูู ุฃู ุดูุก ูู ุจูุงูุงุชู. ุฅุฐุง ูุงู ููุงู ุฎุทุฃ ูุคุฏู ุฅูู ุชูู ุงูุจูุงูุงุช ุฃู ูุชู ุชุนููู ุงูุชุตูููุงุช ุนุดูุงุฆููุงุ ููู ุงููุญุชูู ุฌุฏูุง ุฃูุง ุชุญุตู ุนูู ุฃู ุชุฏุฑูุจ ูููููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุชู. ูุฐุง ุงุจุฏุฃ ุฏุงุฆููุง ุจุงูุชุญูู ุงููุฒุฏูุฌ ูู ูุฏุฎูุงุชู ูุนูุงูุงุชู ุงููุดูุฑุฉุ ูุงุณุฃู ููุณู ุงูุฃุณุฆูุฉ ุงูุชุงููุฉ:

- ูู ุงูุจูุงูุงุช ุงููุดูุฑุฉ ูููููุฉุ
- ูู ุชูุงูู ุนูู ุงูุชุตูููุงุชุ
- ูู ููุงู ุชุตููู ูุงุญุฏ ุฃูุซุฑ ุดููุนูุง ูู ุงูุชุตูููุงุช ุงูุฃุฎุฑูุ
- ูุง ูู ุงูุฎุณุงุฑุฉ/ุงููููุงุณ ุงูุฐู ูุฌุจ ุฃู ูููู ุนููู ุฅุฐุง ุชูุจุฃ ุงููููุฐุฌ ุจุฅุฌุงุจุฉ ุนุดูุงุฆูุฉ/ููุณ ุงูุฅุฌุงุจุฉ ุฏุงุฆููุงุ

<Tip warning={true}>

โ๏ธ ุฅุฐุง ููุช ุชููู ุจุชุฏุฑูุจ ููุฒุนุ ููู ุจุทุจุงุนุฉ ุนููุงุช ูู ูุฌููุนุฉ ุจูุงูุงุชู ูู ูู ุนูููุฉ ูุชุญูู ุซูุงุซ ูุฑุงุช ูู ุฃูู ุชุญุตู ุนูู ููุณ ุงูุดูุก. ุฃุญุฏ ุงูุฃุฎุทุงุก ุงูุดุงุฆุนุฉ ูู ูุฌูุฏ ูุตุฏุฑ ุนุดูุงุฆู ูู ุฅูุดุงุก ุงูุจูุงูุงุช ููุง ูุฌุนู ูู ุนูููุฉ ูุฏููุง ูุณุฎุฉ ูุฎุชููุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.

</Tip>

ุจุนุฏ ุงููุธุฑ ุฅูู ุจูุงูุงุชูุ ูุฑ ุนุจุฑ ุจุนุถ ุชูุจุคุงุช ุงููููุฐุฌ ููู ุจุชุดููุฑูุง ุฃูุถูุง. ุฅุฐุง ูุงู ุงููููุฐุฌ ูุชูุจุฃ ุฏุงุฆููุง ุจููุณ ุงูุดูุกุ ููุฏ ูููู ุฐูู ูุฃู ูุฌููุนุฉ ุจูุงูุงุชู ูุชุญูุฒุฉ ูุญู ูุฆุฉ ูุงุญุฏุฉ (ููุดุงูู ุงูุชุตููู)ุ ูุฏ ุชุณุงุนุฏ ุงูุชูููุงุช ูุซู ุงูุฅูุฑุงุท ูู ุฃุฎุฐ ุนููุงุช ูู ุงููุฆุงุช ุงููุงุฏุฑุฉ.

ุฅุฐุง ูุงูุช ุงูุฎุณุงุฑุฉ/ุงููููุงุณ ุงูุฐู ุชุญุตู ุนููู ูู ูููุฐุฌู ุงูุฃููู ูุฎุชูู ุฌุฏูุง ุนู ุงูุฎุณุงุฑุฉ/ุงููููุงุณ ุงูุฐู ุชุชููุนู ููุชูุจุคุงุช ุงูุนุดูุงุฆูุฉุ ููู ุจุงูุชุญูู ุงููุฒุฏูุฌ ูู ุทุฑููุฉ ุญุณุงุจ ุงูุฎุณุงุฑุฉ ุฃู ุงููููุงุณุ ุญูุซ ูู ุงููุญุชูู ุฃู ูููู ููุงู ุฎุทุฃ ููุงู. ุฅุฐุง ููุช ุชุณุชุฎุฏู ุนุฏุฉ ุฎุณุงุฆุฑ ุชุถูููุง ูู ุงูููุงูุฉุ ูุชุฃูุฏ ูู ุฃููุง ุจููุณ ุงููููุงุณ.

ุนูุฏูุง ุชููู ูุชุฃูุฏูุง ูู ุฃู ุจูุงูุงุชู ูุซุงููุฉุ ููููู ุฃู ุชุฑู ูุง ุฅุฐุง ูุงู ุงููููุฐุฌ ูุงุฏุฑูุง ุนูู ุงูุชุฏุฑูุจ ุนูููุง ุจุงุฎุชุจุงุฑ ุจุณูุท ูุงุญุฏ.

### ูู ุจุถุจุท ูููุฐุฌู ุนูู ุฏูุนุฉ ูุงุญุฏุฉ[[overfit-your-model-on-one-batch]]

ุงูุถุจุท ุงูููุฑุท ูู ุนุงุฏุฉ ุดูุก ูุญุงูู ุชุฌูุจู ุนูุฏ ุงูุชุฏุฑูุจุ ูุฃูู ูุนูู ุฃู ุงููููุฐุฌ ูุง ูุชุนูู ุงูุชุนุฑู ุนูู ุงูููุฒุงุช ุงูุนุงูุฉ ุงูุชู ูุฑูุฏ ููู ุฃู ูุชุนูููุงุ ููููู ุจุฏูุงู ูู ุฐูู ูููู ููุท ุจุญูุธ ุนููุงุช ุงูุชุฏุฑูุจ. ููุน ุฐููุ ูุฅู ูุญุงููุฉ ุชุฏุฑูุจ ูููุฐุฌู ุนูู ุฏูุนุฉ ูุงุญุฏุฉ ูุฑุงุฑูุง ูุชูุฑุงุฑูุง ูู ุงุฎุชุจุงุฑ ุฌูุฏ ููุชุญูู ููุง ุฅุฐุง ูุงูุช ุงููุดููุฉ ููุง ุตุบุชูุง ูููู ุญููุง ุจูุงุณุทุฉ ุงููููุฐุฌ ุงูุฐู ุชุญุงูู ุชุฏุฑูุจู. ุณูุณุงุนุฏู ุฐูู ุฃูุถูุง ุนูู ุฑุคูุฉ ูุง ุฅุฐุง ูุงู ูุนุฏู ุงูุชุนูู ุงูุฃููู ุงูุฎุงุต ุจู ูุฑุชูุนูุง ุฌุฏูุง.

ุงูููุงู ุจุฐูู ุจูุฌุฑุฏ ุชุญุฏูุฏ `Trainer` ุงูุฎุงุต ุจู ุณูู ููุบุงูุฉุ ููุท ุงุญุตู ุนูู ุฏูุนุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจุ ุซู ูู ุจุชุดุบูู ุญููุฉ ุชุฏุฑูุจ ูุฏููุฉ ุตุบูุฑุฉ ุจุงุณุชุฎุฏุงู ุชูู ุงูุฏูุนุฉ ููุท ูุดูุก ูุซู 20 ุฎุทูุฉ:

```py
for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()
```

<Tip>

๐ก ุฅุฐุง ูุงูุช ุจูุงูุงุช ุงูุชุฏุฑูุจ ุบูุฑ ูุชูุงุฒูุฉุ ูุชุฃูุฏ ูู ุจูุงุก ุฏูุนุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ุชุญุชูู ุนูู ุฌููุน ุงูุชุตูููุงุช.

</Tip>

ูุฌุจ ุฃู ูููู ุงููููุฐุฌ ุงููุงุชุฌ ุฐู ูุชุงุฆุฌ ูุฑูุจุฉ ูู ุงูููุงู ุนูู ููุณ `batch`. ุฏุนูุง ูุญุณุจ ุงููููุงุณ ุนูู ุงูุชูุจุคุงุช ุงููุงุชุฌุฉ:

```py
with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```


100% ุฏูุฉุ ูุฐุง ูุซุงู ุฌูุฏ ุนูู ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ (ุจูุนูู ุฃูู ุฅุฐุง ููุช ุจุชุฌุฑุจุฉ ูููุฐุฌู ุนูู ุฃู ุฌููุฉ ุฃุฎุฑูุ ููู ุงููุญุชูู ุฌุฏูุง ุฃู ูุนุทูู ุฅุฌุงุจุฉ ุฎุงุทุฆุฉ)!

ุฅุฐุง ูู ุชุชููู ูู ุงูุญุตูู ุนูู ูุชุงุฆุฌ ูุซุงููุฉ ูุซู ูุฐู ูู ูููุฐุฌูุ ููุฐุง ูุนูู ุฃู ููุงู ุฎุทุฃ ูุง ูู ุทุฑููุฉ ุตูุงุบุชู ูููุดููุฉ ุฃู ุจูุงูุงุชูุ ูุฐุง ูุฌุจ ุนููู ุฅุตูุงุญ ุฐูู. ููุท ุนูุฏูุง ุชุชููู ูู ุงุฌุชูุงุฒ ุงุฎุชุจุงุฑ ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉุ ููููู ุงูุชุฃูุฏ ูู ุฃู ูููุฐุฌู ูุงุฏุฑ ูุนูููุง ุนูู ุงูุชุนูู.

<Tip warning={true}>

โ๏ธ ุณูุชุนูู ุนููู ุฅุนุงุฏุฉ ุฅูุดุงุก ูููุฐุฌู ู`Trainer` ุจุนุฏ ูุฐุง ุงูุงุฎุชุจุงุฑุ ุญูุซ ูู ุงููุญุชูู ุฃูุง ูุชููู ุงููููุฐุฌ ุงูุฐู ุชู ุงูุญุตูู ุนููู ูู ุงูุชุนุงูู ูุงูุชุนูู ุจุดูู ูููุฏ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ ุงูุฎุงุตุฉ ุจู.

</Tip>

### ูุง ุชุถุจุท ุฃู ุดูุก ุญุชู ูููู ูุฏูู ุฎุท ุฃุณุงุณ ุฃูู [[dont-tune-anything-until-you-have-a-first-baseline]]

ูุชู ุงูุชุฃููุฏ ุฏุงุฆููุง ุนูู ุถุจุท ูุฑุท ุงููุนููุงุช ุนูู ุฃูู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ููููู ูุฌุฑุฏ ุงูุฎุทูุฉ ุงูุฃุฎูุฑุฉ ููุณุงุนุฏุชู ูู ุชุญููู ุงููููู ูู ุงูููุงุณุจ ุนูู ุงููููุงุณ. ูู ูุนุธู ุงูุฃููุงุชุ ุณุชุนูู ูุฑุท ุงููุนููุงุช ุงูุงูุชุฑุงุถูุฉ ูู`Trainer` ุจุดูู ุฌูุฏ ูุฅุนุทุงุฆู ูุชุงุฆุฌ ุฌูุฏุฉุ ูุฐุง ูุง ุชุจุฏุฃ ูู ุนูููุฉ ุจุญุซ ููููุฉ ูุชุณุชุบุฑู ููุชูุง ุทูููุงู ุนู ูุฑุท ุงููุนููุงุช ุญุชู ูููู ูุฏูู ุดูุก ูุชููู ุนูู ุฎุท ุงูุฃุณุงุณ ุงูุฐู ูุฏูู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู.

ุจูุฌุฑุฏ ุญุตููู ุนูู ูููุฐุฌ ุฌูุฏ ุจูุง ููู ุงูููุงูุฉุ ููููู ุงูุจุฏุก ูู ุฅุฌุฑุงุก ุจุนุถ ุงูุชุนุฏููุงุช. ูุง ุชุญุงูู ุฅุทูุงู ุฃูู ุนูููุฉ ุจูุฑุท ูุนููุงุช ูุฎุชููุฉุ ูููู ูุงุฑู ุจูู ุจุถุน ุนูููุงุช ุจูุฑุท ูุนููุงุช ูุฎุชููุฉ ููุญุตูู ุนูู ููุฑุฉ ุนู ุงูุชุฃุซูุฑ ุงูุฃูุจุฑ.

ุฅุฐุง ููุช ุชููู ุจุชุนุฏูู ุงููููุฐุฌ ููุณูุ ุฃุจูู ุจุณูุทูุง ููุง ุชุญุงูู ุฃู ุดูุก ูุง ููููู ุชุจุฑูุฑู ุจุดูู ูุนููู. ุชุฃูุฏ ุฏุงุฆููุง ูู ุงูุนูุฏุฉ ุฅูู ุงุฎุชุจุงุฑ ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ ููุชุญูู ูู ุฃู ุงูุชุบููุฑ ุงูุฐู ุฃุฌุฑูุชู ูู ููู ูู ุฃู ุนูุงูุจ ุบูุฑ ููุตูุฏุฉ.

### ุงุทูุจ ุงููุณุงุนุฏุฉ [[ask-for-help]]

ูุฃูู ุฃู ุชููู ูุฏ ูุฌุฏุช ุจุนุถ ุงููุตุงุฆุญ ูู ูุฐุง ุงููุณู ุงูุชู ุณุงุนุฏุชู ูู ุญู ูุดููุชูุ ูููู ุฅุฐุง ูู ููู ุงูุฃูุฑ ูุฐููุ ุชุฐูุฑ ุฃูู ููููู ุฏุงุฆููุง ุทูุจ ุงููุณุงุนุฏุฉ ูู ุงููุฌุชูุน ุนูู [ุงูููุชุฏูุงุช](https://discuss.huggingface.co/).

ููุง ุจุนุถ ุงูููุงุฑุฏ ุงูุฅุถุงููุฉ ุงูุชู ูุฏ ุชููู ูููุฏุฉ:

- ["ุงููุงุจููุฉ ููุชูุฑุงุฑ ููุณููุฉ ูุฃูุถู ุงูููุงุฑุณุงุช ุงูููุฏุณูุฉ"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) ุจูุงุณุทุฉ ุฌููู ุฌุฑูุณ
- ["ูุงุฆูุฉ ูุฑุงุฌุนุฉ ูุชุตุญูุญ ุฃุฎุทุงุก ุงูุดุจูุงุช ุงูุนุตุจูุฉ"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) ุจูุงุณุทุฉ ุณูุณูููุง ุดุงู
- ["ููููุฉ ุงุฎุชุจุงุฑ ูุญุฏุฉ ุงูุชุนูู ุงูุขูู"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) ุจูุงุณุทุฉ ุชุดูุณ ุฑูุจุฑุชุณ
- ["ูุตูุฉ ูุชุฏุฑูุจ ุงูุดุจูุงุช ุงูุนุตุจูุฉ"](http://karpathy.github.io/2019/04/25/recipe/) ุจูุงุณุทุฉ ุฃูุฏุฑู ูุงุฑุจุงุซู

ุจุงูุทุจุนุ ููุณุช ูู ูุดููุฉ ุชูุงุฌููุง ุนูุฏ ุชุฏุฑูุจ ุงูุดุจูุงุช ุงูุนุตุจูุฉ ูู ุฎุทุฃู! ุฅุฐุง ูุงุฌูุช ุดูุฆูุง ูู ููุชุจุฉ ๐ค Transformers ุฃู ๐ค Datasets ูุง ูุจุฏู ุตุญูุญูุงุ ููุฏ ุชููู ูุฏ ูุงุฌูุช ุฎูููุง. ูุฌุจ ุนููู ุจุงูุชุฃููุฏ ุฅุฎุจุงุฑูุง ุจูู ุดูุก ุนููุ ููู ุงููุณู ุงูุชุงูู ุณูุดุฑุญ ุจุงูุถุจุท ููููุฉ ุงูููุงู ุจุฐูู.