# ุชุตุญูุญ ุฎุทุฃ ุฃูุจูุจ ุงูุชุฏุฑูุจ

ููุฏ ูุชุจุช ูุตูุง ุฌููููุง ูุชุฏุฑูุจ ุฃู ุถุจุท ูููุฐุฌ ุนูู ูููุฉ ูุนููุฉุ ูุน ุงุชุจุงุน ุงููุตูุญุฉ ูู [ุงููุตู 7](/course/chapter7) ุจูู ุฏูุฉ. ูููู ุนูุฏ ุชุดุบูู ุงูุฃูุฑ `trainer.train()`ุ ูุญุฏุซ ุดูุก ูุธูุน: ุชุญุตู ุนูู ุฎุทุฃ ๐ฑ! ุฃู ูุง ูู ุฃุณูุฃุ ูุจุฏู ุฃู ูู ุดูุก ุนูู ูุง ูุฑุงูุ ููุชู ุงูุชุฏุฑูุจ ุฏูู ุฃุฎุทุงุกุ ูููู ุงููููุฐุฌ ุงููุงุชุฌ ุบูุฑ ุฌูุฏ. ูู ูุฐุง ุงููุณูุ ุณูุฑููู ูุง ูููููู ูุนูู ูุชุตุญูุญ ูุฐู ุงูุฃููุงุน ูู ุงููุดููุงุช.

## ุชุตุญูุญ ุฎุทุฃ ุฃูุจูุจ ุงูุชุฏุฑูุจ

ุนูุฏ ููุงุฌูุฉ ุฎุทุฃ ูู `trainer.train()`ุ ูุฏ ูููู ูุตุฏุฑู ุนุฏุฉ ุฃููุฑุ ุญูุซ ูููู ุงูู `Trainer` ุนุงุฏุฉ ุจุฌูุน ุงููุซูุฑ ูู ุงูุฃุดูุงุก. ููู ูุญูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุฅูู ูุญููุงุช ุจูุงูุงุชุ ูุฐุง ููุฏ ูููู ุงููุดูู ูุงุชุฌ ุนู ุฎุทุฃ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุ ุฃู ูุดููุฉ ูุง ุนูุฏ ูุญุงููุฉ ุฏูุฌ ุนูุงุตุฑ ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ูุนูุง. ุซู ูุฃุฎุฐ ุฏูุนุฉ ูู ุงูุจูุงูุงุช ููุฑุณููุง ุฅูู ุงููููุฐุฌุ ูุฐุง ููุฏ ูููู ุงููุดูู ูู ููุฏ ุงููููุฐุฌ. ุจุนุฏ ุฐููุ ูุญุณุจ ุงููุดุชูุงุช ููุคุฏู ุฎุทูุฉ ุงูุชุญุณููุ ูุฐุง ููุฏ ูููู ุงููุดูู ุฃูุถูุง ูู ูุญุณูู. ูุญุชู ุฅุฐุง ุณุงุฑ ูู ุดูุก ุนูู ูุง ูุฑุงู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ููุฏ ูุญุฏุซ ุฎุทุฃ ูุง ุฃุซูุงุก ุงูุชูููู ุฅุฐุง ูุงู ููุงู ูุดููุฉ ูู ูููุงุณู.

ุฃูุถู ุทุฑููุฉ ูุชุตุญูุญ ุฎุทุฃ ูุญุฏุซ ูู `trainer.train()` ูู ุงููุฑูุฑ ูุฏูููุง ุนุจุฑ ุฎุท ุงูุฃูุงุจูุจ ูุฐุง ุจุฃูููู ููุนุฑูุฉ ุฃูู ุญุฏุซ ุงูุฎุทุฃ. ุบุงูุจูุง ูุง ูููู ุงูุฎุทุฃ ุณูู ุงูุญู.

ูุฅุซุจุงุช ุฐููุ ุณูุณุชุฎุฏู ุงููุต ุงูุจุฑูุฌู ุงูุชุงูู ุงูุฐู (ูุญุงูู) ุถุจุท ูููุฐุฌ DistilBERT ุนูู ูุฌููุนุฉ ุจูุงูุงุช [MNLI](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
model,
args,
train_dataset=raw_datasets["train"],
eval_dataset=raw_datasets["validation_matched"],
compute_metrics=compute_metrics,
)
trainer.train()
```

ุฅุฐุง ุญุงููุช ุชูููุฐ ูุฐุง ุงููุต ุงูุจุฑูุฌูุ ูุณุชุญุตู ุนูู ุฎุทุฃ ุบุงูุถ ุฅูู ุญุฏ ูุง:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### ุชุญูู ูู ุจูุงูุงุชู

ุบูู ุนู ุงูููู ุฃูู ุฅุฐุง ูุงูุช ุจูุงูุงุชู ุชุงููุฉุ ููู ูุชููู ุงูู `Trainer` ูู ุชุดููู ุฏูุนุงุชุ ูุงููู ุนู ุชุฏุฑูุจ ูููุฐุฌู. ูุฐุงุ ูุฌุจ ุนููู ุฃููุงู ุงูุชุญูู ููุง ููุฌุฏ ุฏุงุฎู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู.

ูุชุฌูุจ ูุถุงุก ุณุงุนุงุช ูุง ุชุญุตู ูู ูุญุงููุฉ ุฅุตูุงุญ ุดูุก ููุณ ูุตุฏุฑ ุงูุฎุทุฃุ ููุตู ุจุงุณุชุฎุฏุงู `trainer.train_dataset` ูุนูููุงุช ุงูุชุญูู ุงูุฎุงุตุฉ ุจู ูุนุฏู ุงุณุชุฎุฏุงู ุฃู ุดูุก ุขุฎุฑ. ูุฐุงุ ุฏุนููุง ูููู ุจุฐูู ููุง:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
'idx': 0,
'label': 1,
'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

ูู ูุงุญุธุช ุดูุฆูุง ุฎุงุทุฆูุงุ ูุฐุงุ ุฅูู ุฌุงูุจ ุฑุณุงูุฉ ุงูุฎุทุฃ ุญูู `input_ids` ุงูููููุฏุฉุ ูุฌุจ ุฃู ูุฌุนูู ุชุฏุฑู ุฃู ูุฐู ูุตูุตุ ูููุณุช ุฃุฑูุงููุง ูููู ูููููุฐุฌ ููููุง. ููุงุ ูููู ุงูุฎุทุฃ ุงูุฃุตูู ูุถููุงู ููุบุงูุฉ ูุฃู ุงูู `Trainer` ูุฒูู ุชููุงุฆููุง ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุชุทุงุจู ูุน ุชูููุน ุงููููุฐุฌ (ุฃูุ ุงูุญุฌุฌ ุงูุชู ูุชููุนูุง ุงููููุฐุฌ). ููุฐุง ูุนูู ุฃูู ููุงุ ุชู ุงูุชุฎูุต ูู ูู ุดูุก ุจุงุณุชุซูุงุก ุงูุนูุงูุงุช. ูุจุงูุชุงููุ ูู ุชูู ููุงู ูุดููุฉ ูู ุฅูุดุงุก ุฏูุนุงุช ุซู ุฅุฑุณุงููุง ุฅูู ุงููููุฐุฌุ ูุงูุฐู ุงุดุชูู ุจุฏูุฑู ูู ุฃูู ูู ูุชูู ุงููุฏุฎูุงุช ุงูุตุญูุญุฉ.

ููุงุฐุง ูู ุชุชู ูุนุงูุฌุฉ ุงูุจูุงูุงุชุ ููุฏ ุงุณุชุฎุฏููุง ุทุฑููุฉ `Dataset.map()` ุนูู ูุฌููุนุงุช ุงูุจูุงูุงุช ูุชุทุจูู ุงูู tokenizer ุนูู ูู ุนููุฉ. ูููู ุฅุฐุง ูุธุฑุช ุนู ูุซุจ ุฅูู ุงูููุฏุ ูุณุชูุงุญุธ ุฃููุง ุงุฑุชูุจูุง ุฎุทุฃู ุนูุฏ ุชูุฑูุฑ ูุฌููุนุงุช ุงูุชุฏุฑูุจ ูุงูุชูููู ุฅูู ุงูู `Trainer`. ุจุฏูุงู ูู ุงุณุชุฎุฏุงู `tokenized_datasets` ููุงุ ุงุณุชุฎุฏููุง `raw_datasets` ๐คฆ. ูุฐุงุ ุฏุนููุง ูุตูุญ ูุฐุง ุงูุฎุทุฃ!

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
)
trainer.train()
```

ุณูุนุทู ูุฐุง ุงูููุฏ ุงูุฌุฏูุฏ ุฎุทุฃ ูุฎุชูููุง (ุชูุฏู!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

ุจุงููุธุฑ ุฅูู ุชุชุจุน ุงูููุฏุณุ ูููููุง ุฃู ูุฑู ุฃู ุงูุฎุทุฃ ูุญุฏุซ ูู ุฎุทูุฉ ุชุฌููุน ุงูุจูุงูุงุช:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
105                 batch[k] = torch.stack([f[k] for f in features])
106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
108
109     return batch
```

ูุฐุงุ ูุฌุจ ุนูููุง ุงูุงูุชูุงู ุฅูู ุฐูู. ูููู ูุจู ุฃู ููุนู ุฐููุ ุฏุนููุง ูููู ูุญุต ุจูุงูุงุชูุงุ ููุท ููุชุฃูุฏ ุจูุณุจุฉ 100% ูู ุฃููุง ุตุญูุญุฉ.

ููุงู ุดูุก ูุฌุจ ุนููู ุฏุงุฆููุง ูุนูู ุนูุฏ ุชุตุญูุญ ุฌูุณุฉ ุชุฏุฑูุจ ููู ุฅููุงุก ูุธุฑุฉ ุนูู ุงููุฏุฎูุงุช ุงููุดูุฑุฉ ููููุฐุฌู. ูุง ูููููุง ููู ุงูุฃุฑูุงู ุงูุชู ููุฑุฑูุง ุฅูููุง ูุจุงุดุฑุฉูุ ูุฐุง ูุฌุจ ุนูููุง ุงููุธุฑ ุฅูู ูุง ุชูุซูู ุชูู ุงูุฃุฑูุงู. ูู ุฑุคูุฉ ุงูููุจููุชุฑุ ุนูู ุณุจูู ุงููุซุงูุ ูุนูู ุฐูู ุงููุธุฑ ุฅูู ุงูุตูุฑ ุงููุดูุฑุฉ ููุจูุณูุงุช ุงูุชู ุชูุฑุฑูุงุ ููู ุงูููุงู ูุนูู ุงูุงุณุชูุงุน ุฅูู ุนููุงุช ุงูุตูุช ุงููุดูุฑุฉุ ูุจุงููุณุจุฉ ููุซุงู NLP ููุงุ ูุนูู ุงุณุชุฎุฏุงู ุงูู tokenizer ุงูุฎุงุต ุจูุง ูุชุดููุฑ ุงููุฏุฎูุงุช:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

ูุฐุง ูุจุฏู ุฐูู ุตุญูุญูุง. ูุฌุจ ุนููู ุงูููุงู ุจุฐูู ูุฌููุน ุงูููุงุชูุญ ูู ุงููุฏุฎูุงุช:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

ูุงุญุธ ุฃูู ุณูุชู ุงูุชุฎูุต ุชููุงุฆููุง ูู ุงูููุงุชูุญ ุงูุชู ูุง ุชุชุทุงุจู ูุน ุงููุฏุฎูุงุช ุงูุชู ููุจููุง ุงููููุฐุฌุ ูุฐุง ููุง ุณูุญุชูุธ ููุท ุจู `input_ids`ุ ู`attention_mask`ุ ู`label` (ูุงูุชู ุณูุชู ุฅุนุงุฏุฉ ุชุณููุชูุง ุฅูู `labels`). ููุชุฃูุฏ ูู ุชูููุน ุงููููุฐุฌุ ููููู ุทุจุงุนุฉ ูุฆุฉ ูููุฐุฌูุ ุซู ุงูุชุญูู ูู ูุซุงุฆูู:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

ูุฐุงุ ูู ุญุงูุชูุงุ ูููููุง ุงูุชุญูู ูู ุงููุนููุงุช ุงูููุจููุฉ ุนูู [ูุฐู ุงูุตูุญุฉ](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). ููุง ุณูููู ุงูู `Trainer` ุจุชุณุฌูู ุงูุฃุนูุฏุฉ ุงูุชู ูุชู ุงูุชุฎูุต ูููุง.

ููุฏ ุชุญูููุง ูู ุฃู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุตุญูุญุฉ ุนู ุทุฑูู ูู ุชุดููุฑูุง. ุงูุชุงูู ูู `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

ูุธุฑูุง ูุฃููุง ูู ูุทุจู ุงูุญุดู ูู ูุนุงูุฌุชูุง ุงููุณุจูุฉุ ูุจุฏู ูุฐุง ุทุจูุนููุง ุชูุงููุง. ููุชุฃูุฏ ูู ุนุฏู ูุฌูุฏ ูุดููุฉ ูุน ููุงุน ุงูุงูุชูุงู ูุฐุงุ ุฏุนูุง ูุชุญูู ูู ุฃูู ุจููุณ ุทูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุงูุฎุงุตุฉ ุจูุง:

```py
len(trainer.train_dataset[0]["attention_mask"]) == len(
trainer.train_dataset[0]["input_ids"]
)
```

```python out
True
```

ูุฐุง ุฌูุฏ! ุฃุฎูุฑูุงุ ุฏุนูุง ูุชุญูู ูู ุนูุงูุชูุง:

```py
trainer.train_dataset[0]["label"]
```

```python out
1
```

ูุซู ูุนุฑูุงุช ุงูุฅุฏุฎุงูุ ูุฐุง ุฑูู ูุง ูุนูู ูู ุจููุฑุฏู. ููุง ุฑุฃููุง ุณุงุจููุงุ ูุชู ุชุฎุฒูู ุงูุฎุฑูุทุฉ ุจูู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ ูุฃุณูุงุก ุงูุนูุงูุงุช ุฏุงุฎู ุงูุณูุฉ `names` ููู *feature* ุงูููุงุจูุฉ ููุฌููุนุฉ ุงูุจูุงูุงุช:

```py
trainer.train_dataset.features["label"].names
```

```python out
['entailment', 'neutral', 'contradiction']
```

ูุฐุง ูุฅู `1` ุชุนูู `neutral`ุ ููุง ูุนูู ุฃู ุงูุฌููุชูู ุงููุชูู ุฑุฃููุงููุง ุฃุนูุงู ูุง ุชุชุนุงุฑุถุงูุ ููุง ุชุณุชูุฒู ุงูุฌููุฉ ุงูุฃููู ุงูุฌููุฉ ุงูุซุงููุฉ. ูุจุฏู ุฐูู ุตุญูุญูุง!

ูุง ุชูุฌุฏ ูุฏููุง ูุนุฑูุงุช ุฃููุงุน ุงูุฑููุฒ ููุงุ ูุฃู DistilBERT ูุง ูุชููุนูุงุ ุฅุฐุง ูุงู ูุฏูู ุจุนุถูุง ูู ูููุฐุฌูุ ููุฌุจ ุนููู ุฃูุถูุง ุงูุชุฃูุฏ ูู ุฃููุง ุชุชุทุงุจู ุจุดูู ุตุญูุญ ูุน ุงูุฌููุฉ ุงูุฃููู ูุงูุซุงููุฉ ูู ุงูุฅุฏุฎุงู.

โ๏ธ **ุฌุฑุจ ุจููุณู!** ุชุญูู ูู ุฃู ูู ุดูุก ูุจุฏู ุตุญูุญูุง ูุน ุงูุนูุตุฑ ุงูุซุงูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชุฏุฑูุจูุฉ.

ูุญู ูููู ุจุงูุชุญูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชุฏุฑูุจูุฉ ููุท ููุงุ ูููู ุจุงูุทุจุน ูุฌุจ ุนููู ุงูุชุญูู ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจุงูุชุญูู ูุงูุงุฎุชุจุงุฑ ุจููุณ ุงูุทุฑููุฉ.

ุงูุขู ุจุนุฏ ุฃู ุนูููุง ุฃู ูุฌููุนุงุช ุงูุจูุงูุงุช ุชุจุฏู ุฌูุฏุฉุ ุญุงู ุงูููุช ููุชุญูู ูู ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ.
### ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุฅูู ูุญููุงุช ุงูุจูุงูุงุช

ุงูุดูุก ุงูุชุงูู ุงูุฐู ูุฏ ูุญุฏุซ ุฎุทุฃ ูู ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ ูู ุนูุฏูุง ูุญุงูู "ุงููุฏุฑุจ" ุชุดููู ุฏูุนุงุช ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ ุฃู ุงูุชุญูู. ุจูุฌุฑุฏ ุงูุชุฃูุฏ ูู ุตุญุฉ ูุฌููุนุงุช ุจูุงูุงุช "ุงููุฏุฑุจ"ุ ููููู ูุญุงููุฉ ุชุดููู ุฏูุนุฉ ูุฏูููุง ุนู ุทุฑูู ุชูููุฐ ูุง ููู (ุงุณุชุจุฏู "train" ุจู "eval" ููุฌููุนุฉ ุจูุงูุงุช ุงูุชุญูู):

```py
for batch in trainer.get_train_dataloader():
break
```

ููุดุฆ ูุฐุง ุงูููุฏ ูุญูู ุจูุงูุงุช ุงูุชุฏุฑูุจุ ุซู ูููู ุจุงูุชุนููู ุฎูุงููุ ูุงูุชููู ุนูุฏ ุงูุชูุฑุงุฑ ุงูุฃูู. ุฅุฐุง ุชู ุชูููุฐ ุงูููุฏ ุฏูู ุฎุทุฃุ ูุณุชุญุตู ุนูู ุฃูู ุฏูุนุฉ ุชุฏุฑูุจ ููููู ูุญุตูุงุ ูุฅุฐุง ุญุฏุซ ุฎุทุฃ ูู ุงูููุฏุ ูุณุชุนุฑู ุจุงูุชุฃููุฏ ุฃู ุงููุดููุฉ ุชููู ูู ูุญูู ุงูุจูุงูุงุชุ ููุง ูู ุงูุญุงู ููุง:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
105                 batch[k] = torch.stack([f[k] for f in features])
106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
108
109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)
```

ูุฌุจ ุฃู ูููู ูุญุต ุงูุฅุทุงุฑ ุงูุฃุฎูุฑ ูู ุชุชุจุน ุงูููุฏุณ ูุงูููุง ูููุญู ุชูููุญูุงุ ูููู ุฏุนูุง ูููู ุจุงูุชูููุจ ุฃูุซุฑ ููููุงู. ุชูุดุฃ ูุนุธู ุงููุดููุงุช ุฃุซูุงุก ุฅูุดุงุก ุงูุฏูุนุฉ ุจุณุจุจ ุชุฌููุน ุงูุฃูุซูุฉ ูู ุฏูุนุฉ ูุงุญุฏุฉุ ูุฐุง ูุฅู ุฃูู ุดูุก ูุฌุจ ุงูุชุญูู ููู ุนูุฏ ุงูุดู ูู ุฏุงูุฉ `collate_fn` ุงูุชู ูุณุชุฎุฏููุง `DataLoader` ุงูุฎุงุต ุจู:

```py
data_collator = trainer.get_train_dataloader().collate_fn
data_collator
```

```python out
<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>
```

ูุฐุงุ ูุฐุง ูู `default_data_collator`ุ ูููู ูุฐุง ููุณ ูุง ูุฑูุฏู ูู ูุฐู ุงูุญุงูุฉ. ูุฑูุฏ ุฃู ูููุฃ ุฃูุซูุฉ ูุฏููุง ุฅูู ุฃุทูู ุฌููุฉ ูู ุงูุฏูุนุฉุ ูุงูุชู ูุชู ุชูููุฐูุง ุจูุงุณุทุฉ `DataCollatorWithPadding` collator. ููู ุงูููุชุฑุถ ุฃู ูุณุชุฎุฏู ูุญูู ุงูุจูุงูุงุช ูุฐุง ุจุดูู ุงูุชุฑุงุถู ุจูุงุณุทุฉ "ุงููุฏุฑุจ"ุ ูููุงุฐุง ูุง ูุชู ุงุณุชุฎุฏุงูู ููุงุ

ุงูุฅุฌุงุจุฉ ูู ุฃููุง ูู ููุฑุฑ "ูุญูู ุงูุฑููุฒ" ุฅูู "ุงููุฏุฑุจ"ุ ูุฐูู ูู ูุชููู ูู ุฅูุดุงุก `DataCollatorWithPadding` ุงูุฐู ูุฑูุฏู. ูู ุงูููุงุฑุณุฉ ุงูุนูููุฉุ ูุฌุจ ุฃูุง ุชุชุฑุฏุฏ ุฃุจุฏูุง ูู ุชูุฑูุฑ ูุญูู ุงูุจูุงูุงุช ุงูุฐู ุชุฑูุฏ ุงุณุชุฎุฏุงูู ุตุฑุงุญุฉูุ ููุชุฃูุฏ ูู ุชุฌูุจ ูุฐู ุงูุฃููุงุน ูู ุงูุฃุฎุทุงุก. ุฏุนูุง ูููู ุจุชุนุฏูู ุงูููุฏ ุงูุฎุงุต ุจูุง ููููุงู ุจุฐูู ุจุงูุถุจุท:

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
trainer.train()
```

ุงูุฃุฎุจุงุฑ ุงูุณุงุฑุฉุ ูุง ูุญุตู ุนูู ููุณ ุงูุฎุทุฃ ููุง ูู ุงูุณุงุจูุ ููู ุชูุฏู ุจุงูุชุฃููุฏ. ุงูุฃุฎุจุงุฑ ุงูุณูุฆุฉุ ูุญุตู ุนูู ุฎุทุฃ CUDA ุณูุฆ ุงูุณูุนุฉ ุจุฏูุงู ูู ุฐูู:

```python out
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
```

ูุฐุง ุฃูุฑ ุณูุก ูุฃู ุฃุฎุทุงุก CUDA ูุตุนุจ ุชุตุญูุญูุง ุจุดูู ุนุงู. ุณูุฑู ุจุนุฏ ูุญุธุฉ ููููุฉ ุญู ุฐููุ ูููู ุฃููุงู ุฏุนูุง ูููู ุชุญููููุง ูุฅูุดุงุก ุฏูุนุฉ.

ุฅุฐุง ููุช ูุชุฃูุฏูุง ูู ุฃู ูุญูู ุงูุจูุงูุงุช ุงูุฎุงุต ุจู ูู ุงูุตุญูุญุ ููุฌุจ ุนููู ูุญุงููุฉ ุชุทุจููู ุนูู ุจุถุน ุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู:

```py
data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])
```

ุณูุคุฏู ูุฐุง ุงูููุฏ ุฅูู ุงููุดู ูุฃู ูุฌููุนุฉ "train_dataset" ุชุญุชูู ุนูู ุฃุนูุฏุฉ ูุตูุฉุ ูุงูุชู ูููู "ุงููุฏุฑุจ" ุนุงุฏุฉู ุจุฅุฒุงูุชูุง. ููููู ุฅุฒุงูุชูุง ูุฏูููุงุ ุฃู ุฅุฐุง ููุช ุชุฑูุฏ ุชูุฑุงุฑ ูุง ููุนูู "ุงููุฏุฑุจ" ุจุงูุถุจุท ุฎูู ุงูููุงููุณุ ูููููู ุงุณุชุฏุนุงุก ุทุฑููุฉ `Trainer._remove_unused_columns()` ุงูุฎุงุตุฉ ุงูุชู ุชููู ุจุฐูู:

```py
data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])
```

ุจุนุฏ ุฐููุ ูุฌุจ ุฃู ุชุชููู ูู ุชุตุญูุญ ุงูุฃุฎุทุงุก ูุฏูููุง ูู ูุญูู ุงูุจูุงูุงุช ุฅุฐุง ุงุณุชูุฑ ุงูุฎุทุฃ.

ุงูุขู ุจุนุฏ ุฃู ูููุง ุจุชุตุญูุญ ุฃุฎุทุงุก ุนูููุฉ ุฅูุดุงุก ุงูุฏูุนุฉุ ุญุงู ุงูููุช ููุฑูุฑูุง ุนุจุฑ ุงููููุฐุฌ!

### ุงููุฑูุฑ ุนุจุฑ ุงููููุฐุฌ

ูุฌุจ ุฃู ุชููู ูุงุฏุฑูุง ุนูู ุงูุญุตูู ุนูู ุฏูุนุฉ ุนู ุทุฑูู ุชูููุฐ ุงูุฃูุฑ ุงูุชุงูู:

```py
for batch in trainer.get_train_dataloader():
break
```

ุฅุฐุง ููุช ุชุดุบู ูุฐุง ุงูููุฏ ูู ุฏูุชุฑ ููุงุญุธุงุชุ ููุฏ ุชุญุตู ุนูู ุฎุทุฃ CUDA ูุดุงุจู ููุง ุฑุฃููุงู ุณุงุจููุงุ ููู ูุฐู ุงูุญุงูุฉุ ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดุบูู ุฏูุชุฑ ุงูููุงุญุธุงุช ุงูุฎุงุต ุจู ูุฅุนุงุฏุฉ ุชูููุฐ ุงูุฌุฒุก ุงูุฃุฎูุฑ ุฏูู ุณุทุฑ `trainer.train()`ุ ููุฐุง ุซุงูู ุฃูุซุฑ ุงูุฃุดูุงุก ุงููุฒุนุฌุฉ ุจุดุฃู ุฃุฎุทุงุก CUDA: ููู ุชุญุทู ููุงุฉ ุฏูุชุฑ ุงูููุงุญุธุงุช ุงูุฎุงุต ุจู ุจุดูู ูุง ูููู ุฅุตูุงุญู. ูุงูุฃูุซุฑ ุฅุฒุนุงุฌูุง ุจุดุฃููุง ูู ุตุนูุจุฉ ุชุตุญูุญูุง.

ููุงุฐุง ูุฐุงุ ูู ุนูุงูุฉ ุจุทุฑููุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPUs). ุฅููุง ูุนุงูุฉ ููุบุงูุฉ ูู ุชูููุฐ ุงููุซูุฑ ูู ุงูุนูููุงุช ุจุดูู ูุชูุงุฒูุ ูููู ุงูุนูุจ ูู ุฃูู ุนูุฏูุง ุชุคุฏู ุฅุญุฏู ูุฐู ุงูุชุนูููุงุช ุฅูู ุฎุทุฃุ ููู ุชุนุฑู ุฐูู ุนูู ุงูููุฑ. ุฅูู ููุท ุนูุฏูุง ูุณุชุฏุนู ุงูุจุฑูุงูุฌ ูุฒุงููุฉ ุงูุนูููุงุช ุงููุชุนุฏุฏุฉ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงูุชู ุณูุฏุฑู ุฃู ุดูุฆูุง ูุง ูุฏ ุญุฏุซ ุฎุทุฃุ ูุฐุง ูุชู ุฑูุน ุงูุฎุทุฃ ูู ุงููุงูุน ูู ููุงู ูุง ุนูุงูุฉ ูู ุจูุง ุฃูุดุฃู. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุธุฑูุง ุฅูู ุชุชุจุน ุงูููุฏุณ ุงูุณุงุจูุ ููุฏ ุญุฏุซ ุงูุฎุทุฃ ุฃุซูุงุก ุงูุชูุฑูุฑ ุงูุฎูููุ ูููููุง ุณูุฑู ุจุนุฏ ูุญุธุฉ ุฃูู ููุจุน ูู ุงููุงูุน ูู ุดูุก ูู ุงูุชูุฑูุฑ ุงูุฃูุงูู.

ุฅุฐูุ ููู ูููู ุจุชุตุญูุญ ูุฐู ุงูุฃุฎุทุงุกุ ุงูุฅุฌุงุจุฉ ุณููุฉ: ูุง ููุนู ุฐูู. ูุง ูู ููู ุฎุทุฃ CUDA ูุฏูู ุฎุทุฃ ูู ุงูุฐุงูุฑุฉ ุบูุฑ ูุงููุฉ (ููุง ูุนูู ุฃูู ูุง ููุฌุฏ ุฐุงูุฑุฉ ูุงููุฉ ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุฎุงุตุฉ ุจู)ุ ููุฌุจ ุนููู ุฏุงุฆููุง ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ูุชุตุญูุญ ุงูุฎุทุฃ.

ููููุงู ุจุฐูู ูู ุญุงูุชูุงุ ูุง ุนูููุง ุณูู ุฅุนุงุฏุฉ ุงููููุฐุฌ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ูุงุณุชุฏุนุงุฆู ุนูู ุฏูุนุชูุง - ูู ูุชู ููู ุงูุฏูุนุฉ ุงูุชู ุชู ุฅุฑุฌุงุนูุง ุจูุงุณุทุฉ `DataLoader` ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุจุนุฏ:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
2386         )
2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
2389     elif dim == 4:
2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

ูุฐุงุ ูุฅู ุงูุตูุฑุฉ ุฃุตุจุญุช ุฃูุซุฑ ูุถูุญูุง. ุจุฏูุงู ูู ุญุฏูุซ ุฎุทุฃ CUDAุ ูุฏููุง ุงูุขู `IndexError` ูู ุญุณุงุจ ุงูุฎุณุงุฑุฉ (ูุฐุง ูุง ุนูุงูุฉ ููุง ุจุงูุชูุฑูุฑ ุงูุฎูููุ ููุง ูููุง ุณุงุจููุง). ูุจุดูู ุฃูุซุฑ ุชุญุฏูุฏูุงุ ูููููุง ุฃู ูุฑู ุฃู ุงููุฏู 2 ูู ุงูุฐู ูุฎูู ุงูุฎุทุฃุ ูุฐุง ููุฐู ูุญุธุฉ ุฌูุฏุฉ ููุชุญูู ูู ุนุฏุฏ ุงูุนูุงูุงุช ูู ูููุฐุฌูุง:

```python
trainer.model.config.num_labels
```

```python out
2
```

ูุน ูุฌูุฏ ุนูุงูุชููุ ููุณูุญ ููุท ุจู 0 ู1 ูุฃูุฏุงูุ ูููู ููููุง ูุฑุณุงูุฉ ุงูุฎุทุฃ ุงูุชู ุญุตููุง ุนูููุงุ ููุฏ ุญุตููุง ุนูู 2. ูู ุงูุทุจูุนู ุงูุญุตูู ุนูู 2: ุฅุฐุง ุชุฐูุฑูุง ุฃุณูุงุก ุงูุนูุงูุงุช ุงูุชู ุงุณุชุฎุฑุฌูุงูุง ุณุงุจููุงุ ููุฏ ูุงู ููุงู ุซูุงุซุฉุ ูุฐุง ูุฏููุง ุงูููุงุฑุณ 0 ู1 ู2 ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุง. ุงููุดููุฉ ูู ุฃููุง ูู ูุฎุจุฑ ุฐูู ููููุฐุฌูุงุ ูุงูุฐู ูุงู ูู ุงูููุชุฑุถ ุฃู ูุชู ุฅูุดุงุคู ุจุงุณุชุฎุฏุงู ุซูุงุซ ุนูุงูุงุช. ูุฐุง ุฏุนูุง ูุตูุญ ุฐูู!

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
```

ูุญู ูุง ูุฏุฑุฌ ุณุทุฑ `trainer.train()` ุจุนุฏุ ูุฃุฎุฐ ุงูููุช ููุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุจุฏู ุฌูุฏูุง. ุฅุฐุง ุทูุจูุง ุฏูุนุฉ ููุฑุฑูุงูุง ุฅูู ูููุฐุฌูุงุ ูุฅูู ูุนูู ุงูุขู ุฏูู ุฎุทุฃ!

```py
for batch in trainer.get_train_dataloader():
break

outputs = trainer.model.cpu()(**batch)
```

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุงูุงูุชูุงู ูุฑุฉ ุฃุฎุฑู ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุงูุชุญูู ูู ุฃู ูู ุดูุก ูุนูู ุจุดูู ุตุญูุญ:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

ุฅุฐุง ููุช ูุง ุชุฒุงู ุชุญุตู ุนูู ุฎุทุฃุ ูุชุฃูุฏ ูู ุฅุนุงุฏุฉ ุชุดุบูู ุฏูุชุฑ ุงูููุงุญุธุงุช ุงูุฎุงุต ุจู ูุชูููุฐ ุงูุฅุตุฏุงุฑ ุงูุฃุฎูุฑ ูู ุงูุจุฑูุงูุฌ ุงููุตู ููุท.

### ุชูููุฐ ุฎุทูุฉ ุชุญุณูู ูุงุญุฏุฉ

ุงูุขู ุจุนุฏ ุฃู ุนูููุง ุฃูู ูููููุง ุจูุงุก ุฏูุนุงุช ุชูุฑ ุจุงููุนู ุนุจุฑ ุงููููุฐุฌุ ููุญู ูุณุชุนุฏูู ููุฎุทูุฉ ุงูุชุงููุฉ ูู ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ: ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ูุฃุฏุงุก ุฎุทูุฉ ุชุญุณูู.

ุงูุฌุฒุก ุงูุฃูู ูู ูุฌุฑุฏ ูุณุฃูุฉ ุงุณุชุฏุนุงุก ุทุฑููุฉ `backward()` ุนูู ุงูุฎุณุงุฑุฉ:

```py
loss = outputs.loss
loss.backward()
```

ูู ุงููุงุฏุฑ ุฌุฏูุง ุญุฏูุซ ุฎุทุฃ ูู ูุฐู ุงููุฑุญูุฉุ ูููู ุฅุฐุง ุญุฏุซ ุฎุทุฃุ ูุชุฃูุฏ ูู ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ููุญุตูู ุนูู ุฑุณุงูุฉ ุฎุทุฃ ูููุฏุฉ.

ูุฃุฏุงุก ุฎุทูุฉ ุงูุชุญุณููุ ูุญุชุงุฌ ููุท ุฅูู ุฅูุดุงุก "ุงููุญุณู" ูุงุณุชุฏุนุงุก ุทุฑููุฉ `step()` ุงูุฎุงุตุฉ ุจู:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

ูุฑุฉ ุฃุฎุฑูุ ุฅุฐุง ููุช ุชุณุชุฎุฏู ุงููุญุณู ุงูุงูุชุฑุงุถู ูู "ุงููุฏุฑุจ"ุ ููุฌุจ ุฃูุง ุชุญุตู ุนูู ุฎุทุฃ ูู ูุฐู ุงููุฑุญูุฉุ ูููู ุฅุฐุง ูุงู ูุฏูู ูุญุณู ูุฎุตุตุ ููุฏ ุชููู ููุงู ุจุนุถ ุงููุดููุงุช ุงูุชู ูุฌุจ ุชุตุญูุญูุง ููุง. ูุง ุชูุณ ุงูุนูุฏุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ุฅุฐุง ุญุตูุช ุนูู ุฎุทุฃ CUDA ุบุฑูุจ ูู ูุฐู ุงููุฑุญูุฉ. ูุจุงูุญุฏูุซ ุนู ุฃุฎุทุงุก CUDAุ ุฐูุฑูุง ุณุงุจููุง ุญุงูุฉ ุฎุงุตุฉ. ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ุฐูู ุงูุขู.

### ุงูุชุนุงูู ูุน ุฃุฎุทุงุก ุฐุงูุฑุฉ CUDA ุบูุฑ ุงููุงููุฉ

ุนูุฏูุง ุชุญุตู ุนูู ุฑุณุงูุฉ ุฎุทุฃ ุชุจุฏุฃ ุจู "RuntimeError: CUDA out of memory"ุ ูุดูุฑ ุฐูู ุฅูู ุฃู ุฐุงูุฑุฉ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุฏูู ูุฏ ููุฏุช. ูุฐุง ููุณ ูู ุนูุงูุฉ ูุจุงุดุฑุฉ ุจุงูููุฏ ุงูุฎุงุต ุจูุ ููููู ุฃู ูุญุฏุซ ูุน ุจุฑูุงูุฌ ูุตู ูุนูู ุจุดูู ูุซุงูู. ูุดูุฑ ูุฐุง ุงูุฎุทุฃ ุฅูู ุฃูู ุญุงููุช ูุถุน ุงููุซูุฑ ูู ุงูุฃุดูุงุก ูู ุงูุฐุงูุฑุฉ ุงูุฏุงุฎููุฉ ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุงูุฎุงุตุฉ ุจูุ ููุง ุฃุฏู ุฅูู ุญุฏูุซ ุฎุทุฃ. ูุซู ุฃุฎุทุงุก CUDA ุงูุฃุฎุฑูุ ุณุชุญุชุงุฌ ุฅูู ุฅุนุงุฏุฉ ุชุดุบูู ุงูููุงุฉ ุงูุฎุงุตุฉ ุจู ูุชุชููู ูู ุชุดุบูู ุงูุชุฏุฑูุจ ูุฑุฉ ุฃุฎุฑู.

ูุญู ูุฐู ุงููุดููุฉุ ุชุญุชุงุฌ ููุท ุฅูู ุงุณุชุฎุฏุงู ูุณุงุญุฉ ุฃูู ููุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) - ููู ุฃูุฑ ุบุงูุจูุง ูุง ูููู ุฃุณูู ูู ุงูููู ูู ุงููุนู. ุฃููุงูุ ุชุฃูุฏ ูู ุนุฏู ูุฌูุฏ ูููุฐุฌูู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูู ููุณ ุงูููุช (ูุง ูู ููู ุฐูู ูุทููุจูุง ููุดููุชูุ ุจุงูุทุจุน). ุจุนุฏ ุฐููุ ูุฌุจ ุนููู ุนูู ุงูุฃุฑุฌุญ ุชูููู ุญุฌู ุงูุฏูุนุฉุ ุญูุซ ูุคุซุฑ ุฐูู ุจุดูู ูุจุงุดุฑ ุนูู ุฃุญุฌุงู ุฌููุน ุงููุฎุฑุฌุงุช ุงููุณูุทุฉ ูููููุฐุฌ ูุชุฏุฑุฌุงุชูุง. ุฅุฐุง ุงุณุชูุฑุช ุงููุดููุฉุ ูููุฑ ูู ุงุณุชุฎุฏุงู ุฅุตุฏุงุฑ ุฃุตุบุฑ ูู ูููุฐุฌู.

<Tip>
ูู ุงูุฌุฒุก ุงูุชุงูู ูู ุงูุฏูุฑุฉ ุงูุชุฏุฑูุจูุฉุ ุณูููู ูุธุฑุฉ ุนูู ุชูููุงุช ุฃูุซุฑ ุชูุฏููุง ูููู ุฃู ุชุณุงุนุฏู ูู ุชูููู ุงูุจุตูุฉ ุงูุฎุงุตุฉ ุจู ูู ุงูุฐุงูุฑุฉ ูุงูุณูุงุญ ูู ุจุถุจุท ุฃูุจุฑ ุงูููุงุฐุฌ.
</Tip>
## ุชูููู ุงููููุฐุฌ

ุงูุขู ุจุนุฏ ุฃู ูููุง ุจุญู ุฌููุน ุงููุดููุงุช ูู ููุฏูุงุ ุฃุตุจุญ ูู ุดูุก ูุซุงูููุง ููุฌุจ ุฃู ุชุณูุฑ ุนูููุฉ ุงูุชุฏุฑูุจ ุจุณูุงุณุฉุ ุฃููุณ ูุฐููุ ููุณ ุจูุฐู ุงูุณุฑุนุฉ! ุฅุฐุง ููุช ุจุชุดุบูู ุฃูุฑ `trainer.train()`ุ ูุณูุจุฏู ูู ุดูุก ุฌูุฏูุง ูู ุงูุจุฏุงูุฉุ ูููู ุจุนุฏ ูุชุฑุฉ ุณุชุญุตู ุนูู ูุง ููู:

```py
# ุณูุณุชุบุฑู ูุฐุง ููุชูุง ุทูููุงู ูุณููุชุฌ ุนูู ุฎุทุฃุ ูุฐุง ูุง ูุฌุจ ุชุดุบูู ูุฐู ุงูุฎููุฉ
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

ุณุชุฏุฑู ุฃู ูุฐุง ุงูุฎุทุฃ ูุญุฏุซ ุฃุซูุงุก ูุฑุญูุฉ ุงูุชููููุ ูุฐุง ูุฅู ูุฐุง ูู ุขุฎุฑ ุดูุก ุณูุญุชุงุฌ ุฅูู ุชุตุญูุญู.

ููููู ุชุดุบูู ุญููุฉ ุงูุชูููู ูู `Trainer` ุจุดูู ูุณุชูู ุนู ุงูุชุฏุฑูุจ ุนูู ุงููุญู ุงูุชุงูู:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

<Tip>

๐ก ูุฌุจ ุนููู ุฏุงุฆููุง ุงูุชุฃูุฏ ูู ุฃูู ููููู ุชุดุบูู `trainer.evaluate()` ูุจู ุฅุทูุงู `trainer.train()`ุ ูุชุฌูุจ ูุฏุฑ ุงููุซูุฑ ูู ููุงุฑุฏ ุงูุญูุณุจุฉ ูุจู ููุงุฌูุฉ ุฎุทุฃ.

</Tip>

ูุจู ูุญุงููุฉ ุชุตุญูุญ ูุดููุฉ ูู ุญููุฉ ุงูุชููููุ ูุฌุจ ุนููู ุฃููุงู ุงูุชุฃูุฏ ูู ุฃูู ููุช ุจูุญุต ุงูุจูุงูุงุชุ ููุงุฏุฑ ุนูู ุชูููู ุฏูุนุฉ ุจุดูู ุตุญูุญุ ูููููู ุชุดุบูู ูููุฐุฌู ุนูููุง. ููุฏ ุฃููููุง ูู ูุฐู ุงูุฎุทูุงุชุ ูุฐุง ูููู ุชูููุฐ ุงูููุฏ ุงูุชุงูู ุฏูู ุฃุฎุทุงุก:

```py
for batch in trainer.get_eval_dataloader():
break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
outputs = trainer.model(**batch)
```

ูุญุฏุซ ุงูุฎุทุฃ ูุงุญููุงุ ูู ููุงูุฉ ูุฑุญูุฉ ุงูุชููููุ ูุฅุฐุง ูุธุฑูุง ุฅูู ุชุชุจุน ุงูููุฏุณุ ูุณูุฑู ูุฐุง:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
431         """
432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
434         if self.writer is None:
435             self._init_writer()
```

ูุฐุง ูุฎุจุฑูุง ุจุฃู ุงูุฎุทุฃ ููุดุฃ ูู ูุญุฏุฉ `datasets/metric.py` -- ูุฐุง ููุฐู ูุดููุฉ ูู ูุธููุฉ `compute_metrics()` ุงูุฎุงุตุฉ ุจูุง. ุฅููุง ุชุฃุฎุฐ ุฒูุฌูุง ูู ุงูููู ูุน logits ูุงูุนูุงูุงุช ูุตูุงุฆู NumPyุ ูุฐุง ุฏุนูุง ูุญุงูู ุฅุทุนุงููุง ุจุฐูู:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

ูุญุตู ุนูู ููุณ ุงูุฎุทุฃุ ูุฐุง ูุฅู ุงููุดููุฉ ุชููู ุจุงูุชุฃููุฏ ูู ุชูู ุงููุธููุฉ. ุฅุฐุง ูุธุฑูุง ูุฑุฉ ุฃุฎุฑู ุฅูู ููุฏูุงุ ูุณูุฑู ุฃููุง ุชููู ููุท ุจุฅุฑุณุงู `predictions` ู`labels` ุฅูู `metric.compute()`. ูุฐุง ูู ููุงู ูุดููุฉ ูู ูุฐู ุงูุทุฑููุฉุ ููุณ ุญูุง. ุฏุนูุง ูููู ูุธุฑุฉ ุณุฑูุนุฉ ุนูู ุงูุฃุดูุงู:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

ุชูุจุคุงุชูุง ูุง ุชุฒุงู logitsุ ูููุณุช ุงูุชูุจุคุงุช ุงููุนููุฉุ ููุฐุง ูู ุงูุณุจุจ ูู ุนูุฏุฉ ุงููููุงุณ ุฅูู ูุฐุง ุงูุฎุทุฃ (ุงูุบุงูุถ ุฅูู ุญุฏ ูุง). ุงูุญู ุจุณูุท ููุบุงูุฉุ ูู ูุง ุนูููุง ูุนูู ูู ุฅุถุงูุฉ argmax ูู ูุธููุฉ `compute_metrics()`

```py
import numpy as np


def compute_metrics(eval_pred):
predictions, labels = eval_pred
predictions = np.argmax(predictions, axis=1)
return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

ุงูุขู ุชู ุฅุตูุงุญ ุฎุทุฃูุง! ูุงู ูุฐุง ุงูุฃุฎูุฑุ ูุฐุง ูุฅู ูุตูุง ุงูุจุฑูุฌู ุณูููู ุงูุขู ุจุชุฏุฑูุจ ูููุฐุฌ ุจุดูู ุตุญูุญ.

ููุฅุดุงุฑุฉุ ูููุง ููู ุงููุต ุงูุจุฑูุฌู ุงูููุตูุญ ุจุงููุงูู:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
predictions = np.argmax(predictions, axis=1)
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
trainer.train()
```

ูู ูุฐู ุงูุญุงูุฉุ ูุง ุชูุฌุฏ ูุดููุงุช ุฃุฎุฑูุ ูุณููุชุฌ ูุตูุง ุงูุจุฑูุฌู ูููุฐุฌูุง ูู ุดุฃูู ุฃู ููุฏู ูุชุงุฆุฌ ูุนูููุฉ. ูููู ูุงุฐุง ูููููุง ุฃู ููุนู ุนูุฏูุง ูุณุชูุฑ ุงูุชุฏุฑูุจ ุฏูู ุฃู ุฎุทุฃุ ููุง ูุคุฏู ุงููููุฐุฌ ุงููุฏุฑุจ ุฅูู ุฃุฏุงุก ุฌูุฏ ุนูู ุงูุฅุทูุงูุ ูุฐุง ูู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ูุณููุถุญ ูู ุจุนุถ ุงูุชูููุงุช ุงูุชู ูููู ุฃู ุชุณุงุนุฏ.

<Tip>

๐ก ุฅุฐุง ููุช ุชุณุชุฎุฏู ุญููุฉ ุชุฏุฑูุจ ูุฏููุฉุ ุชูุทุจู ุงูุฎุทูุงุช ููุณูุง ูุชุตุญูุญ ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ ุงูุฎุงุต ุจูุ ูููู ูู ุงูุฃุณูู ูุตููุง. ุชุฃูุฏ ูู ุนุฏู ูุณูุงู `model.eval()` ุฃู `model.train()` ูู ุงูุฃูุงูู ุงูุตุญูุญุฉุ ุฃู `zero_grad()` ูู ูู ุฎุทูุฉุ ููุน ุฐูู!

</Tip>

## ุชุตุญูุญ ุงูุฃุฎุทุงุก ุงูุตุงูุชุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ

ูุงุฐุง ูููููุง ุฃู ููุนู ูุชุตุญูุญ ุงูุชุฏุฑูุจ ุงูุฐู ููุชูู ุฏูู ุฎุทุฃ ููููู ูุง ูุญูู ูุชุงุฆุฌ ุฌูุฏุฉุ ุณููุฏู ูู ุจุนุถ ุงููุคุดุฑุงุช ููุงุ ูููู ูู ุนูู ุนูู ุจุฃู ูุฐุง ุงูููุน ูู ุงูุชุตุญูุญ ูู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ููุง ููุฌุฏ ุฅุฌุงุจุฉ ุณุญุฑูุฉ.

### ุชุญูู ูู ุจูุงูุงุชู (ูุฑุฉ ุฃุฎุฑู!)

ูู ูุชุนูู ูููุฐุฌู ุดูุฆูุง ูุง ูู ููู ูู ุงููููู ุจุงููุนู ุชุนูู ุฃู ุดูุก ูู ุจูุงูุงุชู. ุฅุฐุง ูุงู ููุงู ุฎุทุฃ ูุคุฏู ุฅูู ุชูู ุงูุจูุงูุงุช ุฃู ุชู ุชุนููู ุงูุนูุงูุงุช ุจุดูู ุนุดูุงุฆูุ ููู ุงููุญุชูู ุฃูุง ุชุญุตู ุนูู ุฃู ูููุฐุฌ ุชุฏุฑูุจ ุนูู ูุฌููุนุฉ ุจูุงูุงุชู. ูุฐุงุ ุงุจุฏุฃ ุฏุงุฆููุง ุจุงูุชุญูู ุงููุฒุฏูุฌ ูู ุฅุฏุฎุงูุงุชู ูุนูุงูุงุชู ุงููุดูุฑุฉุ ูุงุณุฃู ููุณู ุงูุฃุณุฆูุฉ ุงูุชุงููุฉ:

- ูู ุงูุจูุงูุงุช ุงููุดูุฑุฉ ูููููุฉุ
- ูู ุชูุงูู ุนูู ุงูุนูุงูุงุชุ
- ูู ููุงู ุนูุงูุฉ ูุงุญุฏุฉ ุฃูุซุฑ ุดููุนูุง ูู ุงูุนูุงูุงุช ุงูุฃุฎุฑูุ
- ูุง ูู ุงูุฎุณุงุฑุฉ/ุงูููุงููุณ ุงูุชู ูุฌุจ ุฃู ุชููู ุฅุฐุง ุชูุจุฃ ุงููููุฐุฌ ุจุฅุฌุงุจุฉ ุนุดูุงุฆูุฉ/ููุณ ุงูุฅุฌุงุจุฉ ุฏุงุฆููุงุ

<Tip warning={true}>

โ๏ธ ุฅุฐุง ููุช ุชููู ุจุงูุชุฏุฑูุจ ุงูููุฒุนุ ููู ุจุทุจุงุนุฉ ุนููุงุช ูู ูุฌููุนุฉ ุจูุงูุงุชู ูู ูู ุนูููุฉ ูุชุญูู ุซูุงุซ ูุฑุงุช ูู ุญุตููู ุนูู ููุณ ุงูุดูุก. ุฃุญุฏ ุงูุฃุฎุทุงุก ุงูุดุงุฆุนุฉ ูู ูุฌูุฏ ูุตุฏุฑ ููุงุญุชูุงููุฉ ูู ุฅูุดุงุก ุงูุจูุงูุงุช ูุฌุนู ูู ุนูููุฉ ุชุญุชูู ุนูู ุฅุตุฏุงุฑ ูุฎุชูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.

</Tip>

ุจุนุฏ ุงููุธุฑ ูู ุจูุงูุงุชูุ ุงูุชูู ุฎูุงู ุจุนุถ ุชูุจุคุงุช ูููุฐุฌู ููู ุจูู ุชุดููุฑูุง ุฃูุถูุง. ุฅุฐุง ูุงู ุงููููุฐุฌ ูุชููุน ุฏุงุฆููุง ููุณ ุงูุดูุกุ ููุฏ ูููู ุฐูู ูุฃู ูุฌููุนุฉ ุจูุงูุงุชู ูุชุญูุฒุฉ ูุญู ูุฆุฉ ูุงุญุฏุฉ (ููุดููุงุช ุงูุชุตููู)ุ ูุฏ ุชุณุงุนุฏ ุงูุชูููุงุช ูุซู ุงูุฅูุฑุงุท ูู ุฃุฎุฐ ุนููุงุช ุงููุฆุงุช ุงููุงุฏุฑุฉ.

ุฅุฐุง ูุงูุช ุงูุฎุณุงุฑุฉ/ุงูููุงููุณ ุงูุชู ุชุญุตู ุนูููุง ูู ูููุฐุฌู ุงูุฃููู ูุฎุชููุฉ ูุซูุฑูุง ุนู ุงูุฎุณุงุฑุฉ/ุงูููุงููุณ ุงูุชู ุชุชููุนูุง ููุชูุจุคุงุช ุงูุนุดูุงุฆูุฉุ ูุชุญูู ูู ุทุฑููุฉ ุญุณุงุจ ุฎุณุงุฑุชู ุฃู ูููุงุณูุ ุญูุซ ูู ุงููุญุชูู ุฃู ูููู ููุงู ุฎุทุฃ ููุงู. ุฅุฐุง ููุช ุชุณุชุฎุฏู ุนุฏุฉ ุฎุณุงุฆุฑ ุชุถูููุง ูู ุงูููุงูุฉุ ูุชุฃูุฏ ูู ุฃููุง ุจููุณ ุงูุญุฌู.

ุนูุฏูุง ุชููู ูุชุฃูุฏูุง ูู ุฃู ุจูุงูุงุชู ูุซุงููุฉุ ููููู ูุนุฑูุฉ ูุง ุฅุฐุง ูุงู ุงููููุฐุฌ ูุงุฏุฑูุง ุนูู ุงูุชุฏุฑูุจ ุนูููุง ุจุงุฎุชุจุงุฑ ุจุณูุท ูุงุญุฏ.

### ุงุฌุนู ูููุฐุฌู ููุงุณุจ ุฏูุนุฉ ูุงุญุฏุฉ

ุนุงุฏุฉ ูุง ูุญุงูู ุชุฌูุจ ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูุฃูู ูุนูู ุฃู ุงููููุฐุฌ ูุง ูุชุนูู ุงูุชุนุฑู ุนูู ุงูููุฒุงุช ุงูุนุงูุฉ ุงูุชู ูุฑูุฏ ููู ุฐููุ ููููู ุจุฏูุงู ูู ุฐูู ูููู ููุท ุจุญูุธ ุนููุงุช ุงูุชุฏุฑูุจ. ููุน ุฐููุ ูุฅู ูุญุงููุฉ ุชุฏุฑูุจ ูููุฐุฌู ุนูู ุฏูุนุฉ ูุงุญุฏุฉ ูุฑุงุฑูุง ูุชูุฑุงุฑูุง ูู ุงุฎุชุจุงุฑ ุฌูุฏ ููุชุญูู ููุง ุฅุฐุง ูุงูุช ุงููุดููุฉ ููุง ุญุฏุฏุชูุง ูููู ุญููุง ุจูุงุณุทุฉ ุงููููุฐุฌ ุงูุฐู ุชุญุงูู ุชุฏุฑูุจู. ููุง ุฃูู ุณูุณุงุนุฏู ุนูู ูุนุฑูุฉ ูุง ุฅุฐุง ูุงู ูุนุฏู ุงูุชุนูู ุงูุฃููู ูุฑุชูุนูุง ุฌุฏูุง.

ุฅู ุงูููุงู ุจุฐูู ุจูุฌุฑุฏ ุชุญุฏูุฏ `Trainer` ุงูุฎุงุต ุจู ุฃูุฑ ุณูู ููุบุงูุฉุ ูุง ุนููู ุณูู ุงูุญุตูู ุนูู ุฏูุนุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจุ ุซู ูู ุจุชุดุบูู ุญููุฉ ุชุฏุฑูุจ ูุฏููุฉ ุตุบูุฑุฉ ุจุงุณุชุฎุฏุงู ุชูู ุงูุฏูุนุฉ ููุท ููุฏุฉ 20 ุฎุทูุฉ ุชูุฑูุจูุง:

```py
for batch in trainer.get_train_dataloader():
break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
outputs = trainer.model(**batch)
loss = outputs.loss
loss.backward()
trainer.optimizer.step()
trainer.optimizer.zero_grad()
```

<Tip>

๐ก ุฅุฐุง ูุงูุช ุจูุงูุงุช ุงูุชุฏุฑูุจ ุบูุฑ ูุชูุงุฒูุฉุ ูุชุฃูุฏ ูู ุฅูุดุงุก ุฏูุนุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ุชุญุชูู ุนูู ุฌููุน ุงูุนูุงูุงุช.

</Tip>

ูุฌุจ ุฃู ูููู ูุฏู ุงููููุฐุฌ ุงููุงุชุฌ ูุชุงุฆุฌ ูุซุงููุฉ ุชูุฑูุจูุง ุนูู ููุณ `batch`. ุฏุนูุง ูุญุณุจ ุงููููุงุณ ุนูู ุงูุชูุจุคุงุช ุงููุงุชุฌุฉ:

```py
with torch.no_grad():
outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```

100% ุฏูุฉุ ูุงูุขู ูุฐุง ูุซุงู ุฌูุฏ ุนูู ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ (ููุง ูุนูู ุฃูู ุฅุฐุง ููุช ุจุชุฌุฑุจุฉ ูููุฐุฌู ุนูู ุฃู ุฌููุฉ ุฃุฎุฑูุ ููู ุงููุญุชูู ุฃู ูุนุทูู ุฅุฌุงุจุฉ ุฎุงุทุฆุฉ)!

ุฅุฐุง ูู ุชุชููู ูู ุฌุนู ูููุฐุฌู ูุญูู ูุชุงุฆุฌ ูุซุงููุฉ ูุซู ูุฐูุ ููุฐุง ูุนูู ุฃู ููุงู ุฎุทุฃ ูุง ูู ุทุฑููุฉ ุตูุงุบุฉ ุงููุดููุฉ ุฃู ุจูุงูุงุชูุ ูุฐุง ูุฌุจ ุนููู ุฅุตูุงุญ ุฐูู. ููุท ุนูุฏูุง ุชูุฌุญ ูู ุงุฌุชูุงุฒ ุงุฎุชุจุงุฑ ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ ููููู ุงูุชุฃูุฏ ูู ุฃู ูููุฐุฌู ููููู ุจุงููุนู ุชุนูู ุดูุก ูุง.

<Tip warning={true}>

โ๏ธ ุณูุชุนูู ุนููู ุฅุนุงุฏุฉ ุฅูุดุงุก ูููุฐุฌู ู`Trainer` ุงูุฎุงุต ุจู ุจุนุฏ ูุฐุง ุงูุงุฎุชุจุงุฑุ ุญูุซ ูู ุงููุญุชูู ุฃูุง ูุชููู ุงููููุฐุฌ ุงููุงุชุฌ ูู ุงูุชุนุงูู ูุชุนูู ุดูุก ูููุฏ ุนูู ูุฌููุนุฉ ุจูุงูุงุชู ุงููุงููุฉ.

</Tip>

### ูุง ุชูู ุจุงูุถุจุท ุญุชู ูููู ูุฏูู ุฎุท ุฃุณุงุณ ุฃููู

ูุชู ุงูุชุฃููุฏ ุฏุงุฆููุง ุนูู ุถุจุท ูุฑุท ุงููุนููุงุช ุจุงุนุชุจุงุฑู ุงูุฌุฒุก ุงูุฃุตุนุจ ูู ุงูุชุนูู ุงูุขููุ ููููู ูุฌุฑุฏ ุงูุฎุทูุฉ ุงูุฃุฎูุฑุฉ ููุณุงุนุฏุชู ุนูู ุชุญููู ููุงุณุจ ุทูููุฉ ูู ุงููููุงุณ. ูู ูุนุธู ุงูููุชุ ุชุนูู ูุฑุท ูุนููุงุช ุงูุงูุชุฑุงุถูุฉ ูู `Trainer` ุจุดูู ุฌูุฏ ูุฅุนุทุงุฆู ูุชุงุฆุฌ ุฌูุฏุฉุ ูุฐุง ูุง ุชุทูู ุจุญุซูุง ููุซููุง ููููููุง ุนู ูุฑุท ุงููุนููุงุช ุญุชู ูููู ูุฏูู ุดูุก ูุชููู ุนูู ุฎุท ุงูุฃุณุงุณ ูุฏูู ูู ูุฌููุนุฉ ุจูุงูุงุชู.

ุจูุฌุฑุฏ ุญุตููู ุนูู ูููุฐุฌ ุฌูุฏ ุจูุง ููู ุงูููุงูุฉุ ููููู ุงูุจุฏุก ูู ุงูุชุนุฏูู ููููุงู. ูุง ุชุญุงูู ุฅุทูุงู ุฃูู ุนูููุฉ ุชุดุบูู ุจูุฑุท ูุนููุงุช ูุฎุชููุฉุ ูููู ูุงุฑู ุจูู ุจุถุน ุนูููุงุช ุชุดุบูู ุจูุฑุท ูุนููุงุช ูุฎุชููุฉ ููููุฉ ูุงุญุฏุฉ ููุฑุท ุงููุนููุงุช ููุญุตูู ุนูู ููุฑุฉ ุนู ุงูุชุฃุซูุฑ ุงูุฃูุจุฑ.

ุฅุฐุง ููุช ุชููู ุจุชุนุฏูู ุงููููุฐุฌ ููุณูุ ูุงุญุชูุธ ุจู ุจุณูุทูุง ููุง ุชุญุงูู ุฃู ุดูุก ูุง ูููู ุชุจุฑูุฑู ุจุดูู ูุนููู. ุชุฃูุฏ ุฏุงุฆููุง ูู ุงูุนูุฏุฉ ุฅูู ุงุฎุชุจุงุฑ ุงูุฅูุฑุงุท ูู ุงูููุงุกูุฉ ููุชุญูู ูู ุฃู ุชุบููุฑู ูู ููู ูู ุฃู ุนูุงูุจ ุบูุฑ ููุตูุฏุฉ.

### ุงุทูุจ ุงููุณุงุนุฏุฉ

ูุฃูู ุฃู ุชููู ูุฏ ูุฌุฏุช ุจุนุถ ุงููุตุงุฆุญ ูู ูุฐุง ุงููุณู ูุงูุชู ุณุงุนุฏุชู ูู ุญู ูุดููุชูุ ูููู ุฅุฐุง ูู ููู ุงูุฃูุฑ ูุฐููุ ูุชุฐูุฑ ุฃูู ููููู ุฏุงุฆููุง ุทูุจ ุงููุณุงุนุฏุฉ ูู ุงููุฌุชูุน ูู [ุงูููุชุฏูุงุช](https://discuss.huggingface.co/).

ูููุง ููู ุจุนุถ ุงูููุงุฑุฏ ุงูุฅุถุงููุฉ ุงูุชู ูุฏ ุชููู ูููุฏุฉ:

- ["ูุงุจููุฉ ุฅุนุงุฏุฉ ุงูุฅูุชุงุฌ ููุฑูุจุฉ ูุฃูุถู ุงูููุงุฑุณุงุช ุงูููุฏุณูุฉ"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) ุจููู ุฌููู ุฌุฑูุณ
- ["ูุงุฆูุฉ ูุฑุงุฌุนุฉ ูุชุตุญูุญ ุฃุฎุทุงุก ุงูุดุจูุงุช ุงูุนุตุจูุฉ"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) ุจููู ุณูุณูููุง ุดุงู
- ["ููููุฉ ุงุฎุชุจุงุฑ ุงููุญุฏุฉ ูุฑูุฒ ุงูุชุนูู ุงูุขูู"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) ุจููู ุชุดูุณ ุฑูุจุฑุชุณ
- ["ูุตูุฉ ูุชุฏุฑูุจ ุงูุดุจูุงุช ุงูุนุตุจูุฉ"](http://karpathy.github.io/2019/04/25/recipe/) ุจููู ุฃูุฏุฑูู ูุงุฑุจุงุซู

ุจุงูุทุจุนุ ููุณุช ูู ูุดููุฉ ุชูุงุฌููุง ุนูุฏ ุชุฏุฑูุจ ุงูุดุจูุงุช ุงูุนุตุจูุฉ ุฎุทุฃู! ุฅุฐุง ุตุงุฏูุช ุดูุฆูุง ูู ููุชุจุฉ ๐ค Transformers ุฃู ๐ค Datasets ูุง ูุจุฏู ุตุญูุญูุงุ ููุฏ ุชููู ูุงุฌูุช ุฎุทุฃู. ูุฌุจ ุนููู ุจุงูุชุฃููุฏ ุฅุฎุจุงุฑูุง ุจูู ุดูุก ุนููุ ููู ุงููุณู ุงูุชุงูู ุณูุดุฑุญ ุจุงูุถุจุท ููููุฉ ุงูููุงู ุจุฐูู.