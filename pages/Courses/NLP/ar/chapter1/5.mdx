# نماذج التشفير[[encoder-models]]

<CourseFloatingBanner
    chapter={1}
    classNames="absolute z-10 right-0 top-0"
/>

<Youtube id="MUqNwgPjJvQ" />

تستخدم نماذج التشفير مُشفِّر نموذج المحول فقط. في كل مرحلة، يمكن لطبقات الانتباه الوصول إلى جميع الكلمات في الجملة الأولية. غالبًا ما تتميز هذه النماذج بامتلاكها انتباه "ثنائي الاتجاه"، وغالبًا ما تسمى *نماذج التشفير التلقائي*.

يدور التدريب المسبق لهذه النماذج عادةً حول إتلاف جملة معينة بطريقة ما (على سبيل المثال، عن طريق إخفاء كلمات عشوائية فيها) وتكليف النموذج بإيجاد أو إعادة بناء الجملة الأولية.

تُناسب نماذج التشفير بشكل أفضل المهام التي تتطلب فهمًا للجملة الكاملة، مثل تصنيف الجمل، والتعرف على الكيانات المسماة (وبشكل أعم تصنيف الكلمات)، والإجابة على الأسئلة الاستخراجية.

تشمل الأمثلة على هذه العائلة من النماذج:

- [ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)
- [BERT](https://huggingface.co/docs/transformers/model_doc/bert)
- [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)
- [ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)
- [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)