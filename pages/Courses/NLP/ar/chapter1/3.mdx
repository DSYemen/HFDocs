# المحولات، ماذا يمكنها أن تفعل؟ [[transformers-what-can-they-do]]

<CourseFloatingBanner chapter={1}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
]} />

في هذا القسم، سنلقي نظرة على ما يمكن أن تفعله نماذج المحولات ونستخدم أول أداة لدينا من مكتبة 🤗 Transformers: دالة `pipeline()`.

<Tip>
👀 هل ترى زر *فتح في Colab* في أعلى اليمين؟ انقر عليه لفتح دفتر ملاحظات Google Colab مع جميع نماذج التعليمات البرمجية لهذا القسم. سيكون هذا الزر موجودًا في أي قسم يحتوي على أمثلة للتعليمات البرمجية.

إذا كنت ترغب في تشغيل الأمثلة محليًا، فإننا نوصي بإلقاء نظرة على <a href="/course/chapter0">الإعداد</a>.
</Tip>

## المحولات في كل مكان! [[transformers-are-everywhere]]

تُستخدم نماذج المحولات لحل جميع أنواع مهام البرمجة اللغوية العصبية، مثل تلك المذكورة في القسم السابق. إليك بعض الشركات والمؤسسات التي تستخدم Hugging Face ونماذج المحولات، والتي تساهم أيضًا في المجتمع من خلال مشاركة نماذجها:

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG" alt="Companies using Hugging Face" width="100%">

توفر [مكتبة 🤗 Transformers](https://github.com/huggingface/transformers) الوظائف لإنشاء واستخدام هذه النماذج المشتركة. يحتوي [مركز النماذج](https://huggingface.co/models) على آلاف النماذج المدربة مسبقًا والتي يمكن لأي شخص تنزيلها واستخدامها. يمكنك أيضًا تحميل نماذجك الخاصة إلى المركز!

<Tip>
⚠️ لا يقتصر مركز Hugging Face على نماذج المحولات. يمكن لأي شخص مشاركة أي نوع من النماذج أو مجموعات البيانات التي يريدها! <a href="https://huggingface.co/join">أنشئ حسابًا على huggingface.co</a> للاستفادة من جميع الميزات المتاحة!
</Tip>

قبل الخوض في كيفية عمل نماذج المحولات من الداخل، دعونا نلقي نظرة على بعض الأمثلة لكيفية استخدامها لحل بعض مشاكل البرمجة اللغوية العصبية المثيرة للاهتمام.

## العمل مع خطوط الأنابيب [[working-with-pipelines]]

<Youtube id="tiZFewofSLM" />

الكائن الأكثر أساسية في مكتبة 🤗 Transformers هو دالة `pipeline()`. تربط هذه الدالة نموذجًا بخطوات المعالجة المسبقة والمعالجة اللاحقة اللازمة، مما يسمح لنا بإدخال أي نص مباشرة والحصول على إجابة مفهومة:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

يمكننا حتى تمرير عدة جمل!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

بشكل افتراضي، يختار خط الأنابيب هذا نموذجًا معينًا مدربًا مسبقًا لتحليل المشاعر باللغة الإنجليزية. يتم تنزيل النموذج وتخزينه مؤقتًا عند إنشاء كائن `classifier`. إذا قمت بإعادة تشغيل الأمر، فسيتم استخدام النموذج المخزن مؤقتًا بدلاً من ذلك ولن تكون هناك حاجة لتنزيل النموذج مرة أخرى.

هناك ثلاث خطوات رئيسية متضمنة عند تمرير نص إلى خط أنابيب:

1. تتم معالجة النص مسبقًا إلى تنسيق يمكن للنموذج فهمه.
2. يتم تمرير المدخلات المعالجة مسبقًا إلى النموذج.
3. تتم معالجة تنبؤات النموذج لاحقًا، حتى تتمكن من فهمها.


بعض [خطوط الأنابيب المتاحة](https://huggingface.co/transformers/main_classes/pipelines) حاليًا هي:

- `feature-extraction` (الحصول على تمثيل متجه للنص)
- `fill-mask`
- `ner` (التعرف على الكيانات المسماة)
- `question-answering`
- `sentiment-analysis`
- `summarization`
- `text-generation`
- `translation`
- `zero-shot-classification`

دعونا نلقي نظرة على بعض هذه!

## تصنيف بدون بيانات [[zero-shot-classification]]

سنبدأ بمعالجة مهمة أكثر صعوبة حيث نحتاج إلى تصنيف نصوص لم يتم تصنيفها. هذا سيناريو شائع في المشاريع الواقعية لأن التعليق على النص عادة ما يستغرق وقتًا طويلاً ويتطلب خبرة في المجال. بالنسبة لحالة الاستخدام هذه، فإن خط أنابيب `zero-shot-classification` قوي جدًا: فهو يسمح لك بتحديد التصنيفات التي سيتم استخدامها للتصنيف، لذلك لا يتعين عليك الاعتماد على تصنيفات النموذج المدرب مسبقًا. لقد رأيت بالفعل كيف يمكن للنموذج تصنيف جملة على أنها إيجابية أو سلبية باستخدام هذين التصنيفين - ولكن يمكنه أيضًا تصنيف النص باستخدام أي مجموعة أخرى من التصنيفات التي تريدها.

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python out
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

يُطلق على خط الأنابيب هذا اسم *بدون بيانات* لأنه لا تحتاج إلى ضبط النموذج على بياناتك لاستخدامه. يمكنه مباشرةً إرجاع درجات الاحتمال لأي قائمة من التصنيفات تريدها!

<Tip>

✏️ **جربه!** العب مع التسلسلات والتصنيفات الخاصة بك وشاهد كيف يتصرف النموذج.

</Tip>


## توليد النصوص [[text-generation]]

الآن دعونا نرى كيفية استخدام خط أنابيب لتوليد بعض النصوص. الفكرة الرئيسية هنا هي أنك تقدم مطالبة وسيقوم النموذج بإكمالها تلقائيًا عن طريق إنشاء النص المتبقي. يشبه هذا ميزة النص التنبؤي الموجودة في العديد من الهواتف. يتضمن توليد النصوص عشوائية، لذا من الطبيعي ألا تحصل على نفس النتائج الموضحة أدناه.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python out
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows — data flows of various types, as seen by the '
                    'HTTP'}]
```

يمكنك التحكم في عدد التسلسلات المختلفة التي يتم إنشاؤها باستخدام الوسيطة `num_return_sequences` والطول الإجمالي للنص الناتج باستخدام الوسيطة `max_length`.

<Tip>

✏️ **جربه!** استخدم الوسيطتين `num_return_sequences` و `max_length` لإنشاء جملتين من 15 كلمة لكل منهما.

</Tip>


## استخدام أي نموذج من المركز في خط أنابيب [[using-any-model-from-the-hub-in-a-pipeline]]

استخدمت الأمثلة السابقة النموذج الافتراضي للمهمة قيد البحث، ولكن يمكنك أيضًا اختيار نموذج معين من المركز لاستخدامه في خط أنابيب لمهمة محددة - على سبيل المثال، توليد النصوص. انتقل إلى [مركز النماذج](https://huggingface.co/models) وانقر على العلامة المقابلة على اليسار لعرض النماذج المدعومة فقط لتلك المهمة. يجب أن تصل إلى صفحة مثل [هذه الصفحة](https://huggingface.co/models?pipeline_tag=text-generation).

دعونا نجرب نموذج [`distilgpt2`](https://huggingface.co/distilgpt2)! إليك كيفية تحميله في نفس خط الأنابيب كما كان من قبل:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python out
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```


يمكنك تحسين بحثك عن نموذج عن طريق النقر فوق علامات اللغة، واختيار نموذج سينشئ نصًا بلغة أخرى. يحتوي مركز النماذج حتى على نقاط تفتيش للنماذج متعددة اللغات التي تدعم عدة لغات.

بمجرد تحديد نموذج عن طريق النقر فوقه، سترى أنه توجد أداة تمكنك من تجربته مباشرة عبر الإنترنت. بهذه الطريقة يمكنك اختبار قدرات النموذج بسرعة قبل تنزيله.

<Tip>

✏️ **جربه!** استخدم الفلاتر للعثور على نموذج توليد نصوص بلغة أخرى. لا تتردد في اللعب بالأداة واستخدامها في سلسلة عمليات!

</Tip>

### واجهة برمجة التطبيقات للاستدلال[[the-inference-api]]

يمكن اختبار جميع النماذج مباشرة من خلال متصفحك باستخدام واجهة برمجة التطبيقات للاستدلال، والمتاحة على [موقع](https://huggingface.co/) Hugging Face. يمكنك اللعب بالنموذج مباشرة على هذه الصفحة عن طريق إدخال نص مخصص ومشاهدة النموذج وهو يعالج بيانات الإدخال.

واجهة برمجة التطبيقات للاستدلال التي تشغل الأداة متاحة أيضًا كمنتج مدفوع، وهو أمر مفيد إذا كنت بحاجة إليه لسير عملك. راجع [صفحة التسعير](https://huggingface.co/pricing) لمزيد من التفاصيل.


## ملء الأقنعة[[mask-filling]]

سلسلة العمليات التالية التي ستجربها هي `fill-mask`. تتمثل فكرة هذه المهمة في ملء الفراغات في نص معين:

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python out
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

يتحكم الوسيط `top_k` في عدد الاحتمالات التي تريد عرضها. لاحظ هنا أن النموذج يملأ كلمة `<mask>` الخاصة، والتي غالبًا ما يشار إليها باسم *رمز القناع*. قد تحتوي نماذج ملء الأقنعة الأخرى على رموز أقنعة مختلفة، لذلك من الجيد دائمًا التحقق من كلمة القناع المناسبة عند استكشاف نماذج أخرى. إحدى طرق التحقق من ذلك هي النظر إلى كلمة القناع المستخدمة في الأداة.

<Tip>

✏️ **جربه!** ابحث عن نموذج `bert-base-cased` في المركز وحدد كلمة القناع الخاصة به في أداة واجهة برمجة التطبيقات للاستدلال. ماذا يتنبأ هذا النموذج للجملة في مثال `pipeline` أعلاه؟

</Tip>

## التعرف على الكيانات المسماة[[named-entity-recognition]]

التعرف على الكيانات المسماة (NER) هي مهمة حيث يجب على النموذج العثور على أجزاء نص الإدخال التي تتوافق مع كيانات مثل الأشخاص أو المواقع أو المؤسسات. لنلقِ نظرة على مثال:

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

هنا حدد النموذج بشكل صحيح أن Sylvain هو شخص (PER) و Hugging Face مؤسسة (ORG) و Brooklyn موقع (LOC).

نقوم بتمرير الخيار `grouped_entities=True` في دالة إنشاء سلسلة العمليات لإخبار سلسلة العمليات بإعادة تجميع أجزاء الجملة التي تتوافق مع نفس الكيان معًا: هنا قام النموذج بتجميع "Hugging" و "Face" بشكل صحيح كمؤسسة واحدة، على الرغم من أن الاسم يتكون من كلمات متعددة. في الواقع، كما سنرى في الفصل التالي، فإن المعالجة المسبقة تقسم بعض الكلمات إلى أجزاء أصغر. على سبيل المثال، يتم تقسيم `Sylvain` إلى أربعة أجزاء: `S` و `##yl` و `##va` و `##in`. في خطوة المعالجة اللاحقة، أعادت سلسلة العمليات تجميع هذه القطع بنجاح.


<Tip>

✏️ **جربه!** ابحث في مركز النماذج عن نموذج قادر على القيام بوسم أجزاء الكلام (عادة ما يتم اختصاره كـ POS) باللغة الإنجليزية. ماذا يتنبأ هذا النموذج للجملة في المثال أعلاه؟

</Tip>

## الإجابة على الأسئلة[[question-answering]]

تجيب سلسلة عمليات `question-answering` على الأسئلة باستخدام المعلومات من سياق معين:

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python out
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

لاحظ أن سلسلة العمليات هذه تعمل عن طريق استخراج المعلومات من السياق المقدم؛ إنها لا تولد الإجابة.

## التلخيص[[summarization]]

التلخيص هو مهمة اختزال نص إلى نص أقصر مع الاحتفاظ بجميع (أو معظم) الجوانب المهمة المشار إليها في النص. إليك مثال:

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)
```

```python out
[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]
```

كما هو الحال مع توليد النصوص، يمكنك تحديد `max_length` أو `min_length` للنتيجة.


## الترجمة[[translation]]

بالنسبة للترجمة، يمكنك استخدام نموذج افتراضي إذا قدمت زوجًا لغويًا في اسم المهمة (مثل `"translation_en_to_fr"`)، ولكن أسهل طريقة هي اختيار النموذج الذي تريد استخدامه في [مركز النماذج](https://huggingface.co/models). هنا سنحاول الترجمة من الفرنسية إلى الإنجليزية:

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python out
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

كما هو الحال مع توليد النصوص والتلخيص، يمكنك تحديد `max_length` أو `min_length` للنتيجة.

<Tip>

✏️ **جربه!** ابحث عن نماذج ترجمة بلغات أخرى وحاول ترجمة الجملة السابقة إلى بضع لغات مختلفة.

</Tip>

سلاسل العمليات المعروضة حتى الآن هي في الغالب لأغراض توضيحية. تمت برمجتها لمهام محددة ولا يمكنها تنفيذ أشكال مختلفة منها. في الفصل التالي، ستتعرف على ما بداخل دالة `pipeline()` وكيفية تخصيص سلوكها.