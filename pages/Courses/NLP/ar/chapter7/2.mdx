<FrameworkSwitchCourse {fw} />

# تصنيف الرموز [[token-classification]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
]} />

{/if}

التطبيق الأول الذي سنستكشفه هو تصنيف الرموز. هذه المهمة العامة تشمل أي مشكلة يمكن صياغتها على أنها "إسناد تسمية إلى كل رمز في جملة"، مثل:

- **التعرف على الكيانات المسماة (NER)**: العثور على الكيانات (مثل الأشخاص أو المواقع أو المنظمات) في جملة. يمكن صياغة هذه المهمة على أنها إسناد تسمية إلى كل رمز من خلال وجود فئة واحدة لكل كيان وفئة واحدة لـ "لا كيان".
- **وسم أجزاء الكلام (POS)**: وضع علامة على كل كلمة في جملة على أنها تتوافق مع جزء معين من الكلام (مثل الاسم أو الفعل أو الصفة، إلخ).
- **التقسيم إلى أجزاء**: العثور على الرموز التي تنتمي إلى نفس الكيان. يمكن صياغة هذه المهمة (التي يمكن دمجها مع POS أو NER) على أنها إسناد تسمية واحدة (عادةً `B-`) إلى أي رموز تكون في بداية جزء، وتسمية أخرى (عادةً `I-`) إلى الرموز التي تكون داخل جزء، وتسمية ثالثة (عادةً `O`) إلى الرموز التي لا تنتمي إلى أي جزء.

<Youtube id="wVHdVlPScxA"/>

بالطبع، هناك العديد من الأنواع الأخرى لمشاكل تصنيف الرموز؛ تلك مجرد أمثلة تمثيلية قليلة. في هذا القسم، سنقوم بضبط نموذج (BERT) على مهمة NER، والذي سيتمكن بعد ذلك من حساب تنبؤات مثل هذا:

<iframe src="https://course-demos-bert-finetuned-ner.hf.space" frameBorder="0" height="350" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

<a class="flex justify-center" href="/huggingface-course/bert-finetuned-ner">
<img class="block dark:hidden lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png" alt="One-hot encoded labels for question answering."/>
</a>

يمكنك العثور على النموذج الذي سنقوم بتدريبه وتحميله إلى Hub والتحقق من تنبؤاته [هنا](https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+name+is+Sylvain+and+I+work+at+Hugging+Face+in+Brooklyn).

## إعداد البيانات [[preparing-the-data]]

أولاً وقبل كل شيء، نحتاج إلى مجموعة بيانات مناسبة لتصنيف الرموز. في هذا القسم، سنستخدم [مجموعة بيانات CoNLL-2003](https://huggingface.co/datasets/conll2003)، والتي تحتوي على قصص إخبارية من رويترز.

<Tip>

💡 طالما أن مجموعة بياناتك تتكون من نصوص مقسمة إلى كلمات مع تسمياتها المقابلة، فستتمكن من تكييف إجراءات معالجة البيانات الموضحة هنا مع مجموعة بياناتك الخاصة. راجع [الفصل 5](/course/chapter5) إذا كنت بحاجة إلى تذكير بكيفية تحميل بياناتك المخصصة في `Dataset`.

</Tip>

### مجموعة بيانات CoNLL-2003 [[the-conll-2003-dataset]]

لتحميل مجموعة بيانات CoNLL-2003، نستخدم طريقة `load_dataset()` من مكتبة 🤗 Datasets:

```py
from datasets import load_dataset

raw_datasets = load_dataset("conll2003")
```

سيقوم هذا بتحميل وتخزين مجموعة البيانات مؤقتًا، كما رأينا في [الفصل 3](/course/chapter3) لمجموعة بيانات GLUE MRPC. يُظهر فحص هذا الكائن لنا الأعمدة الموجودة والتقسيم بين مجموعات التدريب والتحقق والاختبار:

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})
```

على وجه الخصوص، يمكننا أن نرى أن مجموعة البيانات تحتوي على تسميات للمهمات الثلاث التي ذكرناها سابقًا: NER وPOS والتقسيم إلى أجزاء. أحد الاختلافات الكبيرة عن مجموعات البيانات الأخرى هو أن النصوص المدخلة لا يتم تقديمها على أنها جمل أو وثائق، ولكن على أنها قوائم من الكلمات (العمود الأخير يسمى `tokens`، ولكنه يحتوي على كلمات بالمعنى أن هذه هي المدخلات المقطعة مسبقًا التي لا تزال بحاجة إلى المرور عبر المقطّع الرمزي للتقسيم الرمزي الفرعي).

دعنا نلقي نظرة على العنصر الأول من مجموعة التدريب:

```py
raw_datasets["train"][0]["tokens"]
```

```python out
['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']
```

نظرًا لأننا نريد إجراء التعرف على الكيانات المسماة، فسننظر إلى تسميات NER:

```py
raw_datasets["train"][0]["ner_tags"]
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
```

تلك هي التسميات كأعداد صحيحة جاهزة للتدريب، ولكنها ليست بالضرورة مفيدة عندما نريد فحص البيانات. مثل التصنيف النصي، يمكننا الوصول إلى المراسلات بين هذه الأعداد الصحيحة وأسماء التسميات من خلال النظر إلى سمة `features` لمجموعة بياناتنا:

```py
ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature
```

```python out
Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)
```

لذلك يحتوي هذا العمود على عناصر تكون تسلسلات من `ClassLabel`s. نوع عناصر التسلسل موجود في سمة `feature` لهذا `ner_feature`، ويمكننا الوصول إلى قائمة الأسماء من خلال النظر إلى سمة `names` لهذا `feature`:

```py
label_names = ner_feature.feature.names
label_names
```

```python out
['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']
```

لقد رأينا هذه التسميات بالفعل عند التعمق في خط أنابيب `token-classification` في [الفصل 6](/course/chapter6/3)، ولكن للتذكير السريع:

- `O` يعني أن الكلمة لا تتوافق مع أي كيان.
- `B-PER`/`I-PER` يعني أن الكلمة تتوافق مع بداية/داخل كيان *شخص*.
- `B-ORG`/`I-ORG` يعني أن الكلمة تتوافق مع بداية/داخل كيان *منظمة*.
- `B-LOC`/`I-LOC` يعني أن الكلمة تتوافق مع بداية/داخل كيان *موقع*.
- `B-MISC`/`I-MISC` يعني أن الكلمة تتوافق مع بداية/داخل كيان *متنوع*.

الآن فك تشفير التسميات التي رأيناها سابقًا يعطينا هذا:

```python
words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)
```

```python out
'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'
```
ولمثال يجمع بين علامتي `B-` و `I-`، إليك ما ينتجه نفس الكود على عنصر مجموعة التدريب عند الفهرس 4:

```python out
'Germany \'s representative to the European Union \'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'
```

كما نرى، فإن الكيانات الممتدة على كلمتين، مثل "European Union" و"Werner Zwingmann"، تُنسب لها علامة `B-` للكلمة الأولى وعلامة `I-` للكلمة الثانية.

<Tip>

✏️ **دورك الآن!** اطبع نفس الجملتين مع علامات الوسم أو التقطيع الخاصة بهما.

</Tip>

### معالجة البيانات[[processing-the-data]]

<Youtube id="iY2AZYdZAr0"/>

كما هو معتاد، نحتاج إلى تحويل نصوصنا إلى معرفات الرموز قبل أن يتمكن النموذج من فهمها. كما رأينا في [الفصل 6](/course/chapter6/)، هناك اختلاف كبير في حالة مهام تصنيف الرموز، حيث لدينا مدخلات مسبقة التقطيع. لحسن الحظ، يمكن لواجهة برمجة التقطيع التعامل مع ذلك بسهولة؛ كل ما نحتاج إليه هو تحذير `tokenizer` بعلم خاص.

لنبدأ بإنشاء كائن `tokenizer` الخاص بنا. كما ذكرنا سابقاً، سنستخدم نموذج BERT مسبق التدريب، لذا سنبدأ بتنزيل وتخزين محول الرموز المرتبط:

```python
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

يمكنك استبدال `model_checkpoint` بأي نموذج آخر تفضله من [Hub](https://huggingface.co/models)، أو باستخدام مجلد محلي قمت بحفظ نموذج مسبق التدريب ومحول رموز فيه. القيد الوحيد هو أن محول الرموز يجب أن يكون مدعومًا بمكتبة 🤗 Tokenizers، بحيث يكون هناك إصدار "سريع" متاح. يمكنك الاطلاع على جميع البنى التي تأتي مع إصدار سريع في [هذا الجدول الكبير](https://huggingface.co/transformers/#supported-frameworks)، وللتأكد من أن كائن `tokenizer` الذي تستخدمه مدعوم بالفعل من 🤗 Tokenizers يمكنك التحقق من سمة `is_fast`:

```py
tokenizer.is_fast
```

```python out
True
```

لتحويل مدخلات مسبقة التقطيع إلى رموز، يمكننا استخدام `tokenizer` الخاص بنا كالمعتاد وإضافة `is_split_into_words=True`:

```py
inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()
```

```python out
['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']
```

كما نرى، أضاف محول الرموز الرموز الخاصة التي يستخدمها النموذج (`[CLS]` في البداية و`[SEP]` في النهاية) وترك معظم الكلمات دون تغيير. ومع ذلك، تم تقطيع الكلمة `lamb` إلى كلمتين فرعيتين، `la` و`##mb`. هذا يخلق عدم تطابق بين مدخلاتنا والعلامات: قائمة العلامات تحتوي على 9 عناصر فقط، في حين أن مدخلاتنا الآن تحتوي على 12 رمز. من السهل حساب الرموز الخاصة (نحن نعرف أنها في البداية والنهاية)، ولكننا نحتاج أيضًا إلى التأكد من محاذاة جميع العلامات مع الكلمات الصحيحة.

لحسن الحظ، لأننا نستخدم محول رموز سريع، يمكننا الوصول إلى قدرات 🤗 Tokenizers الخارقة، مما يعني أنه يمكننا بسهولة مطابقة كل رمز مع الكلمة المقابلة (كما رأينا في [الفصل 6](/course/chapter6/3)):

```py
inputs.word_ids()
```

```python out
[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]
```

مع القليل من العمل، يمكننا بعد ذلك توسيع قائمة العلامات لمطابقة الرموز. القاعدة الأولى التي سنطبقها هي أن الرموز الخاصة تحصل على علامة `-100`. هذا لأنه، بشكل افتراضي، يتم تجاهل الفهرس `-100` في دالة الخسارة التي سنستخدمها (الانتروبيا المتقاطعة). ثم يحصل كل رمز على نفس العلامة مثل الرمز الذي بدأ الكلمة التي يوجد بداخلها، حيث إنها جزء من نفس الكيان. بالنسبة للرموز داخل الكلمة ولكن ليس في البداية، نستبدل `B-` بـ `I-` (حيث لا يبدأ الرمز الكيان):

```python
def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # بداية كلمة جديدة!
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # رمز خاص
            new_labels.append(-100)
        else:
            # نفس الكلمة كالرمز السابق
            label = labels[word_id]
            # إذا كانت العلامة B-XXX، نغيرها إلى I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels
```

دعنا نجربها على جملتنا الأولى:

```py
labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
```

كما نرى، أضافت دالتنا `-100` للرمزين الخاصين في البداية والنهاية، و`0` جديدة لكلمتنا التي تم تقسيمها إلى رمزين.

<Tip>

✏️ **دورك الآن!** يفضل بعض الباحثين إسناد علامة واحدة فقط لكل كلمة، وتعيين `-100` للرموز الفرعية الأخرى في كلمة معينة. هذا لتجنب الكلمات الطويلة التي تنقسم إلى العديد من الرموز الفرعية التي تساهم بشكل كبير في الخسارة. غيّر الدالة السابقة لمطابقة العلامات مع معرفات المدخلات باتباع هذه القاعدة.

</Tip>

لمعالجة مجموعة بياناتنا بالكامل، نحتاج إلى تقطيع جميع المدخلات وتطبيق `align_labels_with_tokens()` على جميع العلامات. للاستفادة من سرعة محول الرموز السريع، من الأفضل تقطيع الكثير من النصوص في نفس الوقت، لذا سنكتب دالة تقوم بمعالجة قائمة من الأمثلة واستخدام طريقة `Dataset.map()` مع الخيار `batched=True`. الشيء الوحيد المختلف عن مثالنا السابق هو أن دالة `word_ids()` تحتاج إلى الحصول على فهرس المثال الذي نريد معرفات كلماته عندما تكون المدخلات إلى محول الرموز قوائم من النصوص (أو في حالتنا، قوائم من قوائم الكلمات)، لذا نضيف ذلك أيضًا:

```py
def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs
```

لاحظ أننا لم نقم بعد بملء مدخلاتنا؛ سنفعل ذلك لاحقًا، عند إنشاء الدفعات باستخدام أداة تجميع البيانات.

يمكننا الآن تطبيق كل هذه المعالجة في خطوة واحدة على التقسيمات الأخرى لمجموعة بياناتنا:

```py
tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
```
```
لقد أنجزنا الجزء الأصعب! الآن بعد أن تم معالجة البيانات مسبقًا، سيكون التدريب الفعلي مشابهًا لما قمنا به في [الفصل 3](/course/chapter3).

{#if fw === 'pt'}

## ضبط نموذج الدقة باستخدام واجهة برمجة التطبيقات `Trainer`[[fine-tuning-the-model-with-the-trainer-api]]

سيكون الكود الفعلي باستخدام `Trainer` هو نفسه كما في السابق؛ التغييرات الوحيدة هي طريقة تجميع البيانات في دفعة ووظيفة حساب المقياس.

{:else}

## ضبط نموذج الدقة باستخدام Keras[[fine-tuning-the-model-with-keras]]

سيكون الكود الفعلي باستخدام Keras مشابهًا جدًا لما سبق؛ التغييرات الوحيدة هي طريقة تجميع البيانات في دفعة ووظيفة حساب المقياس.

{/if}


### تجميع البيانات[[data-collation]]

لا يمكننا استخدام `DataCollatorWithPadding` مثلما فعلنا في [الفصل 3](/course/chapter3) لأن ذلك يقوم فقط بملء المدخلات (معرفات الإدخال، وقناع الانتباه، ومعرفات نوع الرمز). هنا يجب أن يتم ملء التصنيفات بنفس الطريقة تمامًا مثل المدخلات بحيث تبقى بنفس الحجم، باستخدام `-100` كقيمة بحيث يتم تجاهل التوقعات المقابلة في حساب الخسارة.

يتم ذلك كله بواسطة [`DataCollatorForTokenClassification`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification). مثل `DataCollatorWithPadding`، فإنه يأخذ `tokenizer` المستخدمة لمعالجة المدخلات مسبقًا:

{#if fw === 'pt'}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)
```

{:else}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)
```

{/if}

لاختبار هذا على بعض العينات، يمكننا فقط استدعاؤه على قائمة من الأمثلة من مجموعة بياناتنا المعالجة بالرموز:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]
```

```python out
tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])
```

دعنا نقارن هذا بالتصنيفات للعنصر الأول والثاني في مجموعة بياناتنا:

```py
for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])
```

```python out
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]
```

{#if fw === 'pt'}

كما نرى، تم ملء مجموعة التصنيفات الثانية إلى طول المجموعة الأولى باستخدام `-100`s.

{:else}

مجمّع البيانات جاهز للاستخدام! الآن دعنا نستخدمه لإنشاء `tf.data.Dataset` باستخدام طريقة `to_tf_dataset()`. يمكنك أيضًا استخدام `model.prepare_tf_dataset()` للقيام بذلك مع القليل من كود التعبئة - سترى هذا في بعض الأقسام الأخرى من هذا الفصل.

```py
tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

المحطة التالية: النموذج نفسه.

{/if}

{#if fw === 'tf'}

### تعريف النموذج[[defining-the-model]]

نظرًا لأننا نعمل على مشكلة تصنيف الرموز، فسنستخدم فئة `TFAutoModelForTokenClassification`. الشيء الرئيسي الذي يجب تذكره عند تعريف هذا النموذج هو تمرير بعض المعلومات حول عدد التصنيفات التي لدينا. أسهل طريقة للقيام بذلك هي تمرير ذلك العدد مع حجة `num_labels`، ولكن إذا أردنا أداة استدلال تعمل بشكل جيد مثل التي رأيناها في بداية هذا القسم، فمن الأفضل تعيين المراسلات الصحيحة للتصنيفات بدلاً من ذلك.

يجب تعيينها بواسطة قاموسين، `id2label` و `label2id`، واللذان يحتويان على الخريطة من المعرف إلى التصنيف والعكس:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

الآن يمكننا فقط تمريرهما إلى طريقة `TFAutoModelForTokenClassification.from_pretrained()`، وسيتم تعيينهما في تكوين النموذج، ثم يتم حفظهما وتحميلهما بشكل صحيح إلى المركز:

```py
from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

مثلما قمنا بتعريف `TFAutoModelForSequenceClassification` في [الفصل 3](/course/chapter3)، فإن إنشاء النموذج يصدر تحذيرًا بأن بعض الأوزان لم يتم استخدامها (التي من رأس المعالجة المسبقة) وبعض الأوزان الأخرى تم تهيئتها عشوائيًا (التي من رأس تصنيف الرموز الجديد)، وأنه يجب تدريب هذا النموذج. سنقوم بذلك بعد قليل، ولكن دعنا نتأكد أولاً من أن نموذجنا لديه العدد الصحيح من التصنيفات:

```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>

⚠️ إذا كان لديك نموذج بالعدد الخاطئ من التصنيفات، فستحصل على خطأ غامض عند استدعاء `model.fit()` لاحقًا. قد يكون من المزعج تصحيح هذا الخطأ، لذا تأكد من إجراء هذا الفحص للتأكد من أن لديك العدد المتوقع من التصنيفات.

</Tip>

### ضبط نموذج الدقة[[fine-tuning-the-model]]

نحن الآن مستعدون لتدريب نموذجنا! لدينا القليل من الأعمال المنزلية الإضافية للقيام بها أولاً، على الرغم من ذلك: يجب أن نقوم بتسجيل الدخول إلى Hugging Face وتحديد معلمات التدريب الخاصة بنا. إذا كنت تعمل في دفتر ملاحظات، فهناك وظيفة ملائمة لمساعدتك في ذلك:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيظهر هذا عنصر واجهة مستخدم يمكنك من خلاله إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face.

إذا لم تكن تعمل في دفتر ملاحظات، فما عليك سوى كتابة السطر التالي في طرفيتك:

```bash
huggingface-cli login
```

بعد تسجيل الدخول، يمكننا إعداد كل ما نحتاجه لتجميع نموذجنا. يوفر 🤗 Transformers وظيفة `create_optimizer()` ملائمة ستمنحك محسن `AdamW` مع الإعدادات المناسبة لاضمحلال الوزن وسرعة تعلم الوزن، وكلاهما سيحسن أداء نموذجك مقارنةً بالمحسن `Adam` المدمج:

```python
from transformers import create_optimizer
import tensorflow as tf

# التدريب بدقة النقطة العائمة المختلطة 16
# قم بتعليق هذا السطر إذا كنت تستخدم وحدة معالجة الرسومات التي لن تستفيد من هذا
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# عدد خطوات التدريب هو عدد العينات في مجموعة البيانات، مقسومًا على حجم الدفعة ثم مضروبًا
# في العدد الإجمالي للدورات. لاحظ أن tf_train_dataset هنا عبارة عن مجموعة بيانات tf.data.Dataset ذات دفعات،
# وليس مجموعة بيانات Hugging Face الأصلية، لذا فإن len() الخاصة بها هي بالفعل num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)
```

لاحظ أيضًا أننا لا نقدم حجة `loss` إلى `compile()`. وذلك لأن النماذج يمكنها بالفعل حساب الخسارة داخليًا - إذا قمت بالتجميع بدون خسارة وقمت بتزويد التصنيفات الخاصة بك في قاموس الإدخال (كما نفعل في مجموعات بياناتنا)، فسيتم تدريب النموذج باستخدام تلك الخسارة الداخلية، والتي ستكون مناسبة للمهمة ونوع النموذج الذي اخترته.

بعد ذلك، نقوم بتعريف `PushToHubCallback` لتحميل نموذجنا إلى المركز أثناء التدريب، وتناسب النموذج مع ذلك الاستدعاء:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)
```
```
يمكنك تحديد الاسم الكامل للمستودع الذي تريد الدفع إليه باستخدام حجة `hub_model_id` (على وجه التحديد، سيتعين عليك استخدام هذه الحجة للدفع إلى منظمة). على سبيل المثال، عندما قمنا بدفع النموذج إلى منظمة [`huggingface-course`](https://huggingface.co/huggingface-course)، أضفنا `hub_model_id="huggingface-course/bert-finetuned-ner"`. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة عملك وسيتم تسميته وفقًا لدليل الإخراج الذي حددته، على سبيل المثال `"cool_huggingface_user/bert-finetuned-ner"`.

<Tip>

💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون نسخة محلية من المستودع الذي تريد الدفع إليه. إذا لم يكن كذلك، فستحصل على خطأ عند استدعاء `model.fit()` وسيتعين عليك تعيين اسم جديد.

</Tip>

لاحظ أنه أثناء التدريب، كل مرة يتم فيها حفظ النموذج (هنا، كل حقبة) يتم تحميله إلى المركز في الخلفية. بهذه الطريقة، ستتمكن من استئناف تدريبك على آلة أخرى إذا لزم الأمر.

في هذه المرحلة، يمكنك استخدام أداة الاستدلال على مركز النماذج لاختبار نموذجك ومشاركته مع أصدقائك. لقد قمت بضبط نموذج على مهمة تصنيف الرموز بنجاح - تهانينا! ولكن كم هو جيد نموذجنا حقًا؟ يجب أن نقيم بعض المقاييس لمعرفة ذلك.

{/if}


### المقاييس[[metrics]]

{#if fw === 'pt'}

لجعل `Trainer` يحسب مقياسًا كل حقبة، سنحتاج إلى تعريف دالة `compute_metrics()` تأخذ مصفوفات التوقعات والعلامات، وتعيد قاموسًا بأسماء المقاييس وقيمها.

الإطار التقليدي المستخدم لتقييم تنبؤات تصنيف الرموز هو [*seqeval*](https://github.com/chakki-works/seqeval). لاستخدام هذا المقياس، نحتاج أولاً إلى تثبيت مكتبة *seqeval*:

```py
!pip install seqeval
```

يمكننا بعد ذلك تحميله عبر دالة `evaluate.load()` كما فعلنا في [الفصل 3](/course/chapter3):

{:else}

الإطار التقليدي المستخدم لتقييم تنبؤات تصنيف الرموز هو [*seqeval*](https://github.com/chakki-works/seqeval). لاستخدام هذا المقياس، نحتاج أولاً إلى تثبيت مكتبة *seqeval*:

```py
!pip install seqeval
```

يمكننا بعد ذلك تحميله عبر دالة `evaluate.load()` كما فعلنا في [الفصل 3](/course/chapter3):

{/if}

```py
import evaluate

metric = evaluate.load("seqeval")
```

هذا المقياس لا يتصرف مثل الدقة القياسية: في الواقع، سيأخذ قوائم العلامات كسلاسل نصية، وليس كأعداد صحيحة، لذلك سيتعين علينا فك تشفير التوقعات والعلامات بالكامل قبل تمريرها إلى المقياس. دعنا نرى كيف يعمل. أولاً، سنحصل على العلامات لمثال التدريب الأول:

```py
labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels
```

```python out
['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']
```

بعد ذلك، يمكننا إنشاء تنبؤات وهمية لتلك العلامات عن طريق تغيير القيمة في الفهرس 2:

```py
predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])
```

لاحظ أن المقياس يأخذ قائمة من التوقعات (ليس فقط واحدة) وقائمة من العلامات. إليك المخرجات:

```python out
{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}
```

{#if fw === 'pt'}

هذا يرسل الكثير من المعلومات! نحصل على الدقة، والاستدعاء، ودرجة F1 لكل كيان منفصل، وكذلك بشكل عام. بالنسبة لحساب مقياسنا، سنحتفظ فقط بالنتيجة الإجمالية، ولكن يمكنك تعديل دالة `compute_metrics()` لإعادة جميع المقاييس التي تريد الإبلاغ عنها.

تقوم دالة `compute_metrics()` هذه أولاً بأخذ argmax من logits لتحويلها إلى تنبؤات (كما هو معتاد، logits والاحتمالات بنفس الترتيب، لذلك لا نحتاج إلى تطبيق softmax). بعد ذلك، يجب علينا تحويل كل من العلامات والتوقعات من أعداد صحيحة إلى سلاسل نصية. نزيل جميع القيم حيث تكون العلامة `-100`، ثم نمرر النتائج إلى طريقة `metric.compute()`:

```py
import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Remove ignored index (special tokens) and convert to labels
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }
```

الآن بعد أن تم ذلك، نحن على وشك تعريف `Trainer`. نحتاج فقط إلى `model` لضبطه!

{:else}

هذا يرسل الكثير من المعلومات! نحصل على الدقة، والاستدعاء، ودرجة F1 لكل كيان منفصل، وكذلك بشكل عام. الآن دعنا نرى ما يحدث إذا حاولنا استخدام تنبؤات نموذجنا الفعلي لحساب بعض الدرجات الحقيقية.

لا يحب TensorFlow دمج تنبؤاتنا معًا، لأنها ذات أطوال متسلسلة متغيرة. هذا يعني أننا لا نستطيع استخدام `model.predict()` - ولكن هذا لن يوقفنا. سنحصل على بعض التنبؤات دفعة واحدة ونقوم بدمجها في قائمة طويلة كبيرة أثناء التنقل، وإسقاط رموز `-100` التي تشير إلى التعتيم/التعبئة، ثم حساب المقاييس على القائمة في النهاية:

```py
import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict_on_batch(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])
```


```python out
{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}
```

كيف كان أداء نموذجك، مقارنة بنموذجنا؟ إذا حصلت على أرقام مماثلة، فقد نجح تدريبك!

{/if}

{#if fw === 'pt'}

### تعريف النموذج[[defining-the-model]]

نظرًا لأننا نعمل على مشكلة تصنيف الرموز، فسنستخدم فئة `AutoModelForTokenClassification`. الشيء الرئيسي الذي يجب تذكره عند تعريف هذا النموذج هو تمرير بعض المعلومات حول عدد العلامات التي لدينا. أسهل طريقة للقيام بذلك هي تمرير هذا العدد باستخدام حجة `num_labels`، ولكن إذا أردنا أداة استدلال لطيفة تعمل مثل التي رأيناها في بداية هذا القسم، فمن الأفضل تعيين المراسلات الصحيحة للعلامات بدلاً من ذلك.

يجب تعيينها بواسطة قاموسين، `id2label` و`label2id`، اللذين يحتويان على الخرائط من المعرف إلى العلامة والعكس:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

الآن يمكننا فقط تمريرها إلى طريقة `AutoModelForTokenClassification.from_pretrained()`، وسيتم تعيينها في تكوين النموذج ثم حفظها وتحميلها بشكل صحيح إلى المركز:

```py
from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```
```
مثلما قمنا بتعريف `AutoModelForSequenceClassification` في [الفصل 3](/course/chapter3)، فإن إنشاء النموذج يصدر تحذيرًا بأن بعض الأوزان لم تستخدم (تلك الخاصة برأس التهيئة المسبقة) وأن بعض الأوزان الأخرى تم تهيئتها عشوائيًا (تلك الخاصة برأس التصنيف الرمزي الجديد)، وأنه يجب تدريب هذا النموذج. سنقوم بذلك بعد قليل، ولكن دعونا أولاً نتأكد من أن نموذجنا لديه العدد الصحيح من التصنيفات:

```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>

⚠️ إذا كان لديك نموذج بعدد غير صحيح من التصنيفات، فستحصل على خطأ غامض عند استدعاء طريقة `Trainer.train()` لاحقًا (شيء مثل "خطأ CUDA: تم تشغيل التأكيد من جانب الجهاز"). هذا هو السبب الأول للأخطاء التي أبلغ عنها المستخدمون لمثل هذه الأخطاء، لذا تأكد من إجراء هذا الفحص للتأكد من أن لديك العدد المتوقع من التصنيفات.

</Tip>

### ضبط دقيق للنموذج[[fine-tuning-the-model]]

نحن الآن مستعدون لتدريب نموذجنا! نحتاج فقط إلى القيام بآخر خطوتين قبل أن نحدد `Trainer` الخاص بنا: تسجيل الدخول إلى Hugging Face وتحديد حجج التدريب. إذا كنت تعمل في دفتر ملاحظات، فهناك وظيفة ملائمة لمساعدتك في ذلك:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيظهر هذا مربعًا يمكنك فيه إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face.

إذا لم تكن تعمل في دفتر ملاحظات، فما عليك سوى كتابة السطر التالي في طرفيتك:

```bash
huggingface-cli login
```

بمجرد الانتهاء من ذلك، يمكننا تحديد `TrainingArguments` الخاصة بنا:

```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)
```

لقد رأيت معظمها من قبل: نحدد بعض المعاملات (مثل معدل التعلم، وعدد العصور التي يجب التدريب عليها، ودرجة التلاشي)، ونحدد `push_to_hub=True` للإشارة إلى أننا نريد حفظ النموذج وتقييمه في نهاية كل عصر، وأننا نريد تحميل نتائجنا إلى Model Hub. لاحظ أنه يمكنك تحديد اسم المستودع الذي تريد التحميل إليه بحجة `hub_model_id` (على وجه الخصوص، سيتعين عليك استخدام هذه الحجة للتحميل إلى منظمة). على سبيل المثال، عندما قمنا بتحميل النموذج إلى منظمة [`huggingface-course`](https://huggingface.co/huggingface-course)، أضفنا `hub_model_id="huggingface-course/bert-finetuned-ner"` إلى `TrainingArguments`. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة الاسم الخاصة بك ويتم تسميته وفقًا لدليل الإخراج الذي قمت بتعيينه، لذا في حالتنا سيكون `"sgugger/bert-finetuned-ner"`.

<Tip>

💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون مستنسخًا محليًا للمستودع الذي تريد التحميل إليه. إذا لم يكن كذلك، فستحصل على خطأ عند تحديد `Trainer` الخاص بك وسيتعين عليك تعيين اسم جديد.

</Tip>

أخيرًا، نقوم فقط بتمرير كل شيء إلى `Trainer` وإطلاق التدريب:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()
```

لاحظ أنه أثناء حدوث التدريب، في كل مرة يتم حفظ النموذج (هنا، كل عصر) يتم تحميله إلى Hub في الخلفية. بهذه الطريقة، ستتمكن من استئناف تدريبك على آلة أخرى إذا لزم الأمر.

بمجرد اكتمال التدريب، نستخدم طريقة `push_to_hub()` للتأكد من تحميل أحدث إصدار من النموذج:

```py
trainer.push_to_hub(commit_message="Training complete")
```

تعيد هذه الأوامر عنوان URL للالتزام الذي قام به للتو، إذا كنت تريد فحصه:

```python out
'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'
```

يقوم `Trainer` أيضًا بمسودة بطاقة نموذج بجميع نتائج التقييم وتحميلها. في هذه المرحلة، يمكنك استخدام أداة الاستدلال على Model Hub لاختبار نموذجك ومشاركته مع أصدقائك. لقد قمت بضبط دقيق ناجح لنموذج على مهمة تصنيف الرموز - تهانينا!

إذا كنت تريد الغوص بشكل أعمق قليلاً في حلقة التدريب، فسنريكم الآن كيفية القيام بنفس الشيء باستخدام 🤗 Accelerate.

## حلقة تدريب مخصصة[[a-custom-training-loop]]

دعونا الآن نلقي نظرة على حلقة التدريب الكاملة، حتى تتمكن من تخصيص الأجزاء التي تحتاجها. ستبدو إلى حد كبير مثل ما فعلناه في [الفصل 3](/course/chapter3/4)، مع بعض التغييرات للتقييم.

### إعداد كل شيء للتدريب[[preparing-everything-for-training]]

أولاً نحتاج إلى بناء `DataLoader`s من مجموعات البيانات الخاصة بنا. سنعيد استخدام `data_collator` كـ `collate_fn` ونخلط مجموعة التدريب، ولكن ليس مجموعة التحقق:

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)
```

بعد ذلك، نعيد إنشاء نموذجنا، للتأكد من أننا لا نواصل الضبط الدقيق من قبل ولكن نبدأ من نموذج BERT المتهيئ مسبقًا مرة أخرى:

```py
model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

بعد ذلك، سنحتاج إلى محسن. سنستخدم `AdamW` الكلاسيكي، والذي يشبه `Adam`، ولكن مع إصلاح في طريقة تطبيق درجة التلاشي:

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

بمجرد حصولنا على كل هذه الأشياء، يمكننا إرسالها إلى طريقة `accelerator.prepare()`:

```py
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

<Tip>

🚨 إذا كنت تتدرب على TPU، فستحتاج إلى نقل كل التعليمات البرمجية بدءًا من الخلية أعلاه إلى وظيفة تدريب مخصصة. راجع [الفصل 3](/course/chapter3) لمزيد من التفاصيل.

</Tip>

الآن بعد أن أرسلنا `train_dataloader` الخاص بنا إلى `accelerator.prepare()`، يمكننا استخدام طوله لحساب عدد خطوات التدريب. تذكر أنه يجب علينا دائمًا القيام بذلك بعد إعداد محمل البيانات، حيث ستغير هذه الطريقة طوله. نستخدم جدولًا خطيًا كلاسيكيًا من معدل التعلم إلى 0:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

أخيرًا، لدفع نموذجنا إلى Hub، سنحتاج إلى إنشاء كائن `Repository` في مجلد عمل. قم بتسجيل الدخول إلى Hugging Face، إذا لم تكن مسجلاً الدخول بالفعل. سنحدد اسم المستودع من معرف النموذج الذي نريد إعطاءه لنموذجنا (لا تتردد في استبدال `repo_name` بخيارك الخاص؛ كل ما يحتاجه هو احتواء اسم المستخدم الخاص بك، وهو ما تقوم به وظيفة `get_full_repo_name()`):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-ner-accelerate'
```

بعد ذلك، يمكننا استنساخ هذا المستودع في مجلد محلي. إذا كان موجودًا بالفعل، فيجب أن يكون هذا المجلد المحلي مستنسخًا محليًا للمستودع الذي نعمل معه:

```py
output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
يمكننا الآن رفع أي شيء نحفظه في `output_dir` عن طريق استدعاء طريقة `repo.push_to_hub()` . هذا سيساعدنا في رفع النماذج الوسيطة في نهاية كل حقبة.

### حلقة التدريب[[training-loop]]

نحن الآن مستعدون لكتابة حلقة التدريب الكاملة. لتبسيط الجزء التقييمي، نحدد هذه الدالة `postprocess()` التي تأخذ التوقعات والعلامات وتحولها إلى قوائم من السلاسل النصية، مثل ما يتوقعه كائن `metric` :

```py
def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # إزالة الفهرس المهمل (الرموز الخاصة) وتحويلها إلى علامات
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions
```

ثم يمكننا كتابة حلقة التدريب. بعد تحديد شريط التقدم لمتابعة كيفية التدريب، تحتوي الحلقة على ثلاثة أجزاء:

- التدريب في حد ذاته، وهو التكرار الكلاسيكي على `train_dataloader`، والمرور الأمامي عبر النموذج، ثم المرور الخلفي وخطوة المحسن.
- التقييم، حيث يوجد شيء جديد بعد الحصول على مخرجات نموذجنا على دفعة: نظرًا لأن عمليتين قد قامتا بملء المدخلات والعلامات إلى أشكال مختلفة، نحتاج إلى استخدام `accelerator.pad_across_processes()` لجعل التوقعات والعلامات بنفس الشكل قبل استدعاء طريقة `gather()` . إذا لم نفعل ذلك، فإن التقييم إما أن يخطئ أو يعلق إلى الأبد. ثم نرسل النتائج إلى `metric.add_batch()` ونستدعي `metric.compute()` بمجرد انتهاء حلقة التقييم.
- الحفظ والرفع، حيث نقوم أولاً بحفظ النموذج والمحلل اللغوي، ثم نستدعي `repo.push_to_hub()`. لاحظ أننا نستخدم الحجة `blocking=False` لإخبار مكتبة 🤗 Hub بالدفع في عملية غير متزامنة. بهذه الطريقة، يستمر التدريب بشكل طبيعي ويتم تنفيذ هذا الأمر (الطويل) في الخلفية.

هنا الكود الكامل لحلقة التدريب:

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # ضروري لملء التوقعات والعلامات لتجميعها
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

في حالة كانت هذه هي المرة الأولى التي ترى فيها نموذجًا محفوظًا مع 🤗 Accelerate، دعنا نأخذ لحظة لفحص أسطر الكود الثلاثة التي تذهب معها:

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```

السطر الأول واضح بذاته: فهو يخبر جميع العمليات بالانتظار حتى يصل الجميع إلى تلك المرحلة قبل الاستمرار. هذا للتأكد من أن لدينا نفس النموذج في كل عملية قبل الحفظ. ثم نأخذ `unwrapped_model`، وهو النموذج الأساسي الذي حددناه. تغير طريقة `accelerator.prepare()` النموذج للعمل في التدريب الموزع، لذلك لن يكون لديه طريقة `save_pretrained()` بعد الآن؛ طريقة `accelerator.unwrap_model()` تلغي تلك الخطوة. أخيرًا، نستدعي `save_pretrained()` لكن نخبر تلك الطريقة باستخدام `accelerator.save()` بدلاً من `torch.save()`.

بمجرد الانتهاء من ذلك، يجب أن يكون لديك نموذج ينتج نتائج مشابهة جدًا للذي تم تدريبه مع `Trainer`. يمكنك التحقق من النموذج الذي قمنا بتدريبه باستخدام هذا الكود في [*huggingface-course/bert-finetuned-ner-accelerate*](https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate). وإذا كنت ترغب في اختبار أي تعديلات على حلقة التدريب، يمكنك تنفيذها مباشرة عن طريق تحرير الكود الموضح أعلاه!

{/if}

## استخدام النموذج الدقيق[[using-the-fine-tuned-model]]

لقد أظهرنا لك بالفعل كيف يمكنك استخدام النموذج الذي قمنا بضبطه الدقيق على Model Hub مع أداة التخمين. لاستخدامه محليًا في `pipeline`، عليك فقط تحديد معرف النموذج الصحيح:

```py
from transformers import pipeline

# استبدل هذا بمعرف نقطة التفتيش الخاصة بك
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
```

رائع! يعمل نموذجنا بنفس جودة النموذج الافتراضي لهذا الأنبوب!