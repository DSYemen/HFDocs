<FrameworkSwitchCourse {fw} />

# ุชุตููู ุงูุฑููุฒ [[token-classification]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
]} />

{/if}

ุงูุชุทุจูู ุงูุฃูู ุงูุฐู ุณูุณุชูุดูู ูู ุชุตููู ุงูุฑููุฒ. ูุฐู ุงููููุฉ ุงูุนุงูุฉ ุชุดูู ุฃู ูุดููุฉ ูููู ุตูุงุบุชูุง ุนูู ุฃููุง "ุฅุณูุงุฏ ุชุณููุฉ ุฅูู ูู ุฑูุฒ ูู ุฌููุฉ"ุ ูุซู:

- **ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉ (NER)**: ุงูุนุซูุฑ ุนูู ุงูููุงูุงุช (ูุซู ุงูุฃุดุฎุงุต ุฃู ุงูููุงูุน ุฃู ุงูููุธูุงุช) ูู ุฌููุฉ. ูููู ุตูุงุบุฉ ูุฐู ุงููููุฉ ุนูู ุฃููุง ุฅุณูุงุฏ ุชุณููุฉ ุฅูู ูู ุฑูุฒ ูู ุฎูุงู ูุฌูุฏ ูุฆุฉ ูุงุญุฏุฉ ููู ููุงู ููุฆุฉ ูุงุญุฏุฉ ูู "ูุง ููุงู".
- **ูุณู ุฃุฌุฒุงุก ุงูููุงู (POS)**: ูุถุน ุนูุงูุฉ ุนูู ูู ูููุฉ ูู ุฌููุฉ ุนูู ุฃููุง ุชุชูุงูู ูุน ุฌุฒุก ูุนูู ูู ุงูููุงู (ูุซู ุงูุงุณู ุฃู ุงููุนู ุฃู ุงูุตูุฉุ ุฅูุฎ).
- **ุงูุชูุณูู ุฅูู ุฃุฌุฒุงุก**: ุงูุนุซูุฑ ุนูู ุงูุฑููุฒ ุงูุชู ุชูุชูู ุฅูู ููุณ ุงูููุงู. ูููู ุตูุงุบุฉ ูุฐู ุงููููุฉ (ุงูุชู ูููู ุฏูุฌูุง ูุน POS ุฃู NER) ุนูู ุฃููุง ุฅุณูุงุฏ ุชุณููุฉ ูุงุญุฏุฉ (ุนุงุฏุฉู `B-`) ุฅูู ุฃู ุฑููุฒ ุชููู ูู ุจุฏุงูุฉ ุฌุฒุกุ ูุชุณููุฉ ุฃุฎุฑู (ุนุงุฏุฉู `I-`) ุฅูู ุงูุฑููุฒ ุงูุชู ุชููู ุฏุงุฎู ุฌุฒุกุ ูุชุณููุฉ ุซุงูุซุฉ (ุนุงุฏุฉู `O`) ุฅูู ุงูุฑููุฒ ุงูุชู ูุง ุชูุชูู ุฅูู ุฃู ุฌุฒุก.

<Youtube id="wVHdVlPScxA"/>

ุจุงูุทุจุนุ ููุงู ุงูุนุฏูุฏ ูู ุงูุฃููุงุน ุงูุฃุฎุฑู ููุดุงูู ุชุตููู ุงูุฑููุฒุ ุชูู ูุฌุฑุฏ ุฃูุซูุฉ ุชูุซูููุฉ ููููุฉ. ูู ูุฐุง ุงููุณูุ ุณูููู ุจุถุจุท ูููุฐุฌ (BERT) ุนูู ูููุฉ NERุ ูุงูุฐู ุณูุชููู ุจุนุฏ ุฐูู ูู ุญุณุงุจ ุชูุจุคุงุช ูุซู ูุฐุง:

<iframe src="https://course-demos-bert-finetuned-ner.hf.space" frameBorder="0" height="350" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

<a class="flex justify-center" href="/huggingface-course/bert-finetuned-ner">
<img class="block dark:hidden lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png" alt="One-hot encoded labels for question answering."/>
</a>

ููููู ุงูุนุซูุฑ ุนูู ุงููููุฐุฌ ุงูุฐู ุณูููู ุจุชุฏุฑูุจู ูุชุญูููู ุฅูู Hub ูุงูุชุญูู ูู ุชูุจุคุงุชู [ููุง](https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+name+is+Sylvain+and+I+work+at+Hugging+Face+in+Brooklyn).

## ุฅุนุฏุงุฏ ุงูุจูุงูุงุช [[preparing-the-data]]

ุฃููุงู ููุจู ูู ุดูุกุ ูุญุชุงุฌ ุฅูู ูุฌููุนุฉ ุจูุงูุงุช ููุงุณุจุฉ ูุชุตููู ุงูุฑููุฒ. ูู ูุฐุง ุงููุณูุ ุณูุณุชุฎุฏู [ูุฌููุนุฉ ุจูุงูุงุช CoNLL-2003](https://huggingface.co/datasets/conll2003)ุ ูุงูุชู ุชุญุชูู ุนูู ูุตุต ุฅุฎุจุงุฑูุฉ ูู ุฑููุชุฑุฒ.

<Tip>

๐ก ุทุงููุง ุฃู ูุฌููุนุฉ ุจูุงูุงุชู ุชุชููู ูู ูุตูุต ููุณูุฉ ุฅูู ูููุงุช ูุน ุชุณููุงุชูุง ุงูููุงุจูุฉุ ูุณุชุชููู ูู ุชูููู ุฅุฌุฑุงุกุงุช ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูููุถุญุฉ ููุง ูุน ูุฌููุนุฉ ุจูุงูุงุชู ุงูุฎุงุตุฉ. ุฑุงุฌุน [ุงููุตู 5](/course/chapter5) ุฅุฐุง ููุช ุจุญุงุฌุฉ ุฅูู ุชุฐููุฑ ุจููููุฉ ุชุญููู ุจูุงูุงุชู ุงููุฎุตุตุฉ ูู `Dataset`.

</Tip>

### ูุฌููุนุฉ ุจูุงูุงุช CoNLL-2003 [[the-conll-2003-dataset]]

ูุชุญููู ูุฌููุนุฉ ุจูุงูุงุช CoNLL-2003ุ ูุณุชุฎุฏู ุทุฑููุฉ `load_dataset()` ูู ููุชุจุฉ ๐ค Datasets:

```py
from datasets import load_dataset

raw_datasets = load_dataset("conll2003")
```

ุณูููู ูุฐุง ุจุชุญููู ูุชุฎุฒูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุคูุชูุงุ ููุง ุฑุฃููุง ูู [ุงููุตู 3](/course/chapter3) ููุฌููุนุฉ ุจูุงูุงุช GLUE MRPC. ููุธูุฑ ูุญุต ูุฐุง ุงููุงุฆู ููุง ุงูุฃุนูุฏุฉ ุงูููุฌูุฏุฉ ูุงูุชูุณูู ุจูู ูุฌููุนุงุช ุงูุชุฏุฑูุจ ูุงูุชุญูู ูุงูุงุฎุชุจุงุฑ:

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})
```

ุนูู ูุฌู ุงูุฎุตูุตุ ูููููุง ุฃู ูุฑู ุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชุญุชูู ุนูู ุชุณููุงุช ูููููุงุช ุงูุซูุงุซ ุงูุชู ุฐูุฑูุงูุง ุณุงุจููุง: NER ูPOS ูุงูุชูุณูู ุฅูู ุฃุฌุฒุงุก. ุฃุญุฏ ุงูุงุฎุชูุงูุงุช ุงููุจูุฑุฉ ุนู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฃุฎุฑู ูู ุฃู ุงููุตูุต ุงููุฏุฎูุฉ ูุง ูุชู ุชูุฏูููุง ุนูู ุฃููุง ุฌูู ุฃู ูุซุงุฆูุ ูููู ุนูู ุฃููุง ููุงุฆู ูู ุงููููุงุช (ุงูุนููุฏ ุงูุฃุฎูุฑ ูุณูู `tokens`ุ ููููู ูุญุชูู ุนูู ูููุงุช ุจุงููุนูู ุฃู ูุฐู ูู ุงููุฏุฎูุงุช ุงูููุทุนุฉ ูุณุจููุง ุงูุชู ูุง ุชุฒุงู ุจุญุงุฌุฉ ุฅูู ุงููุฑูุฑ ุนุจุฑ ุงูููุทูุน ุงูุฑูุฒู ููุชูุณูู ุงูุฑูุฒู ุงููุฑุนู).

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ุงูุนูุตุฑ ุงูุฃูู ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ:

```py
raw_datasets["train"][0]["tokens"]
```

```python out
['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']
```

ูุธุฑูุง ูุฃููุง ูุฑูุฏ ุฅุฌุฑุงุก ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉุ ูุณููุธุฑ ุฅูู ุชุณููุงุช NER:

```py
raw_datasets["train"][0]["ner_tags"]
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
```

ุชูู ูู ุงูุชุณููุงุช ูุฃุนุฏุงุฏ ุตุญูุญุฉ ุฌุงูุฒุฉ ููุชุฏุฑูุจุ ูููููุง ููุณุช ุจุงูุถุฑูุฑุฉ ูููุฏุฉ ุนูุฏูุง ูุฑูุฏ ูุญุต ุงูุจูุงูุงุช. ูุซู ุงูุชุตููู ุงููุตูุ ูููููุง ุงููุตูู ุฅูู ุงููุฑุงุณูุงุช ุจูู ูุฐู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ ูุฃุณูุงุก ุงูุชุณููุงุช ูู ุฎูุงู ุงููุธุฑ ุฅูู ุณูุฉ `features` ููุฌููุนุฉ ุจูุงูุงุชูุง:

```py
ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature
```

```python out
Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)
```

ูุฐูู ูุญุชูู ูุฐุง ุงูุนููุฏ ุนูู ุนูุงุตุฑ ุชููู ุชุณูุณูุงุช ูู `ClassLabel`s. ููุน ุนูุงุตุฑ ุงูุชุณูุณู ููุฌูุฏ ูู ุณูุฉ `feature` ููุฐุง `ner_feature`ุ ููููููุง ุงููุตูู ุฅูู ูุงุฆูุฉ ุงูุฃุณูุงุก ูู ุฎูุงู ุงููุธุฑ ุฅูู ุณูุฉ `names` ููุฐุง `feature`:

```py
label_names = ner_feature.feature.names
label_names
```

```python out
['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']
```

ููุฏ ุฑุฃููุง ูุฐู ุงูุชุณููุงุช ุจุงููุนู ุนูุฏ ุงูุชุนูู ูู ุฎุท ุฃูุงุจูุจ `token-classification` ูู [ุงููุตู 6](/course/chapter6/3)ุ ูููู ููุชุฐููุฑ ุงูุณุฑูุน:

- `O` ูุนูู ุฃู ุงููููุฉ ูุง ุชุชูุงูู ูุน ุฃู ููุงู.
- `B-PER`/`I-PER` ูุนูู ุฃู ุงููููุฉ ุชุชูุงูู ูุน ุจุฏุงูุฉ/ุฏุงุฎู ููุงู *ุดุฎุต*.
- `B-ORG`/`I-ORG` ูุนูู ุฃู ุงููููุฉ ุชุชูุงูู ูุน ุจุฏุงูุฉ/ุฏุงุฎู ููุงู *ููุธูุฉ*.
- `B-LOC`/`I-LOC` ูุนูู ุฃู ุงููููุฉ ุชุชูุงูู ูุน ุจุฏุงูุฉ/ุฏุงุฎู ููุงู *ูููุน*.
- `B-MISC`/`I-MISC` ูุนูู ุฃู ุงููููุฉ ุชุชูุงูู ูุน ุจุฏุงูุฉ/ุฏุงุฎู ููุงู *ูุชููุน*.

ุงูุขู ูู ุชุดููุฑ ุงูุชุณููุงุช ุงูุชู ุฑุฃููุงูุง ุณุงุจููุง ูุนุทููุง ูุฐุง:

```python
words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)
```

```python out
'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'
```
ูููุซุงู ูุฌูุน ุจูู ุนูุงูุชู `B-` ู `I-`ุ ุฅููู ูุง ููุชุฌู ููุณ ุงูููุฏ ุนูู ุนูุตุฑ ูุฌููุนุฉ ุงูุชุฏุฑูุจ ุนูุฏ ุงูููุฑุณ 4:

```python out
'Germany \'s representative to the European Union \'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'
```

ููุง ูุฑูุ ูุฅู ุงูููุงูุงุช ุงูููุชุฏุฉ ุนูู ูููุชููุ ูุซู "European Union" ู"Werner Zwingmann"ุ ุชููุณุจ ููุง ุนูุงูุฉ `B-` ูููููุฉ ุงูุฃููู ูุนูุงูุฉ `I-` ูููููุฉ ุงูุซุงููุฉ.

<Tip>

โ๏ธ **ุฏูุฑู ุงูุขู!** ุงุทุจุน ููุณ ุงูุฌููุชูู ูุน ุนูุงูุงุช ุงููุณู ุฃู ุงูุชูุทูุน ุงูุฎุงุตุฉ ุจููุง.

</Tip>

### ูุนุงูุฌุฉ ุงูุจูุงูุงุช[[processing-the-data]]

<Youtube id="iY2AZYdZAr0"/>

ููุง ูู ูุนุชุงุฏุ ูุญุชุงุฌ ุฅูู ุชุญููู ูุตูุตูุง ุฅูู ูุนุฑูุงุช ุงูุฑููุฒ ูุจู ุฃู ูุชููู ุงููููุฐุฌ ูู ููููุง. ููุง ุฑุฃููุง ูู [ุงููุตู 6](/course/chapter6/)ุ ููุงู ุงุฎุชูุงู ูุจูุฑ ูู ุญุงูุฉ ููุงู ุชุตููู ุงูุฑููุฒุ ุญูุซ ูุฏููุง ูุฏุฎูุงุช ูุณุจูุฉ ุงูุชูุทูุน. ูุญุณู ุงูุญุธุ ูููู ููุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชูุทูุน ุงูุชุนุงูู ูุน ุฐูู ุจุณูููุฉุ ูู ูุง ูุญุชุงุฌ ุฅููู ูู ุชุญุฐูุฑ `tokenizer` ุจุนูู ุฎุงุต.

ููุจุฏุฃ ุจุฅูุดุงุก ูุงุฆู `tokenizer` ุงูุฎุงุต ุจูุง. ููุง ุฐูุฑูุง ุณุงุจูุงูุ ุณูุณุชุฎุฏู ูููุฐุฌ BERT ูุณุจู ุงูุชุฏุฑูุจุ ูุฐุง ุณูุจุฏุฃ ุจุชูุฒูู ูุชุฎุฒูู ูุญูู ุงูุฑููุฒ ุงููุฑุชุจุท:

```python
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

ููููู ุงุณุชุจุฏุงู `model_checkpoint` ุจุฃู ูููุฐุฌ ุขุฎุฑ ุชูุถูู ูู [Hub](https://huggingface.co/models)ุ ุฃู ุจุงุณุชุฎุฏุงู ูุฌูุฏ ูุญูู ููุช ุจุญูุธ ูููุฐุฌ ูุณุจู ุงูุชุฏุฑูุจ ููุญูู ุฑููุฒ ููู. ุงูููุฏ ุงููุญูุฏ ูู ุฃู ูุญูู ุงูุฑููุฒ ูุฌุจ ุฃู ูููู ูุฏุนูููุง ุจููุชุจุฉ ๐ค Tokenizersุ ุจุญูุซ ูููู ููุงู ุฅุตุฏุงุฑ "ุณุฑูุน" ูุชุงุญ. ููููู ุงูุงุทูุงุน ุนูู ุฌููุน ุงูุจูู ุงูุชู ุชุฃุชู ูุน ุฅุตุฏุงุฑ ุณุฑูุน ูู [ูุฐุง ุงูุฌุฏูู ุงููุจูุฑ](https://huggingface.co/transformers/#supported-frameworks)ุ ูููุชุฃูุฏ ูู ุฃู ูุงุฆู `tokenizer` ุงูุฐู ุชุณุชุฎุฏูู ูุฏุนูู ุจุงููุนู ูู ๐ค Tokenizers ููููู ุงูุชุญูู ูู ุณูุฉ `is_fast`:

```py
tokenizer.is_fast
```

```python out
True
```

ูุชุญููู ูุฏุฎูุงุช ูุณุจูุฉ ุงูุชูุทูุน ุฅูู ุฑููุฒุ ูููููุง ุงุณุชุฎุฏุงู `tokenizer` ุงูุฎุงุต ุจูุง ูุงููุนุชุงุฏ ูุฅุถุงูุฉ `is_split_into_words=True`:

```py
inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()
```

```python out
['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']
```

ููุง ูุฑูุ ุฃุถุงู ูุญูู ุงูุฑููุฒ ุงูุฑููุฒ ุงูุฎุงุตุฉ ุงูุชู ูุณุชุฎุฏููุง ุงููููุฐุฌ (`[CLS]` ูู ุงูุจุฏุงูุฉ ู`[SEP]` ูู ุงูููุงูุฉ) ูุชุฑู ูุนุธู ุงููููุงุช ุฏูู ุชุบููุฑ. ููุน ุฐููุ ุชู ุชูุทูุน ุงููููุฉ `lamb` ุฅูู ูููุชูู ูุฑุนูุชููุ `la` ู`##mb`. ูุฐุง ูุฎูู ุนุฏู ุชุทุงุจู ุจูู ูุฏุฎูุงุชูุง ูุงูุนูุงูุงุช: ูุงุฆูุฉ ุงูุนูุงูุงุช ุชุญุชูู ุนูู 9 ุนูุงุตุฑ ููุทุ ูู ุญูู ุฃู ูุฏุฎูุงุชูุง ุงูุขู ุชุญุชูู ุนูู 12 ุฑูุฒ. ูู ุงูุณูู ุญุณุงุจ ุงูุฑููุฒ ุงูุฎุงุตุฉ (ูุญู ูุนุฑู ุฃููุง ูู ุงูุจุฏุงูุฉ ูุงูููุงูุฉ)ุ ูููููุง ูุญุชุงุฌ ุฃูุถูุง ุฅูู ุงูุชุฃูุฏ ูู ูุญุงุฐุงุฉ ุฌููุน ุงูุนูุงูุงุช ูุน ุงููููุงุช ุงูุตุญูุญุฉ.

ูุญุณู ุงูุญุธุ ูุฃููุง ูุณุชุฎุฏู ูุญูู ุฑููุฒ ุณุฑูุนุ ูููููุง ุงููุตูู ุฅูู ูุฏุฑุงุช ๐ค Tokenizers ุงูุฎุงุฑูุฉุ ููุง ูุนูู ุฃูู ูููููุง ุจุณูููุฉ ูุทุงุจูุฉ ูู ุฑูุฒ ูุน ุงููููุฉ ุงูููุงุจูุฉ (ููุง ุฑุฃููุง ูู [ุงููุตู 6](/course/chapter6/3)):

```py
inputs.word_ids()
```

```python out
[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]
```

ูุน ุงููููู ูู ุงูุนููุ ูููููุง ุจุนุฏ ุฐูู ุชูุณูุน ูุงุฆูุฉ ุงูุนูุงูุงุช ููุทุงุจูุฉ ุงูุฑููุฒ. ุงููุงุนุฏุฉ ุงูุฃููู ุงูุชู ุณูุทุจููุง ูู ุฃู ุงูุฑููุฒ ุงูุฎุงุตุฉ ุชุญุตู ุนูู ุนูุงูุฉ `-100`. ูุฐุง ูุฃููุ ุจุดูู ุงูุชุฑุงุถูุ ูุชู ุชุฌุงูู ุงูููุฑุณ `-100` ูู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุงูุชู ุณูุณุชุฎุฏููุง (ุงูุงูุชุฑูุจูุง ุงููุชูุงุทุนุฉ). ุซู ูุญุตู ูู ุฑูุฒ ุนูู ููุณ ุงูุนูุงูุฉ ูุซู ุงูุฑูุฒ ุงูุฐู ุจุฏุฃ ุงููููุฉ ุงูุชู ููุฌุฏ ุจุฏุงุฎููุงุ ุญูุซ ุฅููุง ุฌุฒุก ูู ููุณ ุงูููุงู. ุจุงููุณุจุฉ ููุฑููุฒ ุฏุงุฎู ุงููููุฉ ูููู ููุณ ูู ุงูุจุฏุงูุฉุ ูุณุชุจุฏู `B-` ุจู `I-` (ุญูุซ ูุง ูุจุฏุฃ ุงูุฑูุฒ ุงูููุงู):

```python
def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # ุจุฏุงูุฉ ูููุฉ ุฌุฏูุฏุฉ!
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # ุฑูุฒ ุฎุงุต
            new_labels.append(-100)
        else:
            # ููุณ ุงููููุฉ ูุงูุฑูุฒ ุงูุณุงุจู
            label = labels[word_id]
            # ุฅุฐุง ูุงูุช ุงูุนูุงูุฉ B-XXXุ ูุบูุฑูุง ุฅูู I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels
```

ุฏุนูุง ูุฌุฑุจูุง ุนูู ุฌููุชูุง ุงูุฃููู:

```py
labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
```

ููุง ูุฑูุ ุฃุถุงูุช ุฏุงูุชูุง `-100` ููุฑูุฒูู ุงูุฎุงุตูู ูู ุงูุจุฏุงูุฉ ูุงูููุงูุฉุ ู`0` ุฌุฏูุฏุฉ ููููุชูุง ุงูุชู ุชู ุชูุณูููุง ุฅูู ุฑูุฒูู.

<Tip>

โ๏ธ **ุฏูุฑู ุงูุขู!** ููุถู ุจุนุถ ุงูุจุงุญุซูู ุฅุณูุงุฏ ุนูุงูุฉ ูุงุญุฏุฉ ููุท ููู ูููุฉุ ูุชุนููู `-100` ููุฑููุฒ ุงููุฑุนูุฉ ุงูุฃุฎุฑู ูู ูููุฉ ูุนููุฉ. ูุฐุง ูุชุฌูุจ ุงููููุงุช ุงูุทูููุฉ ุงูุชู ุชููุณู ุฅูู ุงูุนุฏูุฏ ูู ุงูุฑููุฒ ุงููุฑุนูุฉ ุงูุชู ุชุณุงูู ุจุดูู ูุจูุฑ ูู ุงูุฎุณุงุฑุฉ. ุบููุฑ ุงูุฏุงูุฉ ุงูุณุงุจูุฉ ููุทุงุจูุฉ ุงูุนูุงูุงุช ูุน ูุนุฑูุงุช ุงููุฏุฎูุงุช ุจุงุชุจุงุน ูุฐู ุงููุงุนุฏุฉ.

</Tip>

ููุนุงูุฌุฉ ูุฌููุนุฉ ุจูุงูุงุชูุง ุจุงููุงููุ ูุญุชุงุฌ ุฅูู ุชูุทูุน ุฌููุน ุงููุฏุฎูุงุช ูุชุทุจูู `align_labels_with_tokens()` ุนูู ุฌููุน ุงูุนูุงูุงุช. ููุงุณุชูุงุฏุฉ ูู ุณุฑุนุฉ ูุญูู ุงูุฑููุฒ ุงูุณุฑูุนุ ูู ุงูุฃูุถู ุชูุทูุน ุงููุซูุฑ ูู ุงููุตูุต ูู ููุณ ุงูููุชุ ูุฐุง ุณููุชุจ ุฏุงูุฉ ุชููู ุจูุนุงูุฌุฉ ูุงุฆูุฉ ูู ุงูุฃูุซูุฉ ูุงุณุชุฎุฏุงู ุทุฑููุฉ `Dataset.map()` ูุน ุงูุฎูุงุฑ `batched=True`. ุงูุดูุก ุงููุญูุฏ ุงููุฎุชูู ุนู ูุซุงููุง ุงูุณุงุจู ูู ุฃู ุฏุงูุฉ `word_ids()` ุชุญุชุงุฌ ุฅูู ุงูุญุตูู ุนูู ููุฑุณ ุงููุซุงู ุงูุฐู ูุฑูุฏ ูุนุฑูุงุช ูููุงุชู ุนูุฏูุง ุชููู ุงููุฏุฎูุงุช ุฅูู ูุญูู ุงูุฑููุฒ ููุงุฆู ูู ุงููุตูุต (ุฃู ูู ุญุงูุชูุงุ ููุงุฆู ูู ููุงุฆู ุงููููุงุช)ุ ูุฐุง ูุถูู ุฐูู ุฃูุถูุง:

```py
def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs
```

ูุงุญุธ ุฃููุง ูู ููู ุจุนุฏ ุจููุก ูุฏุฎูุงุชูุงุ ุณููุนู ุฐูู ูุงุญููุงุ ุนูุฏ ุฅูุดุงุก ุงูุฏูุนุงุช ุจุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุชุฌููุน ุงูุจูุงูุงุช.

ูููููุง ุงูุขู ุชุทุจูู ูู ูุฐู ุงููุนุงูุฌุฉ ูู ุฎุทูุฉ ูุงุญุฏุฉ ุนูู ุงูุชูุณููุงุช ุงูุฃุฎุฑู ููุฌููุนุฉ ุจูุงูุงุชูุง:

```py
tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
```
```
ููุฏ ุฃูุฌุฒูุง ุงูุฌุฒุก ุงูุฃุตุนุจ! ุงูุขู ุจุนุฏ ุฃู ุชู ูุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุงุ ุณูููู ุงูุชุฏุฑูุจ ุงููุนูู ูุดุงุจููุง ููุง ูููุง ุจู ูู [ุงููุตู 3](/course/chapter3).

{#if fw === 'pt'}

## ุถุจุท ูููุฐุฌ ุงูุฏูุฉ ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช `Trainer`[[fine-tuning-the-model-with-the-trainer-api]]

ุณูููู ุงูููุฏ ุงููุนูู ุจุงุณุชุฎุฏุงู `Trainer` ูู ููุณู ููุง ูู ุงูุณุงุจูุ ุงูุชุบููุฑุงุช ุงููุญูุฏุฉ ูู ุทุฑููุฉ ุชุฌููุน ุงูุจูุงูุงุช ูู ุฏูุนุฉ ููุธููุฉ ุญุณุงุจ ุงููููุงุณ.

{:else}

## ุถุจุท ูููุฐุฌ ุงูุฏูุฉ ุจุงุณุชุฎุฏุงู Keras[[fine-tuning-the-model-with-keras]]

ุณูููู ุงูููุฏ ุงููุนูู ุจุงุณุชุฎุฏุงู Keras ูุดุงุจููุง ุฌุฏูุง ููุง ุณุจูุ ุงูุชุบููุฑุงุช ุงููุญูุฏุฉ ูู ุทุฑููุฉ ุชุฌููุน ุงูุจูุงูุงุช ูู ุฏูุนุฉ ููุธููุฉ ุญุณุงุจ ุงููููุงุณ.

{/if}


### ุชุฌููุน ุงูุจูุงูุงุช[[data-collation]]

ูุง ูููููุง ุงุณุชุฎุฏุงู `DataCollatorWithPadding` ูุซููุง ูุนููุง ูู [ุงููุตู 3](/course/chapter3) ูุฃู ุฐูู ูููู ููุท ุจููุก ุงููุฏุฎูุงุช (ูุนุฑูุงุช ุงูุฅุฏุฎุงูุ ูููุงุน ุงูุงูุชุจุงูุ ููุนุฑูุงุช ููุน ุงูุฑูุฒ). ููุง ูุฌุจ ุฃู ูุชู ููุก ุงูุชุตูููุงุช ุจููุณ ุงูุทุฑููุฉ ุชูุงููุง ูุซู ุงููุฏุฎูุงุช ุจุญูุซ ุชุจูู ุจููุณ ุงูุญุฌูุ ุจุงุณุชุฎุฏุงู `-100` ููููุฉ ุจุญูุซ ูุชู ุชุฌุงูู ุงูุชููุนุงุช ุงูููุงุจูุฉ ูู ุญุณุงุจ ุงูุฎุณุงุฑุฉ.

ูุชู ุฐูู ููู ุจูุงุณุทุฉ [`DataCollatorForTokenClassification`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification). ูุซู `DataCollatorWithPadding`ุ ูุฅูู ูุฃุฎุฐ `tokenizer` ุงููุณุชุฎุฏูุฉ ููุนุงูุฌุฉ ุงููุฏุฎูุงุช ูุณุจููุง:

{#if fw === 'pt'}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)
```

{:else}

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)
```

{/if}

ูุงุฎุชุจุงุฑ ูุฐุง ุนูู ุจุนุถ ุงูุนููุงุชุ ูููููุง ููุท ุงุณุชุฏุนุงุคู ุนูู ูุงุฆูุฉ ูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุชูุง ุงููุนุงูุฌุฉ ุจุงูุฑููุฒ:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]
```

```python out
tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])
```

ุฏุนูุง ููุงุฑู ูุฐุง ุจุงูุชุตูููุงุช ููุนูุตุฑ ุงูุฃูู ูุงูุซุงูู ูู ูุฌููุนุฉ ุจูุงูุงุชูุง:

```py
for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])
```

```python out
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]
```

{#if fw === 'pt'}

ููุง ูุฑูุ ุชู ููุก ูุฌููุนุฉ ุงูุชุตูููุงุช ุงูุซุงููุฉ ุฅูู ุทูู ุงููุฌููุนุฉ ุงูุฃููู ุจุงุณุชุฎุฏุงู `-100`s.

{:else}

ูุฌููุน ุงูุจูุงูุงุช ุฌุงูุฒ ููุงุณุชุฎุฏุงู! ุงูุขู ุฏุนูุง ูุณุชุฎุฏูู ูุฅูุดุงุก `tf.data.Dataset` ุจุงุณุชุฎุฏุงู ุทุฑููุฉ `to_tf_dataset()`. ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู `model.prepare_tf_dataset()` ููููุงู ุจุฐูู ูุน ุงููููู ูู ููุฏ ุงูุชุนุจุฆุฉ - ุณุชุฑู ูุฐุง ูู ุจุนุถ ุงูุฃูุณุงู ุงูุฃุฎุฑู ูู ูุฐุง ุงููุตู.

```py
tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

ุงููุญุทุฉ ุงูุชุงููุฉ: ุงููููุฐุฌ ููุณู.

{/if}

{#if fw === 'tf'}

### ุชุนุฑูู ุงููููุฐุฌ[[defining-the-model]]

ูุธุฑูุง ูุฃููุง ูุนูู ุนูู ูุดููุฉ ุชุตููู ุงูุฑููุฒุ ูุณูุณุชุฎุฏู ูุฆุฉ `TFAutoModelForTokenClassification`. ุงูุดูุก ุงูุฑุฆูุณู ุงูุฐู ูุฌุจ ุชุฐูุฑู ุนูุฏ ุชุนุฑูู ูุฐุง ุงููููุฐุฌ ูู ุชูุฑูุฑ ุจุนุถ ุงููุนูููุงุช ุญูู ุนุฏุฏ ุงูุชุตูููุงุช ุงูุชู ูุฏููุง. ุฃุณูู ุทุฑููุฉ ููููุงู ุจุฐูู ูู ุชูุฑูุฑ ุฐูู ุงูุนุฏุฏ ูุน ุญุฌุฉ `num_labels`ุ ูููู ุฅุฐุง ุฃุฑุฏูุง ุฃุฏุงุฉ ุงุณุชุฏูุงู ุชุนูู ุจุดูู ุฌูุฏ ูุซู ุงูุชู ุฑุฃููุงูุง ูู ุจุฏุงูุฉ ูุฐุง ุงููุณูุ ููู ุงูุฃูุถู ุชุนููู ุงููุฑุงุณูุงุช ุงูุตุญูุญุฉ ููุชุตูููุงุช ุจุฏูุงู ูู ุฐูู.

ูุฌุจ ุชุนููููุง ุจูุงุณุทุฉ ูุงููุณููุ `id2label` ู `label2id`ุ ูุงููุฐุงู ูุญุชููุงู ุนูู ุงูุฎุฑูุทุฉ ูู ุงููุนุฑู ุฅูู ุงูุชุตููู ูุงูุนูุณ:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

ุงูุขู ูููููุง ููุท ุชูุฑูุฑููุง ุฅูู ุทุฑููุฉ `TFAutoModelForTokenClassification.from_pretrained()`ุ ูุณูุชู ุชุนูููููุง ูู ุชูููู ุงููููุฐุฌุ ุซู ูุชู ุญูุธููุง ูุชุญูููููุง ุจุดูู ุตุญูุญ ุฅูู ุงููุฑูุฒ:

```py
from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

ูุซููุง ูููุง ุจุชุนุฑูู `TFAutoModelForSequenceClassification` ูู [ุงููุตู 3](/course/chapter3)ุ ูุฅู ุฅูุดุงุก ุงููููุฐุฌ ูุตุฏุฑ ุชุญุฐูุฑูุง ุจุฃู ุจุนุถ ุงูุฃูุฒุงู ูู ูุชู ุงุณุชุฎุฏุงููุง (ุงูุชู ูู ุฑุฃุณ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ) ูุจุนุถ ุงูุฃูุฒุงู ุงูุฃุฎุฑู ุชู ุชููุฆุชูุง ุนุดูุงุฆููุง (ุงูุชู ูู ุฑุฃุณ ุชุตููู ุงูุฑููุฒ ุงูุฌุฏูุฏ)ุ ูุฃูู ูุฌุจ ุชุฏุฑูุจ ูุฐุง ุงููููุฐุฌ. ุณูููู ุจุฐูู ุจุนุฏ ููููุ ูููู ุฏุนูุง ูุชุฃูุฏ ุฃููุงู ูู ุฃู ูููุฐุฌูุง ูุฏูู ุงูุนุฏุฏ ุงูุตุญูุญ ูู ุงูุชุตูููุงุช:

```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>

โ๏ธ ุฅุฐุง ูุงู ูุฏูู ูููุฐุฌ ุจุงูุนุฏุฏ ุงูุฎุงุทุฆ ูู ุงูุชุตูููุงุชุ ูุณุชุญุตู ุนูู ุฎุทุฃ ุบุงูุถ ุนูุฏ ุงุณุชุฏุนุงุก `model.fit()` ูุงุญููุง. ูุฏ ูููู ูู ุงููุฒุนุฌ ุชุตุญูุญ ูุฐุง ุงูุฎุทุฃุ ูุฐุง ุชุฃูุฏ ูู ุฅุฌุฑุงุก ูุฐุง ุงููุญุต ููุชุฃูุฏ ูู ุฃู ูุฏูู ุงูุนุฏุฏ ุงููุชููุน ูู ุงูุชุตูููุงุช.

</Tip>

### ุถุจุท ูููุฐุฌ ุงูุฏูุฉ[[fine-tuning-the-model]]

ูุญู ุงูุขู ูุณุชุนุฏูู ูุชุฏุฑูุจ ูููุฐุฌูุง! ูุฏููุง ุงููููู ูู ุงูุฃุนูุงู ุงูููุฒููุฉ ุงูุฅุถุงููุฉ ููููุงู ุจูุง ุฃููุงูุ ุนูู ุงูุฑุบู ูู ุฐูู: ูุฌุจ ุฃู ูููู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญุฏูุฏ ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุง. ุฅุฐุง ููุช ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ูููุงู ูุธููุฉ ููุงุฆูุฉ ููุณุงุนุฏุชู ูู ุฐูู:

```python
from huggingface_hub import notebook_login

notebook_login()
```

ุณูุธูุฑ ูุฐุง ุนูุตุฑ ูุงุฌูุฉ ูุณุชุฎุฏู ููููู ูู ุฎูุงูู ุฅุฏุฎุงู ุจูุงูุงุช ุงุนุชูุงุฏ ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face.

ุฅุฐุง ูู ุชูู ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ููุง ุนููู ุณูู ูุชุงุจุฉ ุงูุณุทุฑ ุงูุชุงูู ูู ุทุฑููุชู:

```bash
huggingface-cli login
```

ุจุนุฏ ุชุณุฌูู ุงูุฏุฎููุ ูููููุง ุฅุนุฏุงุฏ ูู ูุง ูุญุชุงุฌู ูุชุฌููุน ูููุฐุฌูุง. ูููุฑ ๐ค Transformers ูุธููุฉ `create_optimizer()` ููุงุฆูุฉ ุณุชููุญู ูุญุณู `AdamW` ูุน ุงูุฅุนุฏุงุฏุงุช ุงูููุงุณุจุฉ ูุงุถูุญูุงู ุงููุฒู ูุณุฑุนุฉ ุชุนูู ุงููุฒูุ ูููุงููุง ุณูุญุณู ุฃุฏุงุก ูููุฐุฌู ููุงุฑูุฉู ุจุงููุญุณู `Adam` ุงููุฏูุฌ:

```python
from transformers import create_optimizer
import tensorflow as tf

# ุงูุชุฏุฑูุจ ุจุฏูุฉ ุงูููุทุฉ ุงูุนุงุฆูุฉ ุงููุฎุชูุทุฉ 16
# ูู ุจุชุนููู ูุฐุง ุงูุณุทุฑ ุฅุฐุง ููุช ุชุณุชุฎุฏู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุชู ูู ุชุณุชููุฏ ูู ูุฐุง
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ ูู ุนุฏุฏ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููุณูููุง ุนูู ุญุฌู ุงูุฏูุนุฉ ุซู ูุถุฑูุจูุง
# ูู ุงูุนุฏุฏ ุงูุฅุฌูุงูู ููุฏูุฑุงุช. ูุงุญุธ ุฃู tf_train_dataset ููุง ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ุจูุงูุงุช tf.data.Dataset ุฐุงุช ุฏูุนุงุชุ
# ูููุณ ูุฌููุนุฉ ุจูุงูุงุช Hugging Face ุงูุฃุตููุฉุ ูุฐุง ูุฅู len() ุงูุฎุงุตุฉ ุจูุง ูู ุจุงููุนู num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)
```

ูุงุญุธ ุฃูุถูุง ุฃููุง ูุง ููุฏู ุญุฌุฉ `loss` ุฅูู `compile()`. ูุฐูู ูุฃู ุงูููุงุฐุฌ ูููููุง ุจุงููุนู ุญุณุงุจ ุงูุฎุณุงุฑุฉ ุฏุงุฎูููุง - ุฅุฐุง ููุช ุจุงูุชุฌููุน ุจุฏูู ุฎุณุงุฑุฉ ูููุช ุจุชุฒููุฏ ุงูุชุตูููุงุช ุงูุฎุงุตุฉ ุจู ูู ูุงููุณ ุงูุฅุฏุฎุงู (ููุง ููุนู ูู ูุฌููุนุงุช ุจูุงูุงุชูุง)ุ ูุณูุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู ุชูู ุงูุฎุณุงุฑุฉ ุงูุฏุงุฎููุฉุ ูุงูุชู ุณุชููู ููุงุณุจุฉ ูููููุฉ ูููุน ุงููููุฐุฌ ุงูุฐู ุงุฎุชุฑุชู.

ุจุนุฏ ุฐููุ ูููู ุจุชุนุฑูู `PushToHubCallback` ูุชุญููู ูููุฐุฌูุง ุฅูู ุงููุฑูุฒ ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูุชูุงุณุจ ุงููููุฐุฌ ูุน ุฐูู ุงูุงุณุชุฏุนุงุก:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)
```
```
ููููู ุชุญุฏูุฏ ุงูุงุณู ุงููุงูู ูููุณุชูุฏุน ุงูุฐู ุชุฑูุฏ ุงูุฏูุน ุฅููู ุจุงุณุชุฎุฏุงู ุญุฌุฉ `hub_model_id` (ุนูู ูุฌู ุงูุชุญุฏูุฏุ ุณูุชุนูู ุนููู ุงุณุชุฎุฏุงู ูุฐู ุงูุญุฌุฉ ููุฏูุน ุฅูู ููุธูุฉ). ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏูุง ูููุง ุจุฏูุน ุงููููุฐุฌ ุฅูู ููุธูุฉ [`huggingface-course`](https://huggingface.co/huggingface-course)ุ ุฃุถููุง `hub_model_id="huggingface-course/bert-finetuned-ner"`. ุจุดูู ุงูุชุฑุงุถูุ ุณูุชู ุงุณุชุฎุฏุงู ุงููุณุชูุฏุน ุงูููุฌูุฏ ูู ูุณุงุญุฉ ุนููู ูุณูุชู ุชุณููุชู ููููุง ูุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ุญุฏุฏุชูุ ุนูู ุณุจูู ุงููุซุงู `"cool_huggingface_user/bert-finetuned-ner"`.

<Tip>

๐ก ุฅุฐุง ูุงู ุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ุชุณุชุฎุฏูู ููุฌูุฏูุง ุจุงููุนูุ ููุฌุจ ุฃู ูููู ูุณุฎุฉ ูุญููุฉ ูู ุงููุณุชูุฏุน ุงูุฐู ุชุฑูุฏ ุงูุฏูุน ุฅููู. ุฅุฐุง ูู ููู ูุฐููุ ูุณุชุญุตู ุนูู ุฎุทุฃ ุนูุฏ ุงุณุชุฏุนุงุก `model.fit()` ูุณูุชุนูู ุนููู ุชุนููู ุงุณู ุฌุฏูุฏ.

</Tip>

ูุงุญุธ ุฃูู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูู ูุฑุฉ ูุชู ูููุง ุญูุธ ุงููููุฐุฌ (ููุงุ ูู ุญูุจุฉ) ูุชู ุชุญูููู ุฅูู ุงููุฑูุฒ ูู ุงูุฎูููุฉ. ุจูุฐู ุงูุทุฑููุฉุ ุณุชุชููู ูู ุงุณุชุฆูุงู ุชุฏุฑูุจู ุนูู ุขูุฉ ุฃุฎุฑู ุฅุฐุง ูุฒู ุงูุฃูุฑ.

ูู ูุฐู ุงููุฑุญูุฉุ ููููู ุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุงูุงุณุชุฏูุงู ุนูู ูุฑูุฒ ุงูููุงุฐุฌ ูุงุฎุชุจุงุฑ ูููุฐุฌู ููุดุงุฑูุชู ูุน ุฃุตุฏูุงุฆู. ููุฏ ููุช ุจุถุจุท ูููุฐุฌ ุนูู ูููุฉ ุชุตููู ุงูุฑููุฒ ุจูุฌุงุญ - ุชูุงูููุง! ูููู ูู ูู ุฌูุฏ ูููุฐุฌูุง ุญููุงุ ูุฌุจ ุฃู ูููู ุจุนุถ ุงูููุงููุณ ููุนุฑูุฉ ุฐูู.

{/if}


### ุงูููุงููุณ[[metrics]]

{#if fw === 'pt'}

ูุฌุนู `Trainer` ูุญุณุจ ูููุงุณูุง ูู ุญูุจุฉุ ุณูุญุชุงุฌ ุฅูู ุชุนุฑูู ุฏุงูุฉ `compute_metrics()` ุชุฃุฎุฐ ูุตูููุงุช ุงูุชููุนุงุช ูุงูุนูุงูุงุชุ ูุชุนูุฏ ูุงููุณูุง ุจุฃุณูุงุก ุงูููุงููุณ ูููููุง.

ุงูุฅุทุงุฑ ุงูุชูููุฏู ุงููุณุชุฎุฏู ูุชูููู ุชูุจุคุงุช ุชุตููู ุงูุฑููุฒ ูู [*seqeval*](https://github.com/chakki-works/seqeval). ูุงุณุชุฎุฏุงู ูุฐุง ุงููููุงุณุ ูุญุชุงุฌ ุฃููุงู ุฅูู ุชุซุจูุช ููุชุจุฉ *seqeval*:

```py
!pip install seqeval
```

ูููููุง ุจุนุฏ ุฐูู ุชุญูููู ุนุจุฑ ุฏุงูุฉ `evaluate.load()` ููุง ูุนููุง ูู [ุงููุตู 3](/course/chapter3):

{:else}

ุงูุฅุทุงุฑ ุงูุชูููุฏู ุงููุณุชุฎุฏู ูุชูููู ุชูุจุคุงุช ุชุตููู ุงูุฑููุฒ ูู [*seqeval*](https://github.com/chakki-works/seqeval). ูุงุณุชุฎุฏุงู ูุฐุง ุงููููุงุณุ ูุญุชุงุฌ ุฃููุงู ุฅูู ุชุซุจูุช ููุชุจุฉ *seqeval*:

```py
!pip install seqeval
```

ูููููุง ุจุนุฏ ุฐูู ุชุญูููู ุนุจุฑ ุฏุงูุฉ `evaluate.load()` ููุง ูุนููุง ูู [ุงููุตู 3](/course/chapter3):

{/if}

```py
import evaluate

metric = evaluate.load("seqeval")
```

ูุฐุง ุงููููุงุณ ูุง ูุชุตุฑู ูุซู ุงูุฏูุฉ ุงูููุงุณูุฉ: ูู ุงููุงูุนุ ุณูุฃุฎุฐ ููุงุฆู ุงูุนูุงูุงุช ูุณูุงุณู ูุตูุฉุ ูููุณ ูุฃุนุฏุงุฏ ุตุญูุญุฉุ ูุฐูู ุณูุชุนูู ุนูููุง ูู ุชุดููุฑ ุงูุชููุนุงุช ูุงูุนูุงูุงุช ุจุงููุงูู ูุจู ุชูุฑูุฑูุง ุฅูู ุงููููุงุณ. ุฏุนูุง ูุฑู ููู ูุนูู. ุฃููุงูุ ุณูุญุตู ุนูู ุงูุนูุงูุงุช ููุซุงู ุงูุชุฏุฑูุจ ุงูุฃูู:

```py
labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels
```

```python out
['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']
```

ุจุนุฏ ุฐููุ ูููููุง ุฅูุดุงุก ุชูุจุคุงุช ููููุฉ ูุชูู ุงูุนูุงูุงุช ุนู ุทุฑูู ุชุบููุฑ ุงููููุฉ ูู ุงูููุฑุณ 2:

```py
predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])
```

ูุงุญุธ ุฃู ุงููููุงุณ ูุฃุฎุฐ ูุงุฆูุฉ ูู ุงูุชููุนุงุช (ููุณ ููุท ูุงุญุฏุฉ) ููุงุฆูุฉ ูู ุงูุนูุงูุงุช. ุฅููู ุงููุฎุฑุฌุงุช:

```python out
{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}
```

{#if fw === 'pt'}

ูุฐุง ูุฑุณู ุงููุซูุฑ ูู ุงููุนูููุงุช! ูุญุตู ุนูู ุงูุฏูุฉุ ูุงูุงุณุชุฏุนุงุกุ ูุฏุฑุฌุฉ F1 ููู ููุงู ูููุตูุ ููุฐูู ุจุดูู ุนุงู. ุจุงููุณุจุฉ ูุญุณุงุจ ูููุงุณูุงุ ุณูุญุชูุธ ููุท ุจุงููุชูุฌุฉ ุงูุฅุฌูุงููุฉุ ูููู ููููู ุชุนุฏูู ุฏุงูุฉ `compute_metrics()` ูุฅุนุงุฏุฉ ุฌููุน ุงูููุงููุณ ุงูุชู ุชุฑูุฏ ุงูุฅุจูุงุบ ุนููุง.

ุชููู ุฏุงูุฉ `compute_metrics()` ูุฐู ุฃููุงู ุจุฃุฎุฐ argmax ูู logits ูุชุญููููุง ุฅูู ุชูุจุคุงุช (ููุง ูู ูุนุชุงุฏุ logits ูุงูุงุญุชูุงูุงุช ุจููุณ ุงูุชุฑุชูุจุ ูุฐูู ูุง ูุญุชุงุฌ ุฅูู ุชุทุจูู softmax). ุจุนุฏ ุฐููุ ูุฌุจ ุนูููุง ุชุญููู ูู ูู ุงูุนูุงูุงุช ูุงูุชููุนุงุช ูู ุฃุนุฏุงุฏ ุตุญูุญุฉ ุฅูู ุณูุงุณู ูุตูุฉ. ูุฒูู ุฌููุน ุงูููู ุญูุซ ุชููู ุงูุนูุงูุฉ `-100`ุ ุซู ููุฑุฑ ุงููุชุงุฆุฌ ุฅูู ุทุฑููุฉ `metric.compute()`:

```py
import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Remove ignored index (special tokens) and convert to labels
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }
```

ุงูุขู ุจุนุฏ ุฃู ุชู ุฐููุ ูุญู ุนูู ูุดู ุชุนุฑูู `Trainer`. ูุญุชุงุฌ ููุท ุฅูู `model` ูุถุจุทู!

{:else}

ูุฐุง ูุฑุณู ุงููุซูุฑ ูู ุงููุนูููุงุช! ูุญุตู ุนูู ุงูุฏูุฉุ ูุงูุงุณุชุฏุนุงุกุ ูุฏุฑุฌุฉ F1 ููู ููุงู ูููุตูุ ููุฐูู ุจุดูู ุนุงู. ุงูุขู ุฏุนูุง ูุฑู ูุง ูุญุฏุซ ุฅุฐุง ุญุงูููุง ุงุณุชุฎุฏุงู ุชูุจุคุงุช ูููุฐุฌูุง ุงููุนูู ูุญุณุงุจ ุจุนุถ ุงูุฏุฑุฌุงุช ุงูุญููููุฉ.

ูุง ูุญุจ TensorFlow ุฏูุฌ ุชูุจุคุงุชูุง ูุนูุงุ ูุฃููุง ุฐุงุช ุฃุทูุงู ูุชุณูุณูุฉ ูุชุบูุฑุฉ. ูุฐุง ูุนูู ุฃููุง ูุง ูุณุชุทูุน ุงุณุชุฎุฏุงู `model.predict()` - ูููู ูุฐุง ูู ูููููุง. ุณูุญุตู ุนูู ุจุนุถ ุงูุชูุจุคุงุช ุฏูุนุฉ ูุงุญุฏุฉ ููููู ุจุฏูุฌูุง ูู ูุงุฆูุฉ ุทูููุฉ ูุจูุฑุฉ ุฃุซูุงุก ุงูุชูููุ ูุฅุณูุงุท ุฑููุฒ `-100` ุงูุชู ุชุดูุฑ ุฅูู ุงูุชุนุชูู/ุงูุชุนุจุฆุฉุ ุซู ุญุณุงุจ ุงูููุงููุณ ุนูู ุงููุงุฆูุฉ ูู ุงูููุงูุฉ:

```py
import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict_on_batch(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])
```


```python out
{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}
```

ููู ูุงู ุฃุฏุงุก ูููุฐุฌูุ ููุงุฑูุฉ ุจูููุฐุฌูุงุ ุฅุฐุง ุญุตูุช ุนูู ุฃุฑูุงู ููุงุซูุฉุ ููุฏ ูุฌุญ ุชุฏุฑูุจู!

{/if}

{#if fw === 'pt'}

### ุชุนุฑูู ุงููููุฐุฌ[[defining-the-model]]

ูุธุฑูุง ูุฃููุง ูุนูู ุนูู ูุดููุฉ ุชุตููู ุงูุฑููุฒุ ูุณูุณุชุฎุฏู ูุฆุฉ `AutoModelForTokenClassification`. ุงูุดูุก ุงูุฑุฆูุณู ุงูุฐู ูุฌุจ ุชุฐูุฑู ุนูุฏ ุชุนุฑูู ูุฐุง ุงููููุฐุฌ ูู ุชูุฑูุฑ ุจุนุถ ุงููุนูููุงุช ุญูู ุนุฏุฏ ุงูุนูุงูุงุช ุงูุชู ูุฏููุง. ุฃุณูู ุทุฑููุฉ ููููุงู ุจุฐูู ูู ุชูุฑูุฑ ูุฐุง ุงูุนุฏุฏ ุจุงุณุชุฎุฏุงู ุญุฌุฉ `num_labels`ุ ูููู ุฅุฐุง ุฃุฑุฏูุง ุฃุฏุงุฉ ุงุณุชุฏูุงู ูุทููุฉ ุชุนูู ูุซู ุงูุชู ุฑุฃููุงูุง ูู ุจุฏุงูุฉ ูุฐุง ุงููุณูุ ููู ุงูุฃูุถู ุชุนููู ุงููุฑุงุณูุงุช ุงูุตุญูุญุฉ ููุนูุงูุงุช ุจุฏูุงู ูู ุฐูู.

ูุฌุจ ุชุนููููุง ุจูุงุณุทุฉ ูุงููุณููุ `id2label` ู`label2id`ุ ุงููุฐูู ูุญุชููุงู ุนูู ุงูุฎุฑุงุฆุท ูู ุงููุนุฑู ุฅูู ุงูุนูุงูุฉ ูุงูุนูุณ:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

ุงูุขู ูููููุง ููุท ุชูุฑูุฑูุง ุฅูู ุทุฑููุฉ `AutoModelForTokenClassification.from_pretrained()`ุ ูุณูุชู ุชุนููููุง ูู ุชูููู ุงููููุฐุฌ ุซู ุญูุธูุง ูุชุญููููุง ุจุดูู ุตุญูุญ ุฅูู ุงููุฑูุฒ:

```py
from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```
```
ูุซููุง ูููุง ุจุชุนุฑูู `AutoModelForSequenceClassification` ูู [ุงููุตู 3](/course/chapter3)ุ ูุฅู ุฅูุดุงุก ุงููููุฐุฌ ูุตุฏุฑ ุชุญุฐูุฑูุง ุจุฃู ุจุนุถ ุงูุฃูุฒุงู ูู ุชุณุชุฎุฏู (ุชูู ุงูุฎุงุตุฉ ุจุฑุฃุณ ุงูุชููุฆุฉ ุงููุณุจูุฉ) ูุฃู ุจุนุถ ุงูุฃูุฒุงู ุงูุฃุฎุฑู ุชู ุชููุฆุชูุง ุนุดูุงุฆููุง (ุชูู ุงูุฎุงุตุฉ ุจุฑุฃุณ ุงูุชุตููู ุงูุฑูุฒู ุงูุฌุฏูุฏ)ุ ูุฃูู ูุฌุจ ุชุฏุฑูุจ ูุฐุง ุงููููุฐุฌ. ุณูููู ุจุฐูู ุจุนุฏ ููููุ ูููู ุฏุนููุง ุฃููุงู ูุชุฃูุฏ ูู ุฃู ูููุฐุฌูุง ูุฏูู ุงูุนุฏุฏ ุงูุตุญูุญ ูู ุงูุชุตูููุงุช:

```python
model.config.num_labels
```

```python out
9
```

<Tip warning={true}>

โ๏ธ ุฅุฐุง ูุงู ูุฏูู ูููุฐุฌ ุจุนุฏุฏ ุบูุฑ ุตุญูุญ ูู ุงูุชุตูููุงุชุ ูุณุชุญุตู ุนูู ุฎุทุฃ ุบุงูุถ ุนูุฏ ุงุณุชุฏุนุงุก ุทุฑููุฉ `Trainer.train()` ูุงุญููุง (ุดูุก ูุซู "ุฎุทุฃ CUDA: ุชู ุชุดุบูู ุงูุชุฃููุฏ ูู ุฌุงูุจ ุงูุฌูุงุฒ"). ูุฐุง ูู ุงูุณุจุจ ุงูุฃูู ููุฃุฎุทุงุก ุงูุชู ุฃุจูุบ ุนููุง ุงููุณุชุฎุฏููู ููุซู ูุฐู ุงูุฃุฎุทุงุกุ ูุฐุง ุชุฃูุฏ ูู ุฅุฌุฑุงุก ูุฐุง ุงููุญุต ููุชุฃูุฏ ูู ุฃู ูุฏูู ุงูุนุฏุฏ ุงููุชููุน ูู ุงูุชุตูููุงุช.

</Tip>

### ุถุจุท ุฏููู ูููููุฐุฌ[[fine-tuning-the-model]]

ูุญู ุงูุขู ูุณุชุนุฏูู ูุชุฏุฑูุจ ูููุฐุฌูุง! ูุญุชุงุฌ ููุท ุฅูู ุงูููุงู ุจุขุฎุฑ ุฎุทูุชูู ูุจู ุฃู ูุญุฏุฏ `Trainer` ุงูุฎุงุต ุจูุง: ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญุฏูุฏ ุญุฌุฌ ุงูุชุฏุฑูุจ. ุฅุฐุง ููุช ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ูููุงู ูุธููุฉ ููุงุฆูุฉ ููุณุงุนุฏุชู ูู ุฐูู:

```python
from huggingface_hub import notebook_login

notebook_login()
```

ุณูุธูุฑ ูุฐุง ูุฑุจุนูุง ููููู ููู ุฅุฏุฎุงู ุจูุงูุงุช ุงุนุชูุงุฏ ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face.

ุฅุฐุง ูู ุชูู ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ููุง ุนููู ุณูู ูุชุงุจุฉ ุงูุณุทุฑ ุงูุชุงูู ูู ุทุฑููุชู:

```bash
huggingface-cli login
```

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฐููุ ูููููุง ุชุญุฏูุฏ `TrainingArguments` ุงูุฎุงุตุฉ ุจูุง:

```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)
```

ููุฏ ุฑุฃูุช ูุนุธููุง ูู ูุจู: ูุญุฏุฏ ุจุนุถ ุงููุนุงููุงุช (ูุซู ูุนุฏู ุงูุชุนููุ ูุนุฏุฏ ุงูุนุตูุฑ ุงูุชู ูุฌุจ ุงูุชุฏุฑูุจ ุนูููุงุ ูุฏุฑุฌุฉ ุงูุชูุงุดู)ุ ููุญุฏุฏ `push_to_hub=True` ููุฅุดุงุฑุฉ ุฅูู ุฃููุง ูุฑูุฏ ุญูุธ ุงููููุฐุฌ ูุชููููู ูู ููุงูุฉ ูู ุนุตุฑุ ูุฃููุง ูุฑูุฏ ุชุญููู ูุชุงุฆุฌูุง ุฅูู Model Hub. ูุงุญุธ ุฃูู ููููู ุชุญุฏูุฏ ุงุณู ุงููุณุชูุฏุน ุงูุฐู ุชุฑูุฏ ุงูุชุญููู ุฅููู ุจุญุฌุฉ `hub_model_id` (ุนูู ูุฌู ุงูุฎุตูุตุ ุณูุชุนูู ุนููู ุงุณุชุฎุฏุงู ูุฐู ุงูุญุฌุฉ ููุชุญููู ุฅูู ููุธูุฉ). ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏูุง ูููุง ุจุชุญููู ุงููููุฐุฌ ุฅูู ููุธูุฉ [`huggingface-course`](https://huggingface.co/huggingface-course)ุ ุฃุถููุง `hub_model_id="huggingface-course/bert-finetuned-ner"` ุฅูู `TrainingArguments`. ุจุดูู ุงูุชุฑุงุถูุ ุณูุชู ุงุณุชุฎุฏุงู ุงููุณุชูุฏุน ุงูููุฌูุฏ ูู ูุณุงุญุฉ ุงูุงุณู ุงูุฎุงุตุฉ ุจู ููุชู ุชุณููุชู ููููุง ูุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ููุช ุจุชุนููููุ ูุฐุง ูู ุญุงูุชูุง ุณูููู `"sgugger/bert-finetuned-ner"`.

<Tip>

๐ก ุฅุฐุง ูุงู ุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ุชุณุชุฎุฏูู ููุฌูุฏูุง ุจุงููุนูุ ููุฌุจ ุฃู ูููู ูุณุชูุณุฎูุง ูุญูููุง ูููุณุชูุฏุน ุงูุฐู ุชุฑูุฏ ุงูุชุญููู ุฅููู. ุฅุฐุง ูู ููู ูุฐููุ ูุณุชุญุตู ุนูู ุฎุทุฃ ุนูุฏ ุชุญุฏูุฏ `Trainer` ุงูุฎุงุต ุจู ูุณูุชุนูู ุนููู ุชุนููู ุงุณู ุฌุฏูุฏ.

</Tip>

ุฃุฎูุฑูุงุ ูููู ููุท ุจุชูุฑูุฑ ูู ุดูุก ุฅูู `Trainer` ูุฅุทูุงู ุงูุชุฏุฑูุจ:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()
```

ูุงุญุธ ุฃูู ุฃุซูุงุก ุญุฏูุซ ุงูุชุฏุฑูุจุ ูู ูู ูุฑุฉ ูุชู ุญูุธ ุงููููุฐุฌ (ููุงุ ูู ุนุตุฑ) ูุชู ุชุญูููู ุฅูู Hub ูู ุงูุฎูููุฉ. ุจูุฐู ุงูุทุฑููุฉุ ุณุชุชููู ูู ุงุณุชุฆูุงู ุชุฏุฑูุจู ุนูู ุขูุฉ ุฃุฎุฑู ุฅุฐุง ูุฒู ุงูุฃูุฑ.

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ูุณุชุฎุฏู ุทุฑููุฉ `push_to_hub()` ููุชุฃูุฏ ูู ุชุญููู ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู ุงููููุฐุฌ:

```py
trainer.push_to_hub(commit_message="Training complete")
```

ุชุนูุฏ ูุฐู ุงูุฃูุงูุฑ ุนููุงู URL ููุงูุชุฒุงู ุงูุฐู ูุงู ุจู ููุชูุ ุฅุฐุง ููุช ุชุฑูุฏ ูุญุตู:

```python out
'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'
```

ูููู `Trainer` ุฃูุถูุง ุจูุณูุฏุฉ ุจุทุงูุฉ ูููุฐุฌ ุจุฌููุน ูุชุงุฆุฌ ุงูุชูููู ูุชุญููููุง. ูู ูุฐู ุงููุฑุญูุฉุ ููููู ุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุงูุงุณุชุฏูุงู ุนูู Model Hub ูุงุฎุชุจุงุฑ ูููุฐุฌู ููุดุงุฑูุชู ูุน ุฃุตุฏูุงุฆู. ููุฏ ููุช ุจุถุจุท ุฏููู ูุงุฌุญ ููููุฐุฌ ุนูู ูููุฉ ุชุตููู ุงูุฑููุฒ - ุชูุงูููุง!

ุฅุฐุง ููุช ุชุฑูุฏ ุงูุบูุต ุจุดูู ุฃุนูู ููููุงู ูู ุญููุฉ ุงูุชุฏุฑูุจุ ูุณูุฑููู ุงูุขู ููููุฉ ุงูููุงู ุจููุณ ุงูุดูุก ุจุงุณุชุฎุฏุงู ๐ค Accelerate.

## ุญููุฉ ุชุฏุฑูุจ ูุฎุตุตุฉ[[a-custom-training-loop]]

ุฏุนููุง ุงูุขู ูููู ูุธุฑุฉ ุนูู ุญููุฉ ุงูุชุฏุฑูุจ ุงููุงููุฉุ ุญุชู ุชุชููู ูู ุชุฎุตูุต ุงูุฃุฌุฒุงุก ุงูุชู ุชุญุชุงุฌูุง. ุณุชุจุฏู ุฅูู ุญุฏ ูุจูุฑ ูุซู ูุง ูุนููุงู ูู [ุงููุตู 3](/course/chapter3/4)ุ ูุน ุจุนุถ ุงูุชุบููุฑุงุช ููุชูููู.

### ุฅุนุฏุงุฏ ูู ุดูุก ููุชุฏุฑูุจ[[preparing-everything-for-training]]

ุฃููุงู ูุญุชุงุฌ ุฅูู ุจูุงุก `DataLoader`s ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุง. ุณูุนูุฏ ุงุณุชุฎุฏุงู `data_collator` ูู `collate_fn` ููุฎูุท ูุฌููุนุฉ ุงูุชุฏุฑูุจุ ูููู ููุณ ูุฌููุนุฉ ุงูุชุญูู:

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)
```

ุจุนุฏ ุฐููุ ูุนูุฏ ุฅูุดุงุก ูููุฐุฌูุงุ ููุชุฃูุฏ ูู ุฃููุง ูุง ููุงุตู ุงูุถุจุท ุงูุฏููู ูู ูุจู ูููู ูุจุฏุฃ ูู ูููุฐุฌ BERT ุงููุชููุฆ ูุณุจููุง ูุฑุฉ ุฃุฎุฑู:

```py
model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

ุจุนุฏ ุฐููุ ุณูุญุชุงุฌ ุฅูู ูุญุณู. ุณูุณุชุฎุฏู `AdamW` ุงูููุงุณูููุ ูุงูุฐู ูุดุจู `Adam`ุ ูููู ูุน ุฅุตูุงุญ ูู ุทุฑููุฉ ุชุทุจูู ุฏุฑุฌุฉ ุงูุชูุงุดู:

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

ุจูุฌุฑุฏ ุญุตูููุง ุนูู ูู ูุฐู ุงูุฃุดูุงุกุ ูููููุง ุฅุฑุณุงููุง ุฅูู ุทุฑููุฉ `accelerator.prepare()`:

```py
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

<Tip>

๐จ ุฅุฐุง ููุช ุชุชุฏุฑุจ ุนูู TPUุ ูุณุชุญุชุงุฌ ุฅูู ููู ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุจุฏุกูุง ูู ุงูุฎููุฉ ุฃุนูุงู ุฅูู ูุธููุฉ ุชุฏุฑูุจ ูุฎุตุตุฉ. ุฑุงุฌุน [ุงููุตู 3](/course/chapter3) ููุฒูุฏ ูู ุงูุชูุงุตูู.

</Tip>

ุงูุขู ุจุนุฏ ุฃู ุฃุฑุณููุง `train_dataloader` ุงูุฎุงุต ุจูุง ุฅูู `accelerator.prepare()`ุ ูููููุง ุงุณุชุฎุฏุงู ุทููู ูุญุณุงุจ ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ. ุชุฐูุฑ ุฃูู ูุฌุจ ุนูููุง ุฏุงุฆููุง ุงูููุงู ุจุฐูู ุจุนุฏ ุฅุนุฏุงุฏ ูุญูู ุงูุจูุงูุงุชุ ุญูุซ ุณุชุบูุฑ ูุฐู ุงูุทุฑููุฉ ุทููู. ูุณุชุฎุฏู ุฌุฏูููุง ุฎุทููุง ููุงุณููููุง ูู ูุนุฏู ุงูุชุนูู ุฅูู 0:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

ุฃุฎูุฑูุงุ ูุฏูุน ูููุฐุฌูุง ุฅูู Hubุ ุณูุญุชุงุฌ ุฅูู ุฅูุดุงุก ูุงุฆู `Repository` ูู ูุฌูุฏ ุนูู. ูู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Faceุ ุฅุฐุง ูู ุชูู ูุณุฌูุงู ุงูุฏุฎูู ุจุงููุนู. ุณูุญุฏุฏ ุงุณู ุงููุณุชูุฏุน ูู ูุนุฑู ุงููููุฐุฌ ุงูุฐู ูุฑูุฏ ุฅุนุทุงุกู ููููุฐุฌูุง (ูุง ุชุชุฑุฏุฏ ูู ุงุณุชุจุฏุงู `repo_name` ุจุฎูุงุฑู ุงูุฎุงุตุ ูู ูุง ูุญุชุงุฌู ูู ุงุญุชูุงุก ุงุณู ุงููุณุชุฎุฏู ุงูุฎุงุต ุจูุ ููู ูุง ุชููู ุจู ูุธููุฉ `get_full_repo_name()`):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-ner-accelerate'
```

ุจุนุฏ ุฐููุ ูููููุง ุงุณุชูุณุงุฎ ูุฐุง ุงููุณุชูุฏุน ูู ูุฌูุฏ ูุญูู. ุฅุฐุง ูุงู ููุฌูุฏูุง ุจุงููุนูุ ููุฌุจ ุฃู ูููู ูุฐุง ุงููุฌูุฏ ุงููุญูู ูุณุชูุณุฎูุง ูุญูููุง ูููุณุชูุฏุน ุงูุฐู ูุนูู ูุนู:

```py
output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
ูููููุง ุงูุขู ุฑูุน ุฃู ุดูุก ูุญูุธู ูู `output_dir` ุนู ุทุฑูู ุงุณุชุฏุนุงุก ุทุฑููุฉ `repo.push_to_hub()` . ูุฐุง ุณูุณุงุนุฏูุง ูู ุฑูุน ุงูููุงุฐุฌ ุงููุณูุทุฉ ูู ููุงูุฉ ูู ุญูุจุฉ.

### ุญููุฉ ุงูุชุฏุฑูุจ[[training-loop]]

ูุญู ุงูุขู ูุณุชุนุฏูู ููุชุงุจุฉ ุญููุฉ ุงูุชุฏุฑูุจ ุงููุงููุฉ. ูุชุจุณูุท ุงูุฌุฒุก ุงูุชูููููุ ูุญุฏุฏ ูุฐู ุงูุฏุงูุฉ `postprocess()` ุงูุชู ุชุฃุฎุฐ ุงูุชููุนุงุช ูุงูุนูุงูุงุช ูุชุญูููุง ุฅูู ููุงุฆู ูู ุงูุณูุงุณู ุงููุตูุฉุ ูุซู ูุง ูุชููุนู ูุงุฆู `metric` :

```py
def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # ุฅุฒุงูุฉ ุงูููุฑุณ ุงููููู (ุงูุฑููุฒ ุงูุฎุงุตุฉ) ูุชุญููููุง ุฅูู ุนูุงูุงุช
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions
```

ุซู ูููููุง ูุชุงุจุฉ ุญููุฉ ุงูุชุฏุฑูุจ. ุจุนุฏ ุชุญุฏูุฏ ุดุฑูุท ุงูุชูุฏู ููุชุงุจุนุฉ ููููุฉ ุงูุชุฏุฑูุจุ ุชุญุชูู ุงูุญููุฉ ุนูู ุซูุงุซุฉ ุฃุฌุฒุงุก:

- ุงูุชุฏุฑูุจ ูู ุญุฏ ุฐุงุชูุ ููู ุงูุชูุฑุงุฑ ุงูููุงุณููู ุนูู `train_dataloader`ุ ูุงููุฑูุฑ ุงูุฃูุงูู ุนุจุฑ ุงููููุฐุฌุ ุซู ุงููุฑูุฑ ุงูุฎููู ูุฎุทูุฉ ุงููุญุณู.
- ุงูุชููููุ ุญูุซ ููุฌุฏ ุดูุก ุฌุฏูุฏ ุจุนุฏ ุงูุญุตูู ุนูู ูุฎุฑุฌุงุช ูููุฐุฌูุง ุนูู ุฏูุนุฉ: ูุธุฑูุง ูุฃู ุนูููุชูู ูุฏ ูุงูุชุง ุจููุก ุงููุฏุฎูุงุช ูุงูุนูุงูุงุช ุฅูู ุฃุดูุงู ูุฎุชููุฉุ ูุญุชุงุฌ ุฅูู ุงุณุชุฎุฏุงู `accelerator.pad_across_processes()` ูุฌุนู ุงูุชููุนุงุช ูุงูุนูุงูุงุช ุจููุณ ุงูุดูู ูุจู ุงุณุชุฏุนุงุก ุทุฑููุฉ `gather()` . ุฅุฐุง ูู ููุนู ุฐููุ ูุฅู ุงูุชูููู ุฅูุง ุฃู ูุฎุทุฆ ุฃู ูุนูู ุฅูู ุงูุฃุจุฏ. ุซู ูุฑุณู ุงููุชุงุฆุฌ ุฅูู `metric.add_batch()` ููุณุชุฏุนู `metric.compute()` ุจูุฌุฑุฏ ุงูุชูุงุก ุญููุฉ ุงูุชูููู.
- ุงูุญูุธ ูุงูุฑูุนุ ุญูุซ ูููู ุฃููุงู ุจุญูุธ ุงููููุฐุฌ ูุงููุญูู ุงููุบููุ ุซู ูุณุชุฏุนู `repo.push_to_hub()`. ูุงุญุธ ุฃููุง ูุณุชุฎุฏู ุงูุญุฌุฉ `blocking=False` ูุฅุฎุจุงุฑ ููุชุจุฉ ๐ค Hub ุจุงูุฏูุน ูู ุนูููุฉ ุบูุฑ ูุชุฒุงููุฉ. ุจูุฐู ุงูุทุฑููุฉุ ูุณุชูุฑ ุงูุชุฏุฑูุจ ุจุดูู ุทุจูุนู ููุชู ุชูููุฐ ูุฐุง ุงูุฃูุฑ (ุงูุทููู) ูู ุงูุฎูููุฉ.

ููุง ุงูููุฏ ุงููุงูู ูุญููุฉ ุงูุชุฏุฑูุจ:

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # ุถุฑูุฑู ูููุก ุงูุชููุนุงุช ูุงูุนูุงูุงุช ูุชุฌููุนูุง
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

ูู ุญุงูุฉ ูุงูุช ูุฐู ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุฑู ูููุง ูููุฐุฌูุง ูุญููุธูุง ูุน ๐ค Accelerateุ ุฏุนูุง ูุฃุฎุฐ ูุญุธุฉ ููุญุต ุฃุณุทุฑ ุงูููุฏ ุงูุซูุงุซุฉ ุงูุชู ุชุฐูุจ ูุนูุง:

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```

ุงูุณุทุฑ ุงูุฃูู ูุงุถุญ ุจุฐุงุชู: ููู ูุฎุจุฑ ุฌููุน ุงูุนูููุงุช ุจุงูุงูุชุธุงุฑ ุญุชู ูุตู ุงูุฌููุน ุฅูู ุชูู ุงููุฑุญูุฉ ูุจู ุงูุงุณุชูุฑุงุฑ. ูุฐุง ููุชุฃูุฏ ูู ุฃู ูุฏููุง ููุณ ุงููููุฐุฌ ูู ูู ุนูููุฉ ูุจู ุงูุญูุธ. ุซู ูุฃุฎุฐ `unwrapped_model`ุ ููู ุงููููุฐุฌ ุงูุฃุณุงุณู ุงูุฐู ุญุฏุฏูุงู. ุชุบูุฑ ุทุฑููุฉ `accelerator.prepare()` ุงููููุฐุฌ ููุนูู ูู ุงูุชุฏุฑูุจ ุงูููุฒุนุ ูุฐูู ูู ูููู ูุฏูู ุทุฑููุฉ `save_pretrained()` ุจุนุฏ ุงูุขูุ ุทุฑููุฉ `accelerator.unwrap_model()` ุชูุบู ุชูู ุงูุฎุทูุฉ. ุฃุฎูุฑูุงุ ูุณุชุฏุนู `save_pretrained()` ููู ูุฎุจุฑ ุชูู ุงูุทุฑููุฉ ุจุงุณุชุฎุฏุงู `accelerator.save()` ุจุฏูุงู ูู `torch.save()`.

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฐููุ ูุฌุจ ุฃู ูููู ูุฏูู ูููุฐุฌ ููุชุฌ ูุชุงุฆุฌ ูุดุงุจูุฉ ุฌุฏูุง ููุฐู ุชู ุชุฏุฑูุจู ูุน `Trainer`. ููููู ุงูุชุญูู ูู ุงููููุฐุฌ ุงูุฐู ูููุง ุจุชุฏุฑูุจู ุจุงุณุชุฎุฏุงู ูุฐุง ุงูููุฏ ูู [*huggingface-course/bert-finetuned-ner-accelerate*](https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate). ูุฅุฐุง ููุช ุชุฑุบุจ ูู ุงุฎุชุจุงุฑ ุฃู ุชุนุฏููุงุช ุนูู ุญููุฉ ุงูุชุฏุฑูุจุ ููููู ุชูููุฐูุง ูุจุงุดุฑุฉ ุนู ุทุฑูู ุชุญุฑูุฑ ุงูููุฏ ุงูููุถุญ ุฃุนูุงู!

{/if}

## ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุฏููู[[using-the-fine-tuned-model]]

ููุฏ ุฃุธูุฑูุง ูู ุจุงููุนู ููู ููููู ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุฐู ูููุง ุจุถุจุทู ุงูุฏููู ุนูู Model Hub ูุน ุฃุฏุงุฉ ุงูุชุฎููู. ูุงุณุชุฎุฏุงูู ูุญูููุง ูู `pipeline`ุ ุนููู ููุท ุชุญุฏูุฏ ูุนุฑู ุงููููุฐุฌ ุงูุตุญูุญ:

```py
from transformers import pipeline

# ุงุณุชุจุฏู ูุฐุง ุจูุนุฑู ููุทุฉ ุงูุชูุชูุด ุงูุฎุงุตุฉ ุจู
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
```

ุฑุงุฆุน! ูุนูู ูููุฐุฌูุง ุจููุณ ุฌูุฏุฉ ุงููููุฐุฌ ุงูุงูุชุฑุงุถู ููุฐุง ุงูุฃูุจูุจ!