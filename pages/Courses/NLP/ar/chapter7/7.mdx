<FrameworkSwitchCourse {fw} />

# ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ [[ุงูุฅุฌุงุจุฉ-ุนูู-ุงูุฃุณุฆูุฉ]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_tf.ipynb"},
]} />

{/if}

ุญุงู ุงูููุช ููุชุทุฑู ุฅูู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ! ุชุฃุชู ูุฐู ุงููููุฉ ุจุฃุดูุงู ูุฎุชููุฉุ ููู ูุง ุณูุฑูุฒ ุนููู ูู ูุฐุง ุงููุณู ูู ูุง ูุณูู ุจุงูุฅุฌุงุจุฉ ุงูุงุณุชุฎูุงุตูุฉ ุนูู ุงูุฃุณุฆูุฉ. ูุชุถูู ุฐูู ุทุฑุญ ุฃุณุฆูุฉ ุญูู ูุซููุฉ ูุง ูุชุญุฏูุฏ ุงูุฅุฌุงุจุงุช ูู _ููุชุทูุงุช ูุตูุฉ_ ูู ุงููุซููุฉ ููุณูุง.

<Youtube id="ajPx5LwJD-I"/>

ุณูููู ุจุถุจุท ูููุฐุฌ BERT ุนูู [ูุฌููุนุฉ ุจูุงูุงุช SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)ุ ูุงูุชู ุชุชููู ูู ุฃุณุฆูุฉ ุทุฑุญูุง ุนูุงู ูุณุชูููู ุนูู ูุฌููุนุฉ ูู ููุงูุงุช ููููุจูุฏูุง. ุณูุนุทููุง ูุฐุง ูููุฐุฌุงู ูุงุฏุฑุงู ุนูู ุญุณุงุจ ุชูุจุคุงุช ูุซู ูุฐุง:

<iframe src="https://course-demos-bert-finetuned-squad.hf.space" frameBorder="0" height="450" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

ูุฐุง ูู ุงููุงูุน ูุนุฑุถ ุงููููุฐุฌ ุงูุฐู ุชู ุชุฏุฑูุจู ูุชุญูููู ุฅูู ุงููุฑูุฒ ุจุงุณุชุฎุฏุงู ุงูููุฏ ุงูููุถุญ ูู ูุฐุง ุงููุณู. ููููู ุงูุนุซูุฑ ุนููู ูุงูุชุญูู ูู ุงูุชูุจุคุงุช [ููุง](https://huggingface.co/huggingface-course/bert-finetuned-squad?context=%F0%9F%A4%97+Transformers+is+backed+by+the+three+most+popular+deep+learning+libraries+%E2%80%94+Jax%2C+PyTorch+and+TensorFlow+%E2%80%94+with+a+seamless+integration+between+them.+It%27s+straightforward+to+train+your+models+with+one+before+loading+them+for+inference+with+the+other.&question=Which+deep+learning+libraries+back+%F0%9F%A4%97+Transformers%3F).

<Tip>

๐ก ุชููู ุงูููุงุฐุฌ ุงูุชู ุชููู ุจุงูุชุฑููุฒ ููุท ูุซู BERT ุฅูู ุฃู ุชููู ุฑุงุฆุนุฉ ูู ุงุณุชุฎุฑุงุฌ ุงูุฅุฌุงุจุงุช ุนูู ุงูุฃุณุฆูุฉ ุงูููุงุฆุนูุฉ ูุซู "ูู ุงุฎุชุฑุน ุจููุฉ ุงููุญููุ" ูููููุง ูุง ุชุคุฏู ุฌูุฏุงู ุนูุฏ ุทุฑุญ ุฃุณุฆูุฉ ููุชูุญุฉ ูุซู "ููุงุฐุง ุงูุณูุงุก ุฒุฑูุงุกุ" ูู ูุฐู ุงูุญุงูุงุช ุงูุฃูุซุฑ ุชุญุฏูุงูุ ูุชู ุงุณุชุฎุฏุงู ููุงุฐุฌ ุงูุชุฑููุฒ-ูู ุงูุชุฑููุฒ ูุซู T5 ู BART ุนุงุฏุฉู ูุชุฑููุจ ุงููุนูููุงุช ุจุทุฑููุฉ ูุดุงุจูุฉ ุฌุฏุงู [ูุชูุฎูุต ุงููุต](/course/chapter7/5). ุฅุฐุง ููุช ููุชูุงู ุจูุฐุง ุงูููุน ูู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุชูููุฏูุฉุ ููุตู ุจุงูุงุทูุงุน ุนูู [ุนุฑุถูุง ุงูุชูุถูุญู](https://yjernite.github.io/lfqa.html) ุงููุงุฆู ุนูู [ูุฌููุนุฉ ุจูุงูุงุช ELI5](https://huggingface.co/datasets/eli5).

</Tip>

## ุฅุนุฏุงุฏ ุงูุจูุงูุงุช [[ุฅุนุฏุงุฏ-ุงูุจูุงูุงุช]]

ุชุนุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุชู ูุชู ุงุณุชุฎุฏุงููุง ุฃูุซุฑ ูู ุบูุฑูุง ููุนูุงุฑ ุฃูุงุฏููู ููุฅุฌุงุจุฉ ุงูุงุณุชุฎูุงุตูุฉ ุนูู ุงูุฃุณุฆูุฉ ูู [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)ุ ูุฐุง ููู ุงูุชู ุณูุณุชุฎุฏููุง ููุง. ููุงู ุฃูุถุงู ูุนูุงุฑ ุฃุตุนุจ [SQuAD v2](https://huggingface.co/datasets/squad_v2)ุ ูุงูุฐู ูุชุถูู ุฃุณุฆูุฉ ูุง ุชุญุชูู ุนูู ุฅุฌุงุจุฉ. ุทุงููุง ุฃู ูุฌููุนุฉ ุจูุงูุงุชู ุงูุฎุงุตุฉ ุชุญุชูู ุนูู ุนููุฏ ููุณูุงูุงุชุ ูุนููุฏ ููุฃุณุฆูุฉุ ูุนููุฏ ููุฅุฌุงุจุงุชุ ููุฌุจ ุฃู ุชููู ูุงุฏุฑุงู ุนูู ุชูููู ุงูุฎุทูุงุช ุฃุฏูุงู.

### ูุฌููุนุฉ ุจูุงูุงุช SQuAD [[ูุฌููุนุฉ-ุจูุงูุงุช-squad]]

ููุง ูู ูุนุชุงุฏุ ูููููุง ุชูุฒูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชุฎุฒูููุง ูุคูุชุงู ูู ุฎุทูุฉ ูุงุญุฏุฉ ุจูุถู `load_dataset()`:

```py
from datasets import load_dataset

raw_datasets = load_dataset("squad")
```

ุจุนุฏ ุฐููุ ูููููุง ุฅููุงุก ูุธุฑุฉ ุนูู ูุฐุง ุงููุงุฆู ููุนุฑูุฉ ุงููุฒูุฏ ุนู ูุฌููุนุฉ ุจูุงูุงุช SQuAD:

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 87599
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 10570
    })
})
```

ูุจุฏู ุฃู ูุฏููุง ูู ูุง ูุญุชุงุฌู ูุน ุญููู `context` ู`question` ู`answers`ุ ูุฐุง ุฏุนูุง ูุทุจุน ุชูู ุงูุฎุงุตุฉ ุจุงูุนูุตุฑ ุงูุฃูู ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุง:

```py
print("Context: ", raw_datasets["train"][0]["context"])
print("Question: ", raw_datasets["train"][0]["question"])
print("Answer: ", raw_datasets["train"][0]["answers"])
```

```python out
Context: 'Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'
Question: 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'
Answer: {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}
```

ุญููุง `context` ู`question` ุณููุงู ุฌุฏุงู ููุงุณุชุฎุฏุงู. ุญูู `answers` ุฃูุซุฑ ุชุนููุฏุงู ูุฃูู ูุญุชูู ุนูู ูุงููุณ ูุน ุญููููู ููุงููุง ููุงุฆู. ูุฐุง ูู ุงูุชูุณูู ุงูุฐู ูุชููุนู ูููุงุณ `squad` ุฃุซูุงุก ุงูุชููููุ ุฅุฐุง ููุช ุชุณุชุฎุฏู ุจูุงูุงุชู ุงูุฎุงุตุฉุ ููุง ุฏุงุนู ููููู ุจุดุฃู ูุถุน ุงูุฅุฌุงุจุงุช ูู ููุณ ุงูุชูุณูู. ุญูู `text` ูุงุถุญ ุฌุฏุงูุ ูุญูู `answer_start` ูุญุชูู ุนูู ููุฑุณ ุญุฑู ุงูุจุฏุงูุฉ ููู ุฅุฌุงุจุฉ ูู ุงูุณูุงู.

ุฎูุงู ุงูุชุฏุฑูุจุ ููุงู ุฅุฌุงุจุฉ ูุงุญุฏุฉ ููููุฉ ููุท. ูููููุง ุงูุชุญูู ูู ุฐูู ุจุงุณุชุฎุฏุงู ุทุฑููุฉ `Dataset.filter()`:

```py
raw_datasets["train"].filter(lambda x: len(x["answers"]["text"]) != 1)
```

```python out
Dataset({
    features: ['id', 'title', 'context', 'question', 'answers'],
    num_rows: 0
})
```

ููุน ุฐููุ ููุงู ุนุฏุฉ ุฅุฌุงุจุงุช ููููุฉ ููู ุนููุฉุ ูุฏ ุชููู ูุชุทุงุจูุฉ ุฃู ูุฎุชููุฉุ ุฃุซูุงุก ุงูุชูููู:

```py
print(raw_datasets["validation"][0]["answers"])
print(raw_datasets["validation"][2]["answers"])
```

```python out
{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}
{'text': ['Santa Clara, California', "Levi's Stadium", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."], 'answer_start': [403, 355, 355]}
```

ูู ูุชุนูู ูู ูุต ุงูุชูููู ูุฃูู ุณูููู ูููููุงู ุจูุงุณุทุฉ ูููุงุณ ๐ค Datasets ููุงุ ูููู ุงููุณุฎุฉ ุงููุฎุชุตุฑุฉ ูู ุฃู ุจุนุถ ุงูุฃุณุฆูุฉ ูุฏููุง ุนุฏุฉ ุฅุฌุงุจุงุช ููููุฉุ ููุฐุง ุงููุต ุณููุงุฑู ุฅุฌุงุจุฉ ูุชููุนุฉ ุจุฌููุน ุงูุฅุฌุงุจุงุช ุงูููุจููุฉ ููุฃุฎุฐ ุฃูุถู ูุชูุฌุฉ. ุฅุฐุง ุฃููููุง ูุธุฑุฉ ุนูู ุงูุนููุฉ ูู ุงูููุฑุณ 2ุ ุนูู ุณุจูู ุงููุซุงู:

```py
print(raw_datasets["validation"][2]["context"])
print(raw_datasets["validation"][2]["question"])
```

```python out
'ูุงู ุณูุจุฑ ุจูู 50 ูุจุงุฑุงุฉ ูุฑุฉ ูุฏู ุฃูุฑูููุฉ ูุชุญุฏูุฏ ุจุทู ุงูุฏูุฑู ุงููุทูู ููุฑุฉ ุงููุฏู ุงูุฃูุฑูููุฉ (NFL) ูููุณู 2015. ูุฒู ูุฑูู ุฏููุฑ ุจุฑููููุณ ุจุทู ุงููุคุชูุฑ ุงูุฃูุฑููู ููุฑุฉ ุงููุฏู (AFC) ูุฑูู ูุงุฑููููุง ุจุงูุซุฑุฒ ุจุทู ุงููุคุชูุฑ ุงููุทูู ููุฑุฉ ุงููุฏู (NFC) ุจูุชูุฌุฉ 24-10 ููุญูููุง ููุจูู ุงูุซุงูุซ ูู ุณูุจุฑ ุจูู. ุฃูููุช ุงููุจุงุฑุงุฉ ูู 7 ูุจุฑุงูุฑ 2016ุ ูู ููุนุจ ูููู ูู ููุทูุฉ ุฎููุฌ ุณุงู ูุฑุงูุณูุณูู ูู ุณุงูุชุง ููุงุฑุงุ ูุงููููุฑููุง. ูุจูุง ุฃู ูุฐู ูุงูุช ุงูุฐูุฑู ุงูุฎูุณูู ูุณูุจุฑ ุจููุ ููุฏ ุฑูุฒ ุงูุฏูุฑู ุนูู "ุงูุฐูุฑู ุงูุฐูุจูุฉ" ุจูุจุงุฏุฑุงุช ุฐุงุช ุทุงุจุน ุฐูุจูุ ููุฐูู ุชุนููู ูุคูุช ูุชูููุฏ ุชุณููุฉ ูู ูุจุงุฑุงุฉ ุณูุจุฑ ุจูู ุจุงูุฃุฑูุงู ุงูุฑููุงููุฉ (ูุงูุชู ูุงูุช ุณุชุนุฑู ุจุงุณู "ุณูุจุฑ ุจูู L")ุ ุจุญูุซ ูููู ููุดุนุงุฑ ุฃู ูุจุฑุฒ ุงูุฃุฑูุงู ุงูุนุฑุจูุฉ 50 ุจุดูู ุจุงุฑุฒ.'
'ุฃูู ุฃููู ุณูุจุฑ ุจูู 50ุ'
```

ูููููุง ุฃู ูุฑู ุฃู ุงูุฅุฌุงุจุฉ ูููู ุฃู ุชููู ูุงุญุฏุฉ ูู ุงูุงุญุชูุงูุงุช ุงูุซูุงุซุฉ ุงูุชู ุฑุฃููุงูุง ุณุงุจูุงู.

### ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ [[processing-the-training-data]]

<Youtube id="qgaM0weJHpA"/>

ุฏุนูุง ูุจุฏุฃ ุจูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ. ุงูุฌุฒุก ุงูุตุนุจ ุณูููู ูู ุชูููุฏ ุงูุนูุงูุงุช ููุฅุฌุงุจุฉ ุนูู ุงูุณุคุงูุ ูุงูุชู ุณุชููู ููุงุถุน ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ููุฑููุฒ ุงูููุงุจูุฉ ููุฅุฌุงุจุฉ ุฏุงุฎู ุงูุณูุงู.

ููู ุฏุนูุง ูุง ูุณุชุจู ุงูุฃุญุฏุงุซ. ุฃููุงูุ ูุญุชุงุฌ ุฅูู ุชุญููู ุงููุต ูู ุงูุฅุฏุฎุงู ุฅูู ูุนุฑูุงุช ูููู ูููููุฐุฌ ููููุงุ ุจุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุชุฌุฒุฆุฉ ุงููููุงุช:

```py
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

ููุง ุฐูุฑูุง ุณุงุจูุงูุ ุณูููู ุจุถุจุท ูููุฐุฌ BERTุ ูููู ููููู ุงุณุชุฎุฏุงู ุฃู ููุน ุขุฎุฑ ูู ุงูููุงุฐุฌ ุทุงููุง ุฃูู ูุญุชูู ุนูู ุฃุฏุงุฉ ุชุฌุฒุฆุฉ ูููุงุช ุณุฑูุนุฉ. ููููู ุงูุงุทูุงุน ุนูู ุฌููุน ุงูุจูู ุงููุนูุงุฑูุฉ ุงูุชู ุชุฃุชู ูุน ูุณุฎุฉ ุณุฑูุนุฉ ูู [ูุฐุง ุงูุฌุฏูู ุงููุจูุฑ](https://huggingface.co/transformers/#supported-frameworks)ุ ูููุชุฃูุฏ ูู ุฃู ูุงุฆู `tokenizer` ุงูุฐู ุชุณุชุฎุฏูู ูุฏุนูู ุจุงููุนู ูู ูุจู ๐ค Tokenizers ููููู ุงููุธุฑ ุฅูู ุณูุฉ `is_fast`:

```py
tokenizer.is_fast
```

```python out
True
```

ูููููุง ุชูุฑูุฑ ุงูุณุคุงู ูุงูุณูุงู ูุนุงู ุฅูู ุฃุฏุงุฉ ุชุฌุฒุฆุฉ ุงููููุงุชุ ูุณุชููู ุจุฅุฏุฑุงุฌ ุงูุฑููุฒ ุงูุฎุงุตุฉ ุจุดูู ุตุญูุญ ูุชุดููู ุฌููุฉ ูุซู ูุฐู:

```
[CLS] ุงูุณุคุงู [SEP] ุงูุณูุงู [SEP]
```

ุฏุนูุง ูุชุฃูุฏ ูู ุฐูู:

```py
context = raw_datasets["train"][0]["context"]
question = raw_datasets["train"][0]["question"]

inputs = tokenizer(question, context)
tokenizer.decode(inputs["input_ids"])
```

```python out
'[CLS] ุฅูู ูู ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูู ุนุงู 1858 ูู ููุฑุฏุ ูุฑูุณุงุ [SEP] ูู ุงููุงุญูุฉ ุงููุนูุงุฑูุฉุ '
'ุชุชููุฒ ุงููุฏุฑุณุฉ ุจุทุงุจุน ูุงุซููููู. ูู ุฃุนูู ูุจุฉ ุงููุจูู ุงูุฑุฆูุณู ููุฌุฏ ุชูุซุงู ุฐูุจู ููุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู. ูุนูู ุงูููุฑ ุฃูุงู ุงููุจูู ุงูุฑุฆูุณู ูููุงุฌู ููุ ููุฌุฏ ุชูุซุงู ูุญุงุณู ูููุณูุญ ุจุฐุฑุงุนูู ูุฑููุนูู ูุน ุงูุฃุณุทูุฑุฉ "Venite Ad Me Omnes". ุจุฌุงูุจ ุงููุจูู ุงูุฑุฆูุณู ุชูุฌุฏ ูููุณุฉ ุงูููุจ ุงูููุฏุณ. ุฎูู ุงููููุณุฉ ูุจุงุดุฑุฉ ุชูุฌุฏ ุงููุบุงุฑุฉุ ููู ููุงู ูุฎุตุต ููุตูุงุฉ ูุงูุชุฃูู ูุฎุตุต ููุณูุฏุฉ ุงูุนุฐุฑุงุก. ููู ูุณุฎุฉ ุทุจู ุงูุฃุตู ูู ุงููุบุงุฑุฉ ุงูููุฌูุฏุฉ ูู ููุฑุฏุ ูุฑูุณุงุ ุญูุซ ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูููุฏูุณุฉ [SEP]'
```

ุจุนุฏ ุฐููุ ุณุชููู ุงูุนูุงูุงุช ูู ููุฑุณ ุงูุฑููุฒ ุงูุชู ุชุจุฏุฃ ูุชูุชูู ุงูุฅุฌุงุจุฉุ ูุณุชููู ูููุฉ ุงููููุฐุฌ ูู ุงูุชูุจุค ุจูู ูู ุจุฏุงูุฉ ูููุงูุฉ ุงูุฑูุฒ ููู ุฑูุฒ ูู ุงูุฅุฏุฎุงูุ ูุน ุงูุนูุงูุงุช ุงููุธุฑูุฉ ููุง ููู:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels.svg" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels-dark.svg" alt="One-hot encoded labels for question answering."/>
</div>

ูู ูุฐู ุงูุญุงูุฉุ ุงูุณูุงู ููุณ ุทูููุงู ุฌุฏุงูุ ูููู ุจุนุถ ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฏููุง ุณูุงูุงุช ุทูููุฉ ุฌุฏุงู ุณุชุชุฌุงูุฒ ุงูุทูู ุงูุฃูุตู ุงูุฐู ุญุฏุฏูุงู (ูุงูุฐู ูู 384 ูู ูุฐู ุงูุญุงูุฉ). ููุง ุฑุฃููุง ูู [ุงููุตู 6](/course/chapter6/4) ุนูุฏูุง ุงุณุชูุดููุง ุงูุฃุฌุฒุงุก ุงูุฏุงุฎููุฉ ูุฎุท ุฃูุงุจูุจ "question-answering"ุ ุณูุชุนุงูู ูุน ุงูุณูุงูุงุช ุงูุทูููุฉ ูู ุฎูุงู ุฅูุดุงุก ุนุฏุฉ ููุฒุงุช ุชุฏุฑูุจูุฉ ูู ุนููุฉ ูุงุญุฏุฉ ูู ูุฌููุนุฉ ุจูุงูุงุชูุงุ ูุน ูุงูุฐุฉ ููุฒูู ุจูููุง.

ููุนุฑูุฉ ููููุฉ ุนูู ุฐูู ุจุงุณุชุฎุฏุงู ุงููุซุงู ุงูุญุงููุ ูููููุง ุชุญุฏูุฏ ุงูุทูู ุงูุฃูุตู ุจู 100 ูุงุณุชุฎุฏุงู ูุงูุฐุฉ ููุฒูู ูู 50 ุฑูุฒุงู. ูุชุฐููุฑุ ูุณุชุฎุฏู:

- `max_length` ูุชุญุฏูุฏ ุงูุทูู ุงูุฃูุตู (ููุง 100)
- `truncation="only_second"` ูุชูููุต ุงูุณูุงู (ุงูุฐู ูููู ูู ุงูููุถุน ุงูุซุงูู) ุนูุฏูุง ูููู ุงูุณุคุงู ูุน ุณูุงูู ุทูููุงู ุฌุฏุงู
- `stride` ูุชุญุฏูุฏ ุนุฏุฏ ุงูุฑููุฒ ุงููุชุฏุงุฎูุฉ ุจูู ุฌุฒุฃูู ูุชุชุงูููู (ููุง 50)
- `return_overflowing_tokens=True` ูุฅุนูุงู ุฃุฏุงุฉ ุชุฌุฒุฆุฉ ุงููููุงุช ุจุฃููุง ูุฑูุฏ ุงูุฑููุฒ ุงูุฒุงุฆุฏุฉ

```py
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
)

for ids in inputs["input_ids"]:
    print(tokenizer.decode(ids))
```

```python out
'[CLS] ุฅูู ูู ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูู ุนุงู 1858 ูู ููุฑุฏุ ูุฑูุณุงุ [SEP] ูู ุงููุงุญูุฉ ุงููุนูุงุฑูุฉุ ุชุชููุฒ ุงููุฏุฑุณุฉ ุจุทุงุจุน ูุงุซููููู. ูู ุฃุนูู ูุจุฉ ุงููุจูู ุงูุฑุฆูุณู ููุฌุฏ ุชูุซุงู ุฐูุจู ููุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู. ูุนูู ุงูููุฑ ุฃูุงู ุงููุจูู ุงูุฑุฆูุณู ูููุงุฌู ููุ ููุฌุฏ ุชูุซุงู ูุญุงุณู ูููุณูุญ ุจุฐุฑุงุนูู ูุฑููุนูู ูุน ุงูุฃุณุทูุฑุฉ "Venite Ad Me Omnes". ุจุฌุงูุจ ุงููุจูู ุงูุฑุฆูุณู ุชูุฌุฏ ูููุณุฉ ุงูููุจ ุงูููุฏุณ. ุฎูู ุงููููุณุฉ ูุจุงุดุฑุฉ ุชูุฌุฏ ุงููุบุงุฑุฉุ ููู ููุงู ูุฎุตุต ููุตูุงุฉ ูุงูุชุฃูู ูุฎุตุต ููุณูุฏุฉ ุงูุนุฐุฑุงุก. ููู ูุณุฎุฉ ุทุจู ุงูุฃุตู ูู ุงููุบุงุฑุฉ ุงูููุฌูุฏุฉ ูู ููุฑุฏุ ูุฑูุณุงุ ุญูุซ ุธูุฑุช ุงูุณูุฏุฉ [SEP]'
'[CLS] ุฅูู ูู ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูู ุนุงู 1858 ูู ููุฑุฏุ ูุฑูุณุงุ [SEP] ุงููุจูู ุงูุฑุฆูุณู ูููุงุฌู ููุ ููุฌุฏ ุชูุซุงู ูุญุงุณู ูููุณูุญ ุจุฐุฑุงุนูู ูุฑููุนูู ูุน ุงูุฃุณุทูุฑุฉ "Venite Ad Me Omnes". ุจุฌุงูุจ ุงููุจูู ุงูุฑุฆูุณู ุชูุฌุฏ ูููุณุฉ ุงูููุจ ุงูููุฏุณ. ุฎูู ุงููููุณุฉ ูุจุงุดุฑุฉ ุชูุฌุฏ ุงููุบุงุฑุฉุ ููู ููุงู ูุฎุตุต ููุตูุงุฉ ูุงูุชุฃูู ูุฎุตุต ููุณูุฏุฉ ุงูุนุฐุฑุงุก. ููู ูุณุฎุฉ ุทุจู ุงูุฃุตู ูู ุงููุบุงุฑุฉ ุงูููุฌูุฏุฉ ูู ููุฑุฏุ ูุฑูุณุงุ ุญูุซ ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูููุฏูุณุฉ [SEP]'
'[CLS] ุฅูู ูู ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูู ุนุงู 1858 ูู ููุฑุฏุ ูุฑูุณุงุ [SEP] ุจุฌุงูุจ ุงููุจูู ุงูุฑุฆูุณู ุชูุฌุฏ ูููุณุฉ ุงูููุจ ุงูููุฏุณ. ุฎูู ุงููููุณุฉ ูุจุงุดุฑุฉ ุชูุฌุฏ ุงููุบุงุฑุฉุ ููู ููุงู ูุฎุตุต ููุตูุงุฉ ูุงูุชุฃูู ูุฎุตุต ููุณูุฏุฉ ุงูุนุฐุฑุงุก. ููู ูุณุฎุฉ ุทุจู ุงูุฃุตู ูู ุงููุบุงุฑุฉ ุงูููุฌูุฏุฉ ูู ููุฑุฏุ ูุฑูุณุงุ ุญูุซ ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูููุฏูุณุฉ [SEP]'
'[CLS] ุฅูู ูู ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูู ุนุงู 1858 ูู ููุฑุฏุ ูุฑูุณุงุ [SEP]. ููู ูุณุฎุฉ ุทุจู ุงูุฃุตู ูู ุงููุบุงุฑุฉ ุงูููุฌูุฏุฉ ูู ููุฑุฏุ ูุฑูุณุงุ ุญูุซ ุธูุฑุช ุงูุณูุฏุฉ ุงูุนุฐุฑุงุก ูุฑูู ุญุณุจ ุงูุงุฏุนุงุก ูููุฏูุณุฉ [SEP]'
```

ููุง ูุฑูุ ุชู ุชูุณูู ูุซุงููุง ุฅูู ุฃุฑุจุนุฉ ุฅุฏุฎุงูุงุชุ ูู ูููุง ูุญุชูู ุนูู ุงูุณุคุงู ูุจุนุถ ุฃุฌุฒุงุก ุงูุณูุงู. ูุงุญุธ ุฃู ุงูุฅุฌุงุจุฉ ุนูู ุงูุณุคุงู ("Bernadette Soubirous") ุชุธูุฑ ููุท ูู ุงูุฅุฏุฎุงู ุงูุซุงูุซ ูุงูุฃุฎูุฑุ ูุฐุง ูู ุฎูุงู ุงูุชุนุงูู ูุน ุงูุณูุงูุงุช ุงูุทูููุฉ ุจูุฐู ุงูุทุฑููุฉุ ุณูููู ุจุฅูุดุงุก ุจุนุถ ุงูุฃูุซูุฉ ุงูุชุฏุฑูุจูุฉ ุญูุซ ูุง ุชููู ุงูุฅุฌุงุจุฉ ูุฏุฑุฌุฉ ูู ุงูุณูุงู. ุจุงููุณุจุฉ ูุชูู ุงูุฃูุซูุฉุ ุณุชููู ุงูุนูุงูุงุช `start_position = end_position = 0` (ูุฐูู ูุชููุน ุฑูุฒ [CLS]). ุณูููู ุฃูุถุงู ุจุถุจุท ุชูู ุงูุนูุงูุงุช ูู ุงูุญุงูุฉ ุงููุคุณูุฉ ุญูุซ ุชู ุชูููุต ุงูุฅุฌุงุจุฉ ุจุญูุซ ูุญุตู ููุท ุนูู ุจุฏุงูุฉ (ุฃู ููุงูุฉ) ุงูุฅุฌุงุจุฉ. ุจุงููุณุจุฉ ููุฃูุซูุฉ ุงูุชู ุชููู ูููุง ุงูุฅุฌุงุจุฉ ูุงููุฉ ูู ุงูุณูุงูุ ุณุชููู ุงูุนูุงูุงุช ูู ููุฑุณ ุงูุฑูุฒ ุงูุฐู ุชุจุฏุฃ ููู ุงูุฅุฌุงุจุฉ ูููุฑุณ ุงูุฑูุฒ ุงูุฐู ุชูุชูู ููู ุงูุฅุฌุงุจุฉ.

ุชููุฑ ููุง ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุญุฑู ุงูุฃูู ููุฅุฌุงุจุฉ ูู ุงูุณูุงูุ ููู ุฎูุงู ุฅุถุงูุฉ ุทูู ุงูุฅุฌุงุจุฉุ ูููููุง ุงูุนุซูุฑ ุนูู ุงูุญุฑู ุงูุฃุฎูุฑ ูู ุงูุณูุงู. ูุฑุจุท ุชูู ุงูุฑููุฒ ุจููุฑุณ ุงูุฑููุฒุ ุณูุญุชุงุฌ ุฅูู ุงุณุชุฎุฏุงู ุฎุฑูุทุฉ ุงูุฅุฒุงุญุฉ ุงูุชู ุฏุฑุณูุงูุง ูู [ุงููุตู 6](/course/chapter6/4). ูููููุง ุฃู ูุฌุนู ุฃุฏุงุฉ ุชุฌุฒุฆุฉ ุงููููุงุช ุชุนูุฏ ูุฐู ุงูููู ูู ุฎูุงู ุชูุฑูุฑ `return_offsets_mapping=True`:

```py
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)
inputs.keys()
```

```python out
dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])
```
ููุง ูุฑูุ ูุณุชุนูุฏ ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุงููุนุชุงุฏุฉุ ูุฃููุงุน ุฑููุฒ ุงูุฅุฏุฎุงูุ ูููุงุน ุงูุงูุชุจุงูุ ุจุงูุฅุถุงูุฉ ุฅูู ุฎุฑูุทุฉ ุงูุฅุฒุงุญุฉ ุงูุชู ุทูุจูุงูุง ูููุชุงุญ ุฅุถุงูู `overflow_to_sample_mapping`. ุณุชููู ุงููููุฉ ุงูููุงุจูุฉ ูููุฏุฉ ููุง ุนูุฏูุง ูููู ุจุชููููุฒ ุนุฏุฉ ูุตูุต ูู ููุณ ุงูููุช (ููู ูุง ูุฌุจ ุนูููุง ูุนูู ููุงุณุชูุงุฏุฉ ูู ุญูููุฉ ุฃู ูุญูููุง ูุฏุนูู ูู ูุจู Rust). ุจูุง ุฃู ุงูุนููุฉ ุงููุงุญุฏุฉ ูููู ุฃู ุชุนุทู ุนุฏุฉ ููุฒุงุชุ ููู ุชุฑุจุท ูู ููุฒุฉ ุจุงููุซุงู ุงูุฐู ูุดุฃุช ููู. ุจูุง ุฃููุง ูููุง ุจุชููููุฒ ูุซุงู ูุงุญุฏ ููุทุ ูุฅููุง ูุญุตู ุนูู ูุงุฆูุฉ ูู `0`s:

```py
inputs["overflow_to_sample_mapping"]
```

```python out
[0, 0, 0, 0]
```

ูููู ุฅุฐุง ูููุง ุจุชููููุฒ ุงููุฒูุฏ ูู ุงูุฃูุซูุฉุ ูุณูุตุจุญ ูุฐุง ุฃูุซุฑ ูุงุฆุฏุฉ:

```py
inputs = tokenizer(
    raw_datasets["train"][2:6]["question"],
    raw_datasets["train"][2:6]["context"],
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)

print(f"The 4 examples gave {len(inputs['input_ids'])} features.")
print(f"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.")
```

```python out
'The 4 examples gave 19 features.'
'Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].'
```

ููุง ูุฑูุ ูุฅู ุงูุฃูุซูุฉ ุงูุซูุงุซุฉ ุงูุฃููู (ุฐุงุช ุงููุคุดุฑุงุช 2 ู3 ู4 ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ) ุชุนุทู ูู ูููุง ุฃุฑุจุน ููุฒุงุช ูุงููุซุงู ุงูุฃุฎูุฑ (ุฐู ุงููุคุดุฑ 5 ูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ) ูุนุทู 7 ููุฒุงุช.

ุณุชููู ูุฐู ุงููุนูููุงุช ูููุฏุฉ ูุฑุจุท ูู ููุฒุฉ ูุญุตู ุนูููุง ุจุงูุชุณููุฉ ุงูููุงุจูุฉ ููุง. ููุง ุฐูุฑูุง ุณุงุจููุงุ ูุฐู ุงูุชุณููุงุช ูู:

- `(0, 0)` ุฅุฐุง ูุงูุช ุงูุฅุฌุงุจุฉ ุบูุฑ ููุฌูุฏุฉ ูู ุงูุฌุฒุก ุงูููุงุจู ูู ุงูุณูุงู
- `(start_position, end_position)` ุฅุฐุง ูุงูุช ุงูุฅุฌุงุจุฉ ููุฌูุฏุฉ ูู ุงูุฌุฒุก ุงูููุงุจู ูู ุงูุณูุงูุ ูุน ููู `start_position` ูู ูุคุดุฑ ุงูุฑูุฒ (ูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู) ูู ุจุฏุงูุฉ ุงูุฅุฌุงุจุฉ ู`end_position` ูู ูุคุดุฑ ุงูุฑูุฒ (ูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู) ุญูุซ ุชูุชูู ุงูุฅุฌุงุจุฉ

ูุชุญุฏูุฏ ุฃู ูู ูุฐู ุงูุญุงูุงุช ูู ุงูุตุญูุญุ ูุฅุฐุง ูุงู ุฐุง ุตูุฉุ ููุงุถุน ุงูุฑููุฒุ ูุฌุฏ ุฃููุงู ุงููุคุดุฑุงุช ุงูุชู ุชุจุฏุฃ ูุชูุชูู ุงูุณูุงู ูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู. ูููููุง ุงุณุชุฎุฏุงู ุฃููุงุน ุฑููุฒ ุงูุฅุฏุฎุงู ููููุงู ุจุฐููุ ูููู ุจูุง ุฃู ุชูู ูุง ุชูุฌุฏ ุจุงูุถุฑูุฑุฉ ูุฌููุน ุงูููุงุฐุฌ (ุนูู ุณุจูู ุงููุซุงูุ ูุง ูุญุชุงุฌ DistilBERT ุฅูููุง)ุ ูุณูุณุชุฎุฏู ุจุฏูุงู ูู ุฐูู ุทุฑููุฉ `sequence_ids()` ูู `BatchEncoding` ุงูุชู ูุนูุฏูุง ูุญูููุง.

ุจูุฌุฑุฏ ุญุตูููุง ุนูู ูุคุดุฑุงุช ุงูุฑููุฒ ูุฐูุ ููุธุฑ ุฅูู ุงูุฅุฒุงุญุงุช ุงูููุงุจูุฉุ ูุงูุชู ูู ุฃุฒูุงุฌ ูู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ ุงูุชู ุชูุซู ุงูุฌุฒุก ูู ุงูุฃุญุฑู ุฏุงุฎู ุงูุณูุงู ุงูุฃุตูู. ูููููุง ุจุฐูู ุงูุชุดุงู ูุง ุฅุฐุง ูุงู ุฌุฒุก ุงูุณูุงู ูู ูุฐู ุงูููุฒุฉ ูุจุฏุฃ ุจุนุฏ ุงูุฅุฌุงุจุฉ ุฃู ููุชูู ูุจู ุจุฏุก ุงูุฅุฌุงุจุฉ (ูู ูุฐู ุงูุญุงูุฉ ุชููู ุงูุชุณููุฉ `(0, 0)`). ุฅุฐุง ูู ููู ุงูุฃูุฑ ูุฐููุ ูุฅููุง ูุณุชุฎุฏู ุญููุฉ ููุจุญุซ ุนู ุงูุฑูุฒ ุงูุฃูู ูุงูุฃุฎูุฑ ููุฅุฌุงุจุฉ:

```py
answers = raw_datasets["train"][2:6]["answers"]
start_positions = []
end_positions = []

for i, offset in enumerate(inputs["offset_mapping"]):
    sample_idx = inputs["overflow_to_sample_mapping"][i]
    answer = answers[sample_idx]
    start_char = answer["answer_start"][0]
    end_char = answer["answer_start"][0] + len(answer["text"][0])
    sequence_ids = inputs.sequence_ids(i)

    # Find the start and end of the context
    idx = 0
    while sequence_ids[idx] != 1:
        idx += 1
    context_start = idx
    while sequence_ids[idx] == 1:
        idx += 1
    context_end = idx - 1

    # If the answer is not fully inside the context, label is (0, 0)
    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
        start_positions.append(0)
        end_positions.append(0)
    else:
        # Otherwise it's the start and end token positions
        idx = context_start
        while idx <= context_end and offset[idx][0] <= start_char:
            idx += 1
        start_positions.append(idx - 1)

        idx = context_end
        while idx >= context_start and offset[idx][1] >= end_char:
            idx -= 1
        end_positions.append(idx + 1)

start_positions, end_positions
```

```python out
([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],
 [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])
```

ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ุจุนุถ ุงููุชุงุฆุฌ ููุชุญูู ูู ุฃู ููุฌูุง ุตุญูุญ. ุจุงููุณุจุฉ ููููุฒุฉ ุงูุฃูููุ ูุฌุฏ `(83, 85)` ูุนูุงูุงุชุ ูุฐุง ุฏุนููุง ููุงุฑู ุงูุฅุฌุงุจุฉ ุงููุธุฑูุฉ ุจุงูุฌุฒุก ุงููุดูุฑ ูู ุงูุฑููุฒ ูู 83 ุฅูู 85 (ุดุงูู):

```py
idx = 0
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

start = start_positions[idx]
end = end_positions[idx]
labeled_answer = tokenizer.decode(inputs["input_ids"][idx][start : end + 1])

print(f"Theoretical answer: {answer}, labels give: {labeled_answer}")
```

```python out
'Theoretical answer: the Main Building, labels give: the Main Building'
```

ุฅูู ูุทุงุจู! ุงูุขู ุฏุนููุง ูุชุญูู ูู ุงููุคุดุฑ 4ุ ุญูุซ ูููุง ุจุชุนููู ุงูุนูุงูุงุช ุฅูู `(0, 0)`ุ ููุง ูุนูู ุฃู ุงูุฅุฌุงุจุฉ ุบูุฑ ููุฌูุฏุฉ ูู ุฌุฒุก ุงูุณูุงู ูู ุชูู ุงูููุฒุฉ:

```py
idx = 4
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

decoded_example = tokenizer.decode(inputs["input_ids"][idx])
print(f"Theoretical answer: {answer}, decoded example: {decoded_example}")
```

```python out
'Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]'
```

ุจุงููุนูุ ูุง ูุฑู ุงูุฅุฌุงุจุฉ ุฏุงุฎู ุงูุณูุงู.

<Tip>

โ๏ธ **ุฏูุฑู!** ุนูุฏ ุงุณุชุฎุฏุงู ุจููุฉ XLNetุ ูุชู ุชุทุจูู ุงูุญุดู ุนูู ุงููุณุงุฑ ููุชู ุชุจุฏูู ุงูุณุคุงู ูุงูุณูุงู. ูู ุจุชุนุฏูู ูู ุงูููุฏ ุงูุฐู ุฑุฃููุงู ููุชู ููุชูุงุณุจ ูุน ุจููุฉ XLNet (ูุฃุถู `padding=True`). ูู ุนูู ุฏุฑุงูุฉ ุจุฃู ุงูุฑูุฒ `[CLS]` ูุฏ ูุง ูููู ูู ุงูููุถุน 0 ูุน ุชุทุจูู ุงูุญุดู.

</Tip>

ุงูุขู ุจุนุฏ ุฃู ุฑุฃููุง ุฎุทูุฉ ุจุฎุทูุฉ ููููุฉ ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุงุ ูููููุง ุชุฌููุนูุง ูู ุฏุงูุฉ ุณูุทุจููุง ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุจุงููุงูู. ุณูููู ุจุญุดู ูู ููุฒุฉ ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ุญุฏุฏูุงูุ ุญูุซ ุณุชููู ูุนุธู ุงูุณูุงูุงุช ุทูููุฉ (ูุณุชูุณู ุงูุนููุงุช ุงูููุงุจูุฉ ุฅูู ุนุฏุฉ ููุฒุงุช)ุ ูุฐูู ูุง ุชูุฌุฏ ูุงุฆุฏุฉ ุญููููุฉ ูู ุชุทุจูู ุงูุญุดู ุงูุฏููุงูููู ููุง:

```py
max_length = 384
stride = 128


def preprocess_training_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    offset_mapping = inputs.pop("offset_mapping")
    sample_map = inputs.pop("overflow_to_sample_mapping")
    answers = examples["answers"]
    start_positions = []
    end_positions = []

    for i, offset in enumerate(offset_mapping):
        sample_idx = sample_map[i]
        answer = answers[sample_idx]
        start_char = answer["answer_start"][0]
        end_char = answer["answer_start"][0] + len(answer["text"][0])
        sequence_ids = inputs.sequence_ids(i)

        # Find the start and end of the context
        idx = 0
        while sequence_ids[idx] != 1:
            idx += 1
        context_start = idx
        while sequence_ids[idx] == 1:
            idx += 1
        context_end = idx - 1

        # If the answer is not fully inside the context, label is (0, 0)
        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
            start_positions.append(0)
            end_positions.append(0)
        else:
            # Otherwise it's the start and end token positions
            idx = context_start
            while idx <= context_end and offset[idx][0] <= start_char:
                idx += 1
            start_positions.append(idx - 1)

            idx = context_end
            while idx >= context_start and offset[idx][1] >= end_char:
                idx -= 1
            end_positions.append(idx + 1)

    inputs["start_positions"] = start_positions
    inputs["end_positions"] = end_positions
    return inputs
```
```
ูุงุญุธ ุฃููุง ุญุฏุฏูุง ุซุงุจุชูู ูุชุญุฏูุฏ ุงูุทูู ุงูุฃูุตู ุงููุณุชุฎุฏู ุจุงูุฅุถุงูุฉ ุฅูู ุทูู ูุงูุฐุฉ ุงูุงูุฒูุงูุ ูุฃููุง ุฃุถููุง ุจุนุถ ุงูุชูุธูู ูุจู ุงูุชุฌุฒุฆุฉ: ุจุนุถ ุงูุฃุณุฆูุฉ ูู ูุฌููุนุฉ ุจูุงูุงุช SQuAD ุจูุง ูุณุงูุงุช ุฅุถุงููุฉ ูู ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ูุง ุชุถูู ุฃู ุดูุก (ูุชุฃุฎุฐ ูุณุงุญุฉ ุนูุฏ ุงูุชุฌุฒุฆุฉ ุฅุฐุง ููุช ุชุณุชุฎุฏู ูููุฐุฌูุง ูุซู RoBERTa)ุ ูุฐุง ูููุง ุจุฅุฒุงูุฉ ุชูู ุงููุณุงูุงุช ุงูุฅุถุงููุฉ.

ูุชุทุจูู ูุฐู ุงูุฏุงูุฉ ุนูู ูุฌููุนุฉ ุงูุชุฏุฑูุจ ุจุงููุงููุ ูุณุชุฎุฏู ุทุฑููุฉ `Dataset.map()` ูุน ุนูู `batched=True`. ูุฐุง ุถุฑูุฑู ููุง ูุฃููุง ูุบูุฑ ุทูู ูุฌููุนุฉ ุงูุจูุงูุงุช (ุญูุซ ูููู ุฃู ูุนุทู ุงููุซุงู ุงููุงุญุฏ ุนุฏุฉ ููุฒุงุช ุชุฏุฑูุจูุฉ):

```py
train_dataset = raw_datasets["train"].map(
    preprocess_training_examples,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
len(raw_datasets["train"]), len(train_dataset)
```

```python out
(87599, 88729)
```

ููุง ูุฑูุ ุฃุถุงูุช ูุฑุญูุฉ ูุง ูุจู ุงููุนุงูุฌุฉ ุญูุงูู 1000 ููุฒุฉ. ูุฌููุนุฉ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุง ุฌุงูุฒุฉ ุงูุขู ููุงุณุชุฎุฏุงู -- ุฏุนูุง ูุชุนูู ูู ูุนุงูุฌุฉ ูุฌููุนุฉ ุงูุชุญูู!

### ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชุญูู[[processing-the-validation-data]]

ุณุชููู ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชุญูู ุฃุณูู ููููุงู ูุฃููุง ูุง ูุญุชุงุฌ ุฅูู ุชูููุฏ ุชุณููุงุช (ูุง ูู ูุฑุบุจ ูู ุญุณุงุจ ุฎุณุงุฑุฉ ุงูุชุญููุ ูููู ูุฐุง ุงูุฑูู ูู ูุณุงุนุฏูุง ุญููุง ูู ููู ูุฏู ุฌูุฏุฉ ุงููููุฐุฌ). ุณุชููู ุงููุชุนุฉ ุงูุญููููุฉ ูู ุชูุณูุฑ ุชูุจุคุงุช ุงููููุฐุฌ ุฅูู ููุงุทุน ูู ุงูุณูุงู ุงูุฃุตูู. ููุฐุงุ ุณูุญุชุงุฌ ููุท ุฅูู ุชุฎุฒูู ูู ูู ุฎุฑุงุฆุท ุงูุฅุฒุงุญุฉ ูุจุนุถ ุงูุทุฑู ููุทุงุจูุฉ ูู ููุฒุฉ ุชู ุฅูุดุงุคูุง ูุน ุงููุซุงู ุงูุฃุตูู ุงูุฐู ุชุฃุชู ููู. ูุธุฑูุง ููุฌูุฏ ุนููุฏ ูุนุฑู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฃุตููุฉุ ูุณูุณุชุฎุฏู ูุฐุง ุงููุนุฑู.

ุงูุดูุก ุงููุญูุฏ ุงูุฐู ุณูุถููู ููุง ูู ุงููููู ูู ุชูุธูู ุฎุฑุงุฆุท ุงูุฅุฒุงุญุฉ. ุณุชุญุชูู ุนูู ุฅุฒุงุญุงุช ููุณุคุงู ูุงูุณูุงูุ ูููู ุจูุฌุฑุฏ ูุตูููุง ุฅูู ูุฑุญูุฉ ูุง ุจุนุฏ ุงููุนุงูุฌุฉุ ูู ูููู ูุฏููุง ุฃู ุทุฑููุฉ ููุนุฑูุฉ ุฃู ุฌุฒุก ูู ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุงูููุงุจูุฉ ููุณูุงู ูุฃู ุฌุฒุก ูุงู ุงูุณุคุงู (ุทุฑููุฉ `sequence_ids()` ุงูุชู ุงุณุชุฎุฏููุงูุง ูุชุงุญุฉ ููุท ูุฅุฎุฑุงุฌ ุงููุญูู ุงููุบูู). ูุฐุงุ ุณูููู ุจุชุนููู ุงูุฅุฒุงุญุงุช ุงูููุงุจูุฉ ููุณุคุงู ุฅูู `None`:

```py
def preprocess_validation_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    sample_map = inputs.pop("overflow_to_sample_mapping")
    example_ids = []

    for i in range(len(inputs["input_ids"])):
        sample_idx = sample_map[i]
        example_ids.append(examples["id"][sample_idx])

        sequence_ids = inputs.sequence_ids(i)
        offset = inputs["offset_mapping"][i]
        inputs["offset_mapping"][i] = [
            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)
        ]

    inputs["example_id"] = example_ids
    return inputs
```

ูููููุง ุชุทุจูู ูุฐู ุงูุฏุงูุฉ ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุญูู ุจุงููุงูู ูุซููุง ูุนููุง ูู ูุจู:

```py
validation_dataset = raw_datasets["validation"].map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
len(raw_datasets["validation"]), len(validation_dataset)
```

```python out
(10570, 10822)
```

ูู ูุฐู ุงูุญุงูุฉุ ุฃุถููุง ููุท ุจุถุน ูุฆุงุช ูู ุงูุนููุงุชุ ูุฐุง ูุจุฏู ุฃู ุงูุณูุงูุงุช ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุญูู ุฃูุตุฑ ููููุงู.

ุงูุขู ุจุนุฏ ุฃู ูููุง ุจูุนุงูุฌุฉ ุฌููุน ุงูุจูุงูุงุชุ ูููููุง ุงูุงูุชูุงู ุฅูู ุงูุชุฏุฑูุจ.

{#if fw === 'pt'}

## ุถุจุท ุฏููู ูููููุฐุฌ ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช `Trainer`[[fine-tuning-the-model-with-the-trainer-api]]

ุณูุดุจู ุฑูุฒ ุงูุชุฏุฑูุจ ููุฐุง ุงููุซุงู ุฅูู ุญุฏ ูุจูุฑ ุงูุฑูุฒ ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉ -- ุณูููู ุงูุฃูุฑ ุงูุฃุตุนุจ ูู ูุชุงุจุฉ ุฏุงูุฉ `compute_metrics()`. ูุธุฑูุง ูุฃููุง ูููุง ุจููุก ุฌููุน ุงูุนููุงุช ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ุญุฏุฏูุงูุ ูุง ููุฌุฏ ุฌุงูุน ุจูุงูุงุช ูุชุญุฏูุฏูุ ูุฐุง ูุฅู ุญุณุงุจ ุงููููุงุณ ูู ุงูุดูุก ุงููุญูุฏ ุงูุฐู ูุฌุจ ุฃู ูููู ุจุดุฃูู. ุณูููู ุงูุฌุฒุก ุงูุตุนุจ ูู ูุนุงูุฌุฉ ุชูุจุคุงุช ุงููููุฐุฌ ุฅูู ููุงุทุน ูุตูุฉ ูู ุงูุฃูุซูุฉ ุงูุฃุตููุฉุ ุจูุฌุฑุฏ ุฃู ููุนู ุฐููุ ูุฅู ุงููููุงุณ ูู ููุชุจุฉ ๐ค Datasets ุณุชููู ุจูุนุธู ุงูุนูู ูู ุฃุฌููุง.

{:else}

## ุถุจุท ุฏููู ูููููุฐุฌ ุจุงุณุชุฎุฏุงู Keras[[fine-tuning-the-model-with-keras]]

ุณูุดุจู ุฑูุฒ ุงูุชุฏุฑูุจ ููุฐุง ุงููุซุงู ุฅูู ุญุฏ ูุจูุฑ ุงูุฑูุฒ ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉุ ูููู ุญุณุงุจ ุงูููุงููุณ ุณูููู ุชุญุฏููุง ูุฑูุฏูุง. ูุธุฑูุง ูุฃููุง ูููุง ุจููุก ุฌููุน ุงูุนููุงุช ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ุญุฏุฏูุงูุ ูุง ููุฌุฏ ุฌุงูุน ุจูุงูุงุช ูุชุญุฏูุฏูุ ูุฐุง ูุฅู ุญุณุงุจ ุงููููุงุณ ูู ุงูุดูุก ุงููุญูุฏ ุงูุฐู ูุฌุจ ุฃู ูููู ุจุดุฃูู. ุณูููู ุงูุฌุฒุก ุงูุตุนุจ ูู ูุนุงูุฌุฉ ุชูุจุคุงุช ุงููููุฐุฌ ุฅูู ููุงุทุน ูุตูุฉ ูู ุงูุฃูุซูุฉ ุงูุฃุตููุฉุ ุจูุฌุฑุฏ ุฃู ููุนู ุฐููุ ูุฅู ุงููููุงุณ ูู ููุชุจุฉ ๐ค Datasets ุณุชููู ุจูุนุธู ุงูุนูู ูู ุฃุฌููุง.

{/if}

### ูุง ุจุนุฏ ุงููุนุงูุฌุฉ[[post-processing]]

{#if fw === 'pt'}

<Youtube id="BNy08iIWVJM"/>

{:else}

<Youtube id="VN67ZpN33Ss"/>

{/if}

ุณูุฎุฑุฌ ุงููููุฐุฌ ุงุญุชูุงูุงุช ูููุงุถุน ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ููุฅุฌุงุจุฉ ูู ูุนุฑูุงุช ุงูุฅุฏุฎุงูุ ููุง ุฑุฃููุง ุฎูุงู ุงุณุชูุดุงููุง ูุฃูุจูุจ [`question-answering`](/course/chapter6/3b). ุณุชููู ุฎุทูุฉ ูุง ุจุนุฏ ุงููุนุงูุฌุฉ ููุงุซูุฉ ููุง ูุนููุงู ููุงูุ ูุฐุง ุฅููู ุชุฐููุฑ ุณุฑูุน ุจุงูุฅุฌุฑุงุกุงุช ุงูุชู ุงุชุฎุฐูุงูุง:

- ูููุง ุจุชุนููุฉ ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ุงูููุงุจูุฉ ููุฑููุฒ ุฎุงุฑุฌ ุงูุณูุงู.
- ุซู ูููุง ุจุชุญููู ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ุฅูู ุงุญุชูุงูุงุช ุจุงุณุชุฎุฏุงู softmax.
- ูููุง ุจุฅุณูุงุฏ ุฏุฑุฌุฉ ููู ุฒูุฌ `(start_token, end_token)` ุนู ุทุฑูู ุฃุฎุฐ ุญุงุตู ุงูุถุฑุจ ูู ุงูุงุญุชูุงููู ุงูููุงุจููู.
- ุจุญุซูุง ุนู ุงูุฒูุฌ ุฐู ุงูุฏุฑุฌุฉ ุงููุตูู ุงูุชู ุฃุนุทุช ุฅุฌุงุจุฉ ุตุงูุญุฉ (ุนูู ุณุจูู ุงููุซุงูุ `start_token` ุฃูู ูู `end_token`).

ููุง ุณูุบูุฑ ูุฐู ุงูุนูููุฉ ููููุงู ูุฃููุง ูุง ูุญุชุงุฌ ุฅูู ุญุณุงุจ ุงูุฏุฑุฌุงุช ุงููุนููุฉ (ููุท ุงูุฅุฌุงุจุฉ ุงููุชููุนุฉ). ูุฐุง ูุนูู ุฃูู ูููููุง ุชุฎุทู ุฎุทูุฉ softmax. ููุฐูุงุจ ุจุดูู ุฃุณุฑุนุ ูู ูููู ุฃูุถูุง ุจุชุณุฌูู ุฌููุน ุงูุฃุฒูุงุฌ ุงูููููุฉ `(start_token, end_token)`ุ ูููู ููุท ุชูู ุงูููุงุจูุฉ ูุฃุนูู `n_best` ุงุญุชูุงูุงุช (ูุน `n_best=20`). ูุธุฑูุง ูุฃููุง ุณูููู ุจุชุฎุทู softmaxุ ุณุชููู ุชูู ุงูุฏุฑุฌุงุช ุงุญุชูุงูุงุชุ ูุณูุชู ุงูุญุตูู ุนูููุง ุนู ุทุฑูู ุฃุฎุฐ ูุฌููุน ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ (ุจุฏูุงู ูู ุญุงุตู ุงูุถุฑุจุ ุจุณุจุจ ุงููุงุนุฏุฉ \\(\log(ab) = \log(a) + \log(b)\\)).

ูุฅุซุจุงุช ูู ูุฐุงุ ุณูุญุชุงุฌ ุฅูู ููุน ูู ุงูุชูุจุคุงุช. ูุธุฑูุง ูุฃููุง ูู ููู ุจุชุฏุฑูุจ ูููุฐุฌูุง ุจุนุฏุ ุณูุณุชุฎุฏู ุงููููุฐุฌ ุงูุงูุชุฑุงุถู ูุฃูุจูุจ QA ูุชูููุฏ ุจุนุถ ุงูุชูุจุคุงุช ุนูู ุฌุฒุก ุตุบูุฑ ูู ูุฌููุนุฉ ุงูุชุญูู. ูููููุง ุงุณุชุฎุฏุงู ุฏุงูุฉ ุงููุนุงูุฌุฉ ููุณูุง ููุง ูุนููุง ูู ูุจูุ ูุฃููุง ุชุนุชูุฏ ุนูู ุงูุซุงุจุช ุงูุนุงููู `tokenizer`ุ ุนูููุง ููุท ุชุบููุฑ ูุฐุง ุงููุงุฆู ุฅูู ุงููุญูู ุงููุบูู ูููููุฐุฌ ุงูุฐู ูุฑูุฏ ุงุณุชุฎุฏุงูู ูุคูุชูุง:

```python
small_eval_set = raw_datasets["validation"].select(range(100))
trained_checkpoint = "distilbert-base-cased-distilled-squad"

tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)
eval_set = small_eval_set.map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
```

ุงูุขู ุจุนุฏ ุงูุงูุชูุงุก ูู ุงููุนุงูุฌุฉ ุงููุณุจูุฉุ ูุบูุฑ ุงููุญูู ุงููุบูู ูุฑุฉ ุฃุฎุฑู ุฅูู ุงููุญูู ุงููุบูู ุงูุฐู ุงุฎุชุฑูุงู ูู ุงูุฃุตู:

```python
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

ุซู ูููู ุจุฅุฒุงูุฉ ุฃุนูุฏุฉ `eval_set` ุงูุชู ูุง ูุชููุนูุง ุงููููุฐุฌุ ููุจูู ุฏูุนุฉ ุจูู ุชูู ูุฌููุนุฉ ุงูุชุญูู ุงูุตุบูุฑุฉุ ูููุฑุฑูุง ุนุจุฑ ุงููููุฐุฌ. ุฅุฐุง ูุงูุช ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ูุชุงุญุฉุ ูุณุชุฎุฏููุง ููุฐูุงุจ ุจุดูู ุฃุณุฑุน:

{#if fw === 'pt'}

```python
import torch
from transformers import AutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("torch")

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}
trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(
    device
)

with torch.no_grad():
    outputs = trained_model(**batch)
```

ูุธุฑูุง ูุฃู `Trainer` ุณูุนุทููุง ุชูุจุคุงุช ููุตูููุงุช NumPyุ ูุฅููุง ูุฃุฎุฐ ุงุญุชูุงูุงุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉ ููุญูููุง ุฅูู ูุฐุง ุงูุชูุณูู:

```python
start_logits = outputs.start_logits.cpu().numpy()
end_logits = outputs.end_logits.cpu().numpy()
```
```
{:else}

```python
import tensorflow as tf
from transformers import TFAutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("numpy")

batch = {k: eval_set_for_model[k] for k in eval_set_for_model.column_names}
trained_model = TFAutoModelForQuestionAnswering.from_pretrained(trained_checkpoint)

outputs = trained_model(**batch)
```

ููุชุฌุฑุจุฉุ ุฏุนูุง ูุญูู ูุฐู ุงููุฎุฑุฌุงุช ุฅูู ูุตูููุงุช NumPy:

```python
start_logits = outputs.start_logits.numpy()
end_logits = outputs.end_logits.numpy()
```

{/if}

ุงูุขูุ ูุญุชุงุฌ ุฅูู ุฅูุฌุงุฏ ุงูุฅุฌุงุจุฉ ุงููุชููุนุฉ ููู ูุซุงู ูู `small_eval_set`. ูุฏ ูููู ุงููุซุงู ุงููุงุญุฏ ููุณูุงู ุฅูู ุนุฏุฉ ููุฒุงุช ูู `eval_set`ุ ูุฐุง ูุฅู ุงูุฎุทูุฉ ุงูุฃููู ูู ูุทุงุจูุฉ ูู ูุซุงู ูู `small_eval_set` ูุน ุงูููุฒุงุช ุงูููุงุจูุฉ ูู `eval_set`:

```python
import collections

example_to_features = collections.defaultdict(list)
for idx, feature in enumerate(eval_set):
    example_to_features[feature["example_id"]].append(idx)
```

ุจุงุณุชุฎุฏุงู ูุฐู ุงูุจูุงูุงุชุ ูููููุง ุงูุจุฏุก ูู ุงูุนูู ุนู ุทุฑูู ุงูุชูุฑุงุฑ ุฎูุงู ุฌููุน ุงูุฃูุซูุฉุ ูููู ูุซุงูุ ุฎูุงู ุฌููุน ุงูููุฒุงุช ุงููุฑุชุจุทุฉ. ููุง ุฐูุฑูุง ุณุงุจูุงูุ ุณููุธุฑ ุฅูู ุฏุฑุฌุงุช ุงูููุฌูุช ูู `n_best` ููุฌูุช ุงูุจุฏุงูุฉ ูุงูููุงูุฉุ ูุณุชุจุนุฏูู ุงูููุงุถุน ุงูุชู ุชุนุทู:

- ุฅุฌุงุจุฉ ูู ุชููู ุฏุงุฎู ุงูุณูุงู
- ุฅุฌุงุจุฉ ุจุทูู ุณูุจู
- ุฅุฌุงุจุฉ ุทูููุฉ ุฌุฏุงู (ูุญุฏุฏ ุงูุงุญุชูุงูุงุช ุจู `max_answer_length=30`)

ุจูุฌุฑุฏ ุฃู ูุญุตู ุนูู ุฌููุน ุงูุฅุฌุงุจุงุช ุงููุญุชููุฉ ุฐุงุช ุงูุฏุฑุฌุงุช ููู ูุซุงูุ ูุฎุชุงุฑ ุจุจุณุงุทุฉ ุงูุฅุฌุงุจุฉ ุฐุงุช ุฃูุถู ุฏุฑุฌุฉ ููุฌูุช:

```python
import numpy as np

n_best = 20
max_answer_length = 30
predicted_answers = []

for example in small_eval_set:
    example_id = example["id"]
    context = example["context"]
    answers = []

    for feature_index in example_to_features[example_id]:
        start_logit = start_logits[feature_index]
        end_logit = end_logits[feature_index]
        offsets = eval_set["offset_mapping"][feature_index]

        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
        for start_index in start_indexes:
            for end_index in end_indexes:
                # ุชุฎุทู ุงูุฅุฌุงุจุงุช ุงูุชู ููุณุช ุฏุงุฎู ุงูุณูุงู ุจุงููุงูู
                if offsets[start_index] is None or offsets[end_index] is None:
                    continue
                # ุชุฎุทู ุงูุฅุฌุงุจุงุช ุจุทูู ุฃูู ูู 0 ุฃู ุฃูุจุฑ ูู max_answer_length.
                if (
                    end_index < start_index
                    or end_index - start_index + 1 > max_answer_length
                ):
                    continue

                answers.append(
                    {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                )

    best_answer = max(answers, key=lambda x: x["logit_score"])
    predicted_answers.append({"id": example_id, "prediction_text": best_answer["text"]})
```

ุงูุชูุณูู ุงูููุงุฆู ููุฅุฌุงุจุงุช ุงููุชููุนุฉ ูู ูุง ุณูุชููุนู ุงููููุงุณ ุงูุฐู ุณูุณุชุฎุฏูู. ููุง ูู ูุนุชุงุฏุ ูููููุง ุชุญูููู ุจูุณุงุนุฏุฉ ููุชุจุฉ ๐ค Evaluate:

```python
import evaluate

metric = evaluate.load("squad")
```

ูุฐุง ุงููููุงุณ ูุชููุน ุงูุฅุฌุงุจุงุช ุงููุชููุนุฉ ูู ุงูุชูุณูู ุงูุฐู ุฑุฃููุงู ุฃุนูุงู (ูุงุฆูุฉ ูู ุงูููุงููุณ ุจููุชุงุญ ูุงุญุฏ ูุฑูู ุชุนุฑูู ุงููุซุงู ูููุชุงุญ ูุงุญุฏ ูููุต ุงููุชููุน) ูุงูุฅุฌุงุจุงุช ุงููุธุฑูุฉ ูู ุงูุชูุณูู ุฃุฏูุงู (ูุงุฆูุฉ ูู ุงูููุงููุณ ุจููุชุงุญ ูุงุญุฏ ูุฑูู ุชุนุฑูู ุงููุซุงู ูููุชุงุญ ูุงุญุฏ ููุฅุฌุงุจุงุช ุงููุญุชููุฉ):

```python
theoretical_answers = [
    {"id": ex["id"], "answers": ex["answers"]} for ex in small_eval_set
]
```

ูููููุง ุงูุขู ุงูุชุญูู ูู ุฃููุง ูุญุตู ุนูู ูุชุงุฆุฌ ูุนูููุฉ ูู ุฎูุงู ุงููุธุฑ ุฅูู ุงูุนูุตุฑ ุงูุฃูู ูู ููุง ุงููุงุฆูุชูู:

```python
print(predicted_answers[0])
print(theoretical_answers[0])
```

```python out
{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}
{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}
```

ููุณ ุณูุฆุงู! ุงูุขู ููููู ูุธุฑุฉ ุนูู ุงููุชูุฌุฉ ุงูุชู ูุนุทููุง ุฅูุงูุง ุงููููุงุณ:

```python
metric.compute(predictions=predicted_answers, references=theoretical_answers)
```

```python out
{'exact_match': 83.0, 'f1': 88.25}
```

ูุฑุฉ ุฃุฎุฑูุ ูุฐุง ุฌูุฏ ุฌุฏุงู ุจุงููุธุฑ ุฅูู ุฃู [ูุฑูุชู ุงูุจุญุซูุฉ](https://arxiv.org/abs/1910.01108v2) ุชุดูุฑ ุฅูู ุฃู DistilBERT ุงููุนุฒุฒ ุนูู SQuAD ูุญุตู ุนูู 79.1 ู 86.9 ูุชูู ุงูุฏุฑุฌุงุช ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

{#if fw === 'pt'}

ุงูุขู ุฏุนูุง ูุถุน ูู ูุง ูุนููุงู ููุชู ูู ุฏุงูุฉ `compute_metrics()` ุงูุชู ุณูุณุชุฎุฏููุง ูู `Trainer`. ุนุงุฏุฉูุ ุชุณุชูุจู ุฏุงูุฉ `compute_metrics()` ููุท ุฒูุฌุงู `eval_preds` ูุน ุงูููุฌูุช ูุงูููุตูุงุช. ููุง ุณูุญุชุงุฌ ุฅูู ุฃูุซุฑ ูู ุฐูู ุจููููุ ุญูุซ ูุฌุจ ุฃู ูุจุญุซ ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูููุฒุงุช ููุชุนููุถ ููู ูุฌููุนุฉ ุจูุงูุงุช ุงูุฃูุซูุฉ ููุณูุงูุงุช ุงูุฃุตููุฉุ ูุฐุง ูู ูุชููู ูู ุงุณุชุฎุฏุงู ูุฐู ุงูุฏุงูุฉ ููุญุตูู ุนูู ูุชุงุฆุฌ ุงูุชูููู ุงูุนุงุฏูุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ. ูู ูุณุชุฎุฏููุง ุฅูุง ูู ููุงูุฉ ุงูุชุฏุฑูุจ ููุชุญูู ูู ุงููุชุงุฆุฌ.

ุชุถู ุฏุงูุฉ `compute_metrics()` ููุณ ุงูุฎุทูุงุช ููุง ูู ุงูุญุงู ูู ูุจูุ ูุถูู ููุท ูุญุตุงู ุตุบูุฑุงู ูู ุญุงูุฉ ุนุฏู ุชูุตููุง ุฅูู ุฃู ุฅุฌุงุจุงุช ุตุงูุญุฉ (ูู ูุฐู ุงูุญุงูุฉ ูุชููุน ุณูุณูุฉ ูุงุฑุบุฉ).

{:else}

ุงูุขู ุฏุนูุง ูุถุน ูู ูุง ูุนููุงู ููุชู ูู ุฏุงูุฉ `compute_metrics()` ุงูุชู ุณูุณุชุฎุฏููุง ุจุนุฏ ุชุฏุฑูุจ ูููุฐุฌูุง. ุณูุญุชุงุฌ ุฅูู ุชูุฑูุฑ ุฃูุซุฑ ูู ูุฌุฑุฏ ููุฌูุช ุงููุฎุฑุฌุงุชุ ุญูุซ ูุฌุจ ุฃู ูุจุญุซ ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูููุฒุงุช ููุชุนููุถ ููู ูุฌููุนุฉ ุจูุงูุงุช ุงูุฃูุซูุฉ ููุณูุงูุงุช ุงูุฃุตููุฉ:

{/if}

```python
from tqdm.auto import tqdm


def compute_metrics(start_logits, end_logits, features, examples):
    example_to_features = collections.defaultdict(list)
    for idx, feature in enumerate(features):
        example_to_features[feature["example_id"]].append(idx)

    predicted_answers = []
    for example in tqdm(examples):
        example_id = example["id"]
        context = example["context"]
        answers = []

        # ุงูุชูุฑุงุฑ ุฎูุงู ุฌููุน ุงูููุฒุงุช ุงููุฑุชุจุทุฉ ุจุฐูู ุงููุซุงู
        for feature_index in example_to_features[example_id]:
            start_logit = start_logits[feature_index]
            end_logit = end_logits[feature_index]
            offsets = features[feature_index]["offset_mapping"]

            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
            for start_index in start_indexes:
                for end_index in end_indexes:
                    # ุชุฎุทู ุงูุฅุฌุงุจุงุช ุงูุชู ููุณุช ุฏุงุฎู ุงูุณูุงู ุจุงููุงูู
                    if offsets[start_index] is None or offsets[end_index] is None:
                        continue
                    # ุชุฎุทู ุงูุฅุฌุงุจุงุช ุจุทูู ุฃูู ูู 0 ุฃู ุฃูุจุฑ ูู max_answer_length
                    if (
                        end_index < start_index
                        or end_index - start_index + 1 > max_answer_length
                    ):
                        continue

                    answer = {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                    answers.append(answer)

        # ุงุฎุชูุงุฑ ุงูุฅุฌุงุจุฉ ุฐุงุช ุฃูุถู ุฏุฑุฌุฉ
        if len(answers) > 0:
            best_answer = max(answers, key=lambda x: x["logit_score"])
            predicted_answers.append(
                {"id": example_id, "prediction_text": best_answer["text"]}
            )
        else:
            predicted_answers.append({"id": example_id, "prediction_text": ""})

    theoretical_answers = [{"id": ex["id"], "answers": ex["answers"]} for ex in examples]
    return metric.compute(predictions=predicted_answers, references=theoretical_answers)
```

ูููููุง ุงูุชุญูู ูู ุนูููุง ุนูู ุชูุจุคุงุชูุง:

```python
compute_metrics(start_logits, end_logits, eval_set, small_eval_set)
```

```python out
{'exact_match': 83.0, 'f1': 88.25}
```
```
{'exact_match': 83.0, 'f1': 88.25}
```

ูุจุฏู ุฌูุฏูุง! ุงูุขู ุฏุนูุง ูุณุชุฎุฏู ูุฐุง ูุถุจุท ูููุฐุฌูุง.

### ุถุจุท ุงููููุฐุฌ[[fine-tuning-the-model]]

{#if fw === 'pt'}

ูุญู ุงูุขู ูุณุชุนุฏูู ูุชุฏุฑูุจ ูููุฐุฌูุง. ุฏุนูุง ููุดุฆู ุฃููุงูุ ุจุงุณุชุฎุฏุงู ูุฆุฉ `AutoModelForQuestionAnswering` ููุง ูุนููุง ูู ูุจู:

```python
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

{:else}

ูุญู ุงูุขู ูุณุชุนุฏูู ูุชุฏุฑูุจ ูููุฐุฌูุง. ุฏุนูุง ููุดุฆู ุฃููุงูุ ุจุงุณุชุฎุฏุงู ูุฆุฉ `TFAutoModelForQuestionAnswering` ููุง ูุนููุง ูู ูุจู:

```python
model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

{/if}

ููุง ูู ูุนุชุงุฏุ ูุญุตู ุนูู ุชุญุฐูุฑ ุจุฃู ุจุนุถ ุงูุฃูุฒุงู ูุง ูุชู ุงุณุชุฎุฏุงููุง (ุงูุชู ูู ุฑุฃุณ ุงูุชุฏุฑูุจ ุงููุณุจู) ูุงูุจุนุถ ุงูุขุฎุฑ ูุชู ุชููุฆุชูุง ุจุดูู ุนุดูุงุฆู (ุงูุชู ูุฑุฃุณ ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ). ูุฌุจ ุฃู ุชููู ูุนุชุงุฏูุง ุนูู ุฐูู ุงูุขูุ ูููู ูุฐุง ูุนูู ุฃู ูุฐุง ุงููููุฐุฌ ููุณ ุฌุงูุฒูุง ููุงุณุชุฎุฏุงู ุจุนุฏ ููุญุชุงุฌ ุฅูู ุงูุถุจุท - ููู ุฃูุฑ ุฌูุฏ ุฃููุง ุนูู ูุดู ุงูููุงู ุจุฐูู!

ููู ูุชููู ูู ุฏูุน ูููุฐุฌูุง ุฅูู ุงููุฑูุฒุ ุณูุญุชุงุฌ ุฅูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู Hugging Face. ุฅุฐุง ููุช ุชุดุบู ูุฐุง ุงูููุฏ ูู ุฏูุชุฑ ููุงุญุธุงุชุ ูููููู ุงูููุงู ุจุฐูู ุจุงุณุชุฎุฏุงู ูุธููุฉ ุงููุณุงุนุฏุฉ ุงูุชุงููุฉุ ูุงูุชู ุชุนุฑุถ ุฃุฏุงุฉ ููููู ูู ุฎูุงููุง ุฅุฏุฎุงู ุจูุงูุงุช ุงุนุชูุงุฏ ุชุณุฌูู ุงูุฏุฎูู ุงูุฎุงุตุฉ ุจู:

```python
from huggingface_hub import notebook_login

notebook_login()
```

ุฅุฐุง ูู ุชูู ุชุนูู ูู ุฏูุชุฑ ููุงุญุธุงุชุ ููุง ุนููู ุณูู ูุชุงุจุฉ ุงูุณุทุฑ ุงูุชุงูู ูู ุทุฑููุชู:

```bash
huggingface-cli login
```

{#if fw === 'pt'}

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฐููุ ูููููุง ุชุญุฏูุฏ `TrainingArguments`. ููุง ุฐูุฑูุง ุนูุฏูุง ุญุฏุฏูุง ูุธููุชูุง ูุญุณุงุจ ุงููููุงุณุ ูู ูุชููู ูู ุงูุญุตูู ุนูู ุญููุฉ ุชูููู ููุชุธูุฉ ุจุณุจุจ ุชูููุน ูุธููุฉ `compute_metrics()` . ูููููุง ูุชุงุจุฉ ูุฆุฉ ูุฑุนูุฉ ุฎุงุตุฉ ุจูุง ูู `Trainer` ููููุงู ุจุฐูู (ููู ููุฌ ููููู ุงูุนุซูุฑ ุนููู ูู [ูุต ูุซุงู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ](https://github.com/huggingface/transformers/blob/master/examples/pytorch/question-answering/trainer_qa.py))ุ ูููู ูุฐุง ุทููู ุฌุฏูุง ููุฐุง ุงููุณู. ุจุฏูุงู ูู ุฐููุ ุณูููู ููุท ุจุชูููู ุงููููุฐุฌ ูู ููุงูุฉ ุงูุชุฏุฑูุจ ููุง ูุณููุถุญ ูู ููููุฉ ุฅุฌุฑุงุก ุชูููู ููุชุธู ูู "ุญููุฉ ุชุฏุฑูุจ ูุฎุตุตุฉ" ุฃุฏูุงู.

ููุง ุญููุง ูุธูุฑ `Trainer` API ุญุฏูุฏู ููุจุฑุฒ ููุชุจุฉ ๐ค Accelerate: ูููู ุฃู ูููู ุชุฎุตูุต ุงููุฆุฉ ูุญุงูุฉ ุงุณุชุฎุฏุงู ูุญุฏุฏุฉ ูุคูููุงุ ูููู ุชุนุฏูู ุญููุฉ ุชุฏุฑูุจ ููุดููุฉ ุจุงููุงูู ุฃูุฑูุง ุณููุงู.

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู `TrainingArguments`:

```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-squad",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    push_to_hub=True,
)
```

ููุฏ ุฑุฃููุง ูุนุธู ูุฐู ุงูุฃุดูุงุก ูู ูุจู: ูุญุฏุฏ ุจุนุถ ุงููุนููุงุช (ูุซู ูุนุฏู ุงูุชุนููุ ูุนุฏุฏ ุงูุนุตูุฑ ุงูุชู ูุชุฏุฑุจ ุนูููุงุ ูุจุนุถ ุงูุชูุงุดู ุงููุฒูู) ููุดูุฑ ุฅูู ุฃููุง ูุฑูุฏ ุญูุธ ุงููููุฐุฌ ูู ููุงูุฉ ูู ุนุตุฑุ ูุชุฎุทู ุงูุชููููุ ูุชุญููู ูุชุงุฆุฌูุง ุฅูู ูุฑูุฒ ุงููููุฐุฌ. ููุง ูููู ุงูุชุฏุฑูุจ ุงูุฏููู ุงููุฎุชูุท ูุน `fp16=True`ุ ุญูุซ ููููู ุชุณุฑูุน ุงูุชุฏุฑูุจ ุจุดูู ูุทูู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุญุฏูุซุฉ.

{:else}

ุงูุขู ุจุนุฏ ุงูุงูุชูุงุก ูู ุฐููุ ูููููุง ุฅูุดุงุก ูุฌููุนุงุช ุจูุงูุงุช TF ุงูุฎุงุตุฉ ุจูุง. ูููููุง ุงุณุชุฎุฏุงู ุฌุงูุน ุงูุจูุงูุงุช ุงูุงูุชุฑุงุถู ุงูุจุณูุท ูุฐู ุงููุฑุฉ:

```python
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")
```

ูุงูุขู ููุดุฆ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุงููุนุชุงุฏ.

```python
tf_train_dataset = model.prepare_tf_dataset(
    train_dataset,
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)
tf_eval_dataset = model.prepare_tf_dataset(
    validation_dataset,
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

ุจุนุฏ ุฐููุ ูููู ุจุฅุนุฏุงุฏ ุงููุนููุงุช ุงูุชุฏุฑูุจูุฉ ุงูุฎุงุตุฉ ุจูุง ูุชุฌููุน ูููุฐุฌูุง:

```python
from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ ูู ุนุฏุฏ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููุณููุฉ ุนูู ุญุฌู ุงูุฏูุนุฉ ุซู ูุถุฑูุจุฉ
# ุจุนุฏุฏ ุงูุนุตูุฑ ุงูุชุฏุฑูุจูุฉ ุงูุฅุฌูุงูู. ูุงุญุธ ุฃู tf_train_dataset ููุง ุนุจุงุฑุฉ ุนู tf.data.Datasetุ
# ูููุณ ูุฌููุนุฉ ุจูุงูุงุช Hugging Face ุงูุฃุตููุฉุ ูุฐุง ูุฅู len() ุงูุฎุงุตุฉ ุจูุง ูู ุจุงููุนู num_samples // batch_size.
num_train_epochs = 3
num_train_steps = len(tf_train_dataset) * num_train_epochs
optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# ุชุฏุฑูุจ ูู ุฏูุฉ ุนุงุฆูุฉ ูุฎุชูุทุฉ
tf.keras.mixed_precision.set_global_policy("mixed_float16")
```

ุฃุฎูุฑูุงุ ูุญู ูุณุชุนุฏูู ููุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู `model.fit()`. ูุณุชุฎุฏู `PushToHubCallback` ูุชุญููู ุงููููุฐุฌ ุฅูู ุงููุฑูุฒ ุจุนุฏ ูู ุนุตุฑ.

{/if}

ุจุงูุชุฑุงุถ ุงูุงูุชุฑุงุถูุ ุณูุชู ุงุณุชุฎุฏุงู ุงููุณุชูุฏุน ูู ูุณุงุญุฉ ุงูุงุณู ุงูุฎุงุตุฉ ุจู ููุชู ุชุณููุชู ููููุง ูุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ุญุฏุฏุชูุ ูุฐุง ูู ุญุงูุชูุง ุณูููู ูู `"sgugger/bert-finetuned-squad"`. ูููููุง ุชุฌุงูุฒ ุฐูู ุนู ุทุฑูู ุชูุฑูุฑ `hub_model_id`ุ ุนูู ุณุจูู ุงููุซุงูุ ูุฏูุน ุงููููุฐุฌ ุฅูู ููุธูุฉ `huggingface_course`ุ ุงุณุชุฎุฏููุง `hub_model_id="huggingface_course/bert-finetuned-squad"` (ููู ุงููููุฐุฌ ุงูุฐู ุฑุจุท ุจู ูู ุจุฏุงูุฉ ูุฐุง ุงููุณู).

{#if fw === 'pt'}

<Tip>

๐ก ุฅุฐุง ูุงู ุฏููู ุงูุฅุฎุฑุงุฌ ุงูุฐู ุชุณุชุฎุฏูู ููุฌูุฏูุงุ ููุฌุจ ุฃู ูููู ูุณุชูุณุฎูุง ูุญูููุง ูููุณุชูุฏุน ุงูุฐู ุชุฑูุฏ ุฏูุนู ุฅููู (ูุฐุง ูู ุจุชุนููู ุงุณู ุฌุฏูุฏ ุฅุฐุง ุญุตูุช ุนูู ุฎุทุฃ ุนูุฏ ุชุญุฏูุฏ `Trainer`).

</Tip>

ุฃุฎูุฑูุงุ ูููู ููุท ุจุชูุฑูุฑ ูู ุดูุก ุฅูู ูุฆุฉ `Trainer` ูุฅุทูุงู ุงูุชุฏุฑูุจ:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=validation_dataset,
    tokenizer=tokenizer,
)
trainer.train()
```

{:else}

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-squad", tokenizer=tokenizer)

# ุณูููู ุจุงูุชุญูู ูุงุญููุงุ ูุฐุง ูุง ููุฌุฏ ุชุญูู ูู ููุชุตู ุงูุชุฏุฑูุจ
model.fit(tf_train_dataset, callbacks=[callback], epochs=num_train_epochs)
```

{/if}

ูุงุญุธ ุฃูู ุฃุซูุงุก ุญุฏูุซ ุงูุชุฏุฑูุจุ ูู ูุฑุฉ ูุชู ูููุง ุญูุธ ุงููููุฐุฌ (ููุงุ ูู ุนุตุฑ) ูุชู ุชุญูููู ุฅูู ุงููุฑูุฒ ูู ุงูุฎูููุฉ. ุจูุฐู ุงูุทุฑููุฉุ ุณุชุชููู ูู ุงุณุชุฆูุงู ุชุฏุฑูุจู ุนูู ุฌูุงุฒ ุขุฎุฑ ุฅุฐุง ูุฒู ุงูุฃูุฑ. ูุณุชุบุฑู ุงูุชุฏุฑูุจ ุจุงููุงูู ุจุนุถ ุงูููุช (ุฃูุซุฑ ุจูููู ูู ุณุงุนุฉ ุนูู Titan RTX)ุ ูุฐุง ููููู ุชูุงูู ุงููููุฉ ุฃู ุฅุนุงุฏุฉ ูุฑุงุกุฉ ุจุนุถ ุฃุฌุฒุงุก ุงูุฏูุฑุฉ ุงูุชู ูุฌุฏุชูุง ุฃูุซุฑ ุชุญุฏููุง ุฃุซูุงุก ุชูุฏููุง. ูุงุญุธ ุฃูุถูุง ุฃูู ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุงูุนุตุฑ ุงูุฃููุ ุณุชุฑู ุจุนุถ ุงูุฃูุฒุงู ุงููุญููุฉ ุฅูู ุงููุฑูุฒ ูููููู ุงูุจุฏุก ูู ุงููุนุจ ูุน ูููุฐุฌู ุนูู ุตูุญุชู.

{#if fw === 'pt'}

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ูููููุง ุฃุฎูุฑูุง ุชูููู ูููุฐุฌูุง (ูุงูุตูุงุฉ ูู ููุถ ูู ูุฐุง ุงูููุช ูู ุงูุญุณุงุจ ุนูู ูุง ุดูุก). ุณุชุนูุฏ ุทุฑููุฉ `predict()` ุงูุฎุงุตุฉ ุจู `Trainer` ุฒูุฌูุง ุญูุซ ุณุชููู ุงูุนูุงุตุฑ ุงูุฃููู ูู ุชูุจุคุงุช ุงููููุฐุฌ (ููุง ุฒูุฌ ูุน ุชุณุฌููุงุช ุงูุฏุฎูู ุงูุฃูููุฉ ูุงูููุงุฆูุฉ). ูุฑุณู ูุฐุง ุฅูู ูุธููุฉ `compute_metrics()` ุงูุฎุงุตุฉ ุจูุง:

```python
predictions, _, _ = trainer.predict(validation_dataset)
start_logits, end_logits = predictions
compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets["validation"])
```

{:else}

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ูููููุง ุฃุฎูุฑูุง ุชูููู ูููุฐุฌูุง (ูุงูุตูุงุฉ ูู ููุถ ูู ูุฐุง ุงูููุช ูู ุงูุญุณุงุจ ุนูู ูุง ุดูุก). ุณุชุชููู ุทุฑููุฉ `predict()` ุงูุฎุงุตุฉ ุจู `model` ุฑุนุงูุฉ ุงูุญุตูู ุนูู ุงูุชูุจุคุงุชุ ูุจูุง ุฃููุง ูููุง ุจูู ุงูุนูู ุงูุดุงู ูุชุญุฏูุฏ ูุธููุฉ `compute_metrics()`ุ ููููููุง ุงูุญุตูู ุนูู ูุชุงุฆุฌูุง ูู ุณุทุฑ ูุงุญุฏ:

```python
predictions = model.predict(tf_eval_dataset)
compute_metrics(
    predictions["start_logits"],
    predictions["end_logits"],
    validation_dataset,
    raw_datasets["validation"],
)
```

{/if}

```python out
{'exact_match': 81.18259224219489, 'f1': 88.67381321905516}
```

ุฑุงุฆุน! ููููุงุฑูุฉุ ูุฅู ุงูุฏุฑุฌุงุช ุงูุฃุณุงุณูุฉ ุงููุจูุบ ุนููุง ูู ููุงู BERT ููุฐุง ุงููููุฐุฌ ูู 80.8 ู88.5ุ ูุฐุง ูุญู ูู ุงูููุงู ุงูุฐู ูุฌุจ ุฃู ูููู ููู.

{#if fw === 'pt'}

ุฃุฎูุฑูุงุ ูุณุชุฎุฏู ุทุฑููุฉ `push_to_hub()` ููุชุฃูุฏ ูู ุชุญููู ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู ุงููููุฐุฌ:

```py
trainer.push_to_hub(commit_message="Training complete")
```

ูุนูุฏ ูุฐุง ุนููุงู URL ููุงูุชุฒุงู ุงูุฐู ูุงู ุจู ููุชูุ ุฅุฐุง ููุช ุชุฑูุฏ ูุญุตู:

```python out
'https://huggingface.co/sgugger/bert-finetuned-squad/commit/9dcee1fbc25946a6ed4bb32efb1bd71d5fa90b68'
```
ูููู `Trainer` ุฃูุถูุง ุจุตูุงุบุฉ ุจุทุงูุฉ ูููุฐุฌ ูุน ุฌููุน ูุชุงุฆุฌ ุงูุชูููู ูุชุญููููุง.

{/if}

ูู ูุฐู ุงููุฑุญูุฉุ ููููู ุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุงูุงุณุชุฏูุงู ุนูู Model Hub ูุงุฎุชุจุงุฑ ุงููููุฐุฌ ููุดุงุฑูุชู ูุน ุฃุตุฏูุงุฆู ูุนุงุฆูุชู ูุญููุงูุงุชู ุงูุฃูููุฉ ุงูููุถูุฉ. ููุฏ ููุช ุจุชุนุฏูู ูููุฐุฌ ุจูุฌุงุญ ุนูู ูููุฉ ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ - ุชูุงูููุง!

<ูุตูุญุฉ>

โ๏ธ **ุฏูุฑู!** ุฌุฑุจ ุจููุฉ ูููุฐุฌ ุฃุฎุฑู ููุนุฑูุฉ ูุง ุฅุฐุง ูุงู ุฃุฏุงุคูุง ุฃูุถู ูู ูุฐู ุงููููุฉ!

</ูุตูุญุฉ>

{#if fw === 'pt'}

ุฅุฐุง ููุช ุชุฑูุฏ ุงูุบูุต ุจุดูู ุฃุนูู ููููุงู ูู ุญููุฉ ุงูุชุฏุฑูุจุ ูุณูุฑููู ุงูุขู ููููุฉ ุงูููุงู ุจููุณ ุงูุดูุก ุจุงุณุชุฎุฏุงู ๐ค Accelerate.

## ุญููุฉ ุชุฏุฑูุจ ูุฎุตุตุฉ [[a-custom-training-loop]]

ุฏุนููุง ุงูุขู ูููู ูุธุฑุฉ ุนูู ุญููุฉ ุงูุชุฏุฑูุจ ุงููุงููุฉุ ุจุญูุซ ููููู ุชุฎุตูุต ุงูุฃุฌุฒุงุก ุงูุชู ุชุญุชุงุฌูุง ุจุณูููุฉ. ุณุชุจุฏู ูุดุงุจูุฉ ุฌุฏูุง ูุญููุฉ ุงูุชุฏุฑูุจ ูู [ุงููุตู 3](/course/chapter3/4)ุ ุจุงุณุชุซูุงุก ุญููุฉ ุงูุชูููู. ุณูุชููู ูู ุชูููู ุงููููุฐุฌ ุจุงูุชุธุงู ูุฃููุง ูู ูุนุฏ ูููุฏูู ุจูุฆุฉ `Trainer`.

### ุงูุฅุนุฏุงุฏ ููู ุดูุก ููุชุฏุฑูุจ [[preparing-everything-for-training]]

ุฃููุงูุ ูุญุชุงุฌ ุฅูู ุจูุงุก `DataLoader`s ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุง. ูููู ุจุชุนููู ุชูุณูู ุชูู ุงููุฌููุนุงุช ุฅูู `"torch"`ุ ูุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ูู ูุฌููุนุฉ ุงูุชุญูู ุงูุชู ูุง ูุณุชุฎุฏููุง ุงููููุฐุฌ. ุจุนุฏ ุฐููุ ูููููุง ุงุณุชุฎุฏุงู `default_data_collator` ุงูููุฏูุฉ ูู Transformers ูู `collate_fn` ูุฎูุท ูุฌููุนุฉ ุงูุชุฏุฑูุจุ ูููู ููุณ ูุฌููุนุฉ ุงูุชุญูู:

```py
from torch.utils.data import DataLoader
from transformers import default_data_collator

train_dataset.set_format("torch")
validation_set = validation_dataset.remove_columns(["example_id", "offset_mapping"])
validation_set.set_format("torch")

train_dataloader = DataLoader(
    train_dataset,
    shuffle=True,
    collate_fn=default_data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    validation_set, collate_fn=default_data_collator, batch_size=8
)
```

ุจุนุฏ ุฐููุ ูุนูุฏ ุฅูุดุงุก ูููุฐุฌูุงุ ููุชุฃูุฏ ูู ุฃููุง ูุง ููุงุตู ุงูุชุนุฏูู ุงูุฏููู ูู ูุจูุ ูููู ูุจุฏุฃ ูู ุงููููุฐุฌ ุงููุณุจู ุงูุชุฏุฑูุจ BERT ูุฑุฉ ุฃุฎุฑู:

```py
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

ุจุนุฏ ุฐููุ ุณูุญุชุงุฌ ุฅูู ูุญุณู. ููุง ูู ูุนุชุงุฏุ ูุณุชุฎุฏู ุงูููุงุณููู `AdamW`ุ ูุงูุฐู ูุดุจู Adamุ ูููู ูุน ุฅุตูุงุญ ูู ุทุฑููุฉ ุชุทุจูู ุงูุชูุงุดู ุงููุฒูู:

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

ุจูุฌุฑุฏ ุญุตูููุง ุนูู ูู ูุฐู ุงูุฃุดูุงุกุ ูููููุง ุฅุฑุณุงููุง ุฅูู ุทุฑููุฉ `accelerator.prepare()`. ุชุฐูุฑ ุฃูู ุฅุฐุง ููุช ุชุฑูุฏ ุงูุชุฏุฑูุจ ุนูู TPUs ูู ุฏูุชุฑ ููุงุญุธุงุช Colabุ ูุณุชุญุชุงุฌ ุฅูู ููู ูู ูุฐุง ุงูุฑูุฒ ุฅูู ูุธููุฉ ุชุฏุฑูุจุ ูุฃูุง ุชููุฐ ุฃู ุฎููุฉ ุชูุดุฆ `Accelerator`. ูููููุง ูุฑุถ ุชุฏุฑูุจ ุงูุฏูุฉ ุงููุฎุชูุทุฉ ุนู ุทุฑูู ุชูุฑูุฑ `fp16=True` ุฅูู `Accelerator` (ุฃูุ ุฅุฐุง ููุช ุชููุฐ ุงูุฑูุฒ ููุต ุจุฑูุฌูุ ูุชุฃูุฏ ูู ููุก ุชูููู ๐ค Accelerate ุจุดูู ููุงุณุจ).

```py
from accelerate import Accelerator

accelerator = Accelerator(fp16=True)
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

ููุง ูุฌุจ ุฃู ุชุนุฑู ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉุ ูููููุง ููุท ุงุณุชุฎุฏุงู ุทูู `train_dataloader` ูุญุณุงุจ ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ ุจุนุฏ ุฃู ูุฑุช ุจุทุฑููุฉ `accelerator.prepare()`. ูุณุชุฎุฏู ููุณ ุงูุฌุฏูู ุงูุฒููู ุงูุฎุทู ููุง ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉ:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

ูุฏูุน ูููุฐุฌูุง ุฅูู Hubุ ุณูุญุชุงุฌ ุฅูู ุฅูุดุงุก ูุงุฆู `Repository` ูู ูุฌูุฏ ุนูู. ูู ุจุชุณุฌูู ุงูุฏุฎูู ุฃููุงู ุฅูู Hugging Face Hubุ ุฅุฐุง ูู ุชูู ูุณุฌูุงู ุจุงููุนู. ุณูุญุฏุฏ ุงุณู ุงููุณุชูุฏุน ูู ูุนุฑู ุงููููุฐุฌ ุงูุฐู ูุฑูุฏ ุฅุนุทุงุกู ููููุฐุฌูุง (ูุง ุชุชุฑุฏุฏ ูู ุงุณุชุจุฏุงู `repo_name` ุจุฎูุงุฑู ุงูุฎุงุตุ ููู ูุญุชุงุฌ ููุท ุฅูู ุงุญุชูุงุก ุงุณู ุงููุณุชุฎุฏู ุงูุฎุงุต ุจูุ ููู ูุง ุชูุนูู ูุธููุฉ `get_full_repo_name()`):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-squad-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-squad-accelerate'
```

ุจุนุฏ ุฐููุ ูููููุง ุงุณุชูุณุงุฎ ูุฐุง ุงููุณุชูุฏุน ูู ูุฌูุฏ ูุญูู. ุฅุฐุง ูุงู ููุฌูุฏูุง ุจุงููุนูุ ููุฌุจ ุฃู ูููู ูุฐุง ุงููุฌูุฏ ุงููุญูู ูุณุฎุฉ ูู ุงููุณุชูุฏุน ุงูุฐู ูุนูู ุนููู:

```py
output_dir = "bert-finetuned-squad-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

ูููููุง ุงูุขู ุชุญููู ุฃู ุดูุก ูููู ุจุญูุธู ูู `output_dir` ุนู ุทุฑูู ุงุณุชุฏุนุงุก ุทุฑููุฉ `repo.push_to_hub()`. ุณูุณุงุนุฏูุง ูุฐุง ูู ุชุญููู ุงูููุงุฐุฌ ุงููุณูุทุฉ ูู ููุงูุฉ ูู ุญูุจุฉ.

## ุญููุฉ ุงูุชุฏุฑูุจ [[training-loop]]

ูุญู ุงูุขู ูุณุชุนุฏูู ููุชุงุจุฉ ุญููุฉ ุงูุชุฏุฑูุจ ุงููุงููุฉ. ุจุนุฏ ุชุญุฏูุฏ ุดุฑูุท ุงูุชูุฏู ููุชุงุจุนุฉ ููููุฉ ุณูุฑ ุงูุชุฏุฑูุจุ ุชุญุชูู ุงูุญููุฉ ุนูู ุซูุงุซุฉ ุฃุฌุฒุงุก:

- ุงูุชุฏุฑูุจ ูู ุญุฏ ุฐุงุชูุ ููู ุงูุชูุฑุงุฑ ุงูููุงุณููู ุนูู `train_dataloader`ุ ูุงููุฑูุฑ ุงูุฃูุงูู ุนุจุฑ ุงููููุฐุฌุ ุซู ุงููุฑูุฑ ุงูุฎููู ูุฎุทูุฉ ุงููุญุณู.
- ุงูุชููููุ ุงูุฐู ูุฌูุน ููู ุฌููุน ุงูููู ูู `start_logits` ู`end_logits` ูุจู ุชุญููููุง ุฅูู ูุตูููุงุช NumPy. ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุญููุฉ ุงูุชููููุ ูููู ุจุฏูุฌ ุฌููุน ุงููุชุงุฆุฌ. ูุงุญุธ ุฃููุง ูุญุชุงุฌ ุฅูู ุงูุงูุชุตุงุต ูุฃู `Accelerator` ูุฏ ุฃุถุงู ุจุนุถ ุงูุนููุงุช ูู ุงูููุงูุฉ ูุถูุงู ูุฌูุฏ ููุณ ุนุฏุฏ ุงูุฃูุซูุฉ ูู ูู ุนูููุฉ.
- ุงูุญูุธ ูุงูุชุญูููุ ุญูุซ ูููู ุฃููุงู ุจุญูุธ ุงููููุฐุฌ ูุงููุญูู ุงููุบููุ ุซู ุงุณุชุฏุนุงุก `repo.push_to_hub()`. ููุง ูุนููุง ูู ูุจูุ ูุณุชุฎุฏู ุงูุญุฌุฉ `blocking=False` ูุฅุฎุจุงุฑ ููุชุจุฉ ๐ค Hub ุจุงูุฏูุน ูู ุนูููุฉ ุบูุฑ ูุชุฒุงููุฉ. ุจูุฐู ุงูุทุฑููุฉุ ูุณุชูุฑ ุงูุชุฏุฑูุจ ุจุดูู ุทุจูุนู ููุชู ุชูููุฐ ูุฐุง ุงูุชูุฌูู (ุงูุทููู) ูู ุงูุฎูููุฉ.

ููุง ุงูุฑูุฒ ุงููุงูู ูุญููุฉ ุงูุชุฏุฑูุจ:

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    start_logits = []
    end_logits = []
    accelerator.print("Evaluation!")
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            outputs = model(**batch)

        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())
        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())

    start_logits = np.concatenate(start_logits)
    end_logits = np.concatenate(end_logits)
    start_logits = start_logits[: len(validation_dataset)]
    end_logits = end_logits[: len(validation_dataset)]

    metrics = compute_metrics(
        start_logits, end_logits, validation_dataset, raw_datasets["validation"]
    )
    print(f"epoch {epoch}:", metrics)

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

ูู ุญุงูุฉ ุฑุคูุชู ููููุฐุฌ ูุญููุธ ูุน ๐ค Accelerate ูููุฑุฉ ุงูุฃูููุ ุฏุนูุง ูุฃุฎุฐ ูุญุธุฉ ููุญุต ุฃุณุทุฑ ุงูุฑูุฒ ุงูุซูุงุซุฉ ุงูุชู ุชุฃุชู ูุนู:

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```
```
ุงูุณุทุฑ ุงูุฃูู ูุงุถุญ ุจุฐุงุชู: ููู ูุฎุจุฑ ุฌููุน ุงูุนูููุงุช ุจุงูุงูุชุธุงุฑ ุญุชู ูุตู ุงูุฌููุน ุฅูู ุชูู ุงููุฑุญูุฉ ูุจู ุงูุงุณุชูุฑุงุฑ. ูุฐุง ูุถูุงู ุงูุชูุงููุง ูููุณ ุงููููุฐุฌ ูู ูู ุนูููุฉ ูุจู ุงูุญูุธ. ุซู ูููู ุจุฌูุน `unwrapped_model`ุ ููู ุงููููุฐุฌ ุงูุฃุณุงุณู ุงูุฐู ุญุฏุฏูุงู. ุทุฑููุฉ `accelerator.prepare()` ุชุบูุฑ ุงููููุฐุฌ ููุนูู ูู ุงูุชุฏุฑูุจ ุงูููุฒุนุ ูุฐุง ูู ูููู ูุฏูู ุทุฑููุฉ `save_pretrained()` ุจุนุฏ ุงูุขูุ ุทุฑููุฉ `accelerator.unwrap_model()` ุชูุบู ุชูู ุงูุฎุทูุฉ. ุฃุฎูุฑูุงุ ูุณุชุฏุนู `save_pretrained()` ููู ูุฎุจุฑ ุชูู ุงูุทุฑููุฉ ุจุงุณุชุฎุฏุงู `accelerator.save()` ุจุฏูุงู ูู `torch.save()`.

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฐููุ ูุฌุจ ุฃู ูููู ูุฏูู ูููุฐุฌ ููุชุฌ ูุชุงุฆุฌ ูุดุงุจูุฉ ุฌุฏูุง ูููููุฐุฌ ุงูุฐู ุชู ุชุฏุฑูุจู ุจุงุณุชุฎุฏุงู `Trainer`. ููููู ุงูุชุญูู ูู ุงููููุฐุฌ ุงูุฐู ูููุง ุจุชุฏุฑูุจู ุจุงุณุชุฎุฏุงู ูุฐุง ุงูุฑูุฒ ูู [*huggingface-course/bert-finetuned-squad-accelerate*](https://huggingface.co/huggingface-course/bert-finetuned-squad-accelerate). ูุฅุฐุง ููุช ุชุฑุบุจ ูู ุงุฎุชุจุงุฑ ุฃู ุชุนุฏููุงุช ุนูู ุญููุฉ ุงูุชุฏุฑูุจุ ููููู ุชูููุฐูุง ูุจุงุดุฑุฉ ุนู ุทุฑูู ุชุนุฏูู ุงูููุฏ ุงูููุถุญ ุฃุนูุงู!

{/if}

## ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุนุฏู[[using-the-fine-tuned-model]]

ููุฏ ุฃุธูุฑูุง ูู ุจุงููุนู ููู ููููู ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงูุฐู ูููุง ุจุชุนุฏููู ุนูู Model Hub ุจุงุณุชุฎุฏุงู ุฃุฏุงุฉ ุงูุงุณุชุฏูุงู. ูุงุณุชุฎุฏุงูู ูุญูููุง ูู `pipeline`ุ ุนููู ููุท ุชุญุฏูุฏ ูุนุฑูู ุงููููุฐุฌ:

```py
from transformers import pipeline

# ุงุณุชุจุฏู ูุฐุง ุจููุทุฉ ุงูุชุญูู ุงูุฎุงุตุฉ ุจู
model_checkpoint = "huggingface-course/bert-finetuned-squad"
question_answerer = pipeline("question-answering", model=model_checkpoint)

context = """
๐ค Transformers ูุฏุนูู ูู ูุจู ููุชุจุงุช ุงูุชุนูู ุงูุนููู ุงูุซูุงุซ ุงูุฃูุซุฑ ุดุนุจูุฉ โ Jax ู PyTorch ู TensorFlow โ ูุน ุชูุงูู ุณูุณ
ุจูููู. ูู ุงูุณูู ุชุฏุฑูุจ ููุงุฐุฌู ุจุงุณุชุฎุฏุงู ุฃุญุฏูุง ูุจู ุชุญููููุง ููุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุงูุขุฎุฑ.
"""
question = "ูุง ูู ููุชุจุงุช ุงูุชุนูู ุงูุนููู ุงูุชู ุชุฏุนู ๐ค Transformersุ"
question_answerer(question=question, context=context)
```

```python out
{'score': 0.9979003071784973,
 'start': 78,
 'end': 105,
 'answer': 'Jaxุ PyTorch ู TensorFlow'}
```

ุฑุงุฆุน! ูููุฐุฌูุง ูุนูู ุฌูุฏูุง ูุซู ุงููููุฐุฌ ุงูุงูุชุฑุงุถู ููุฐุง ุงูุฃูุจูุจ!
